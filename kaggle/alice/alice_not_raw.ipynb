{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set desired options\n",
    "\n",
    "from __future__ import division, print_function\n",
    "# Disable Anaconda warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function for writing predictions to a file\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites total: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone_le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "      <td>com</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "      <td>com</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "      <td>com</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "      <td>eu</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "      <td>eu</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site zone  zone_le\n",
       "25075              www.abmecatronique.com  com       28\n",
       "13997                     groups.live.com  com       28\n",
       "42436  majeureliguefootball.wordpress.com  com       28\n",
       "30911           cdt46.media.tourinsoft.eu   eu       41\n",
       "8104                  www.hdwallpapers.eu   eu       41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load websites dictionary\n",
    "with open(r\"data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# Create dataframe for the dictionary\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "\n",
    "sites_dict['zone'] = sites_dict['site'].str.split('.').apply(lambda x: x[-1])\n",
    "sites_dict.loc[sites_dict['zone'].str.isnumeric(), 'zone'] = 'ip_address'\n",
    "sites_dict['zone_le'] = LabelEncoder().fit_transform(sites_dict['zone'])\n",
    "\n",
    "print(u'Websites total:', sites_dict.shape[0])\n",
    "sites_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
       "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
       "\n",
       "                         time5  ...                 time6  site7  \\\n",
       "session_id                      ...                                \n",
       "21669                      NaT  ...                   NaT    NaN   \n",
       "54843                      NaT  ...                   NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ...   2013-01-12 08:50:16  948.0   \n",
       "114021     2013-01-12 08:50:18  ...   2013-01-12 08:50:18  947.0   \n",
       "146670     2013-01-12 08:50:21  ...   2013-01-12 08:50:21  946.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
       "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT    NaN                 NaT      0  \n",
       "54843                      NaT    NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training and test data sets\n",
    "train_df = pd.read_csv('data/train_sessions.csv',\n",
    "                      index_col='session_id')\n",
    "test_df = pd.read_csv('data/test_sessions.csv',\n",
    "                      index_col='session_id')\n",
    "\n",
    "# Switch time1, ..., time10 columns to datetime type\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# Look at the first rows of the training set\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change site1, ..., site10 columns type to integer and fill NA-values with zeros\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target variable\n",
    "y_train = train_df['target']\n",
    "\n",
    "# United dataframe of the initial data \n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# Index to split the training and test data sets\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>784</td>\n",
       "      <td>949</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>949</td>\n",
       "      <td>948</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>948</td>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>952</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          56     55      0      0      0      0      0      0      0   \n",
       "54843          56     55     56     55      0      0      0      0      0   \n",
       "77292         946    946    951    946    946    945    948    784    949   \n",
       "114021        945    948    949    948    945    946    947    945    946   \n",
       "146670        947    950    948    947    950    952    946    951    946   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          946  \n",
       "114021         946  \n",
       "146670         947  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with indices of visited websites in session\n",
    "full_sites = full_df[sites]\n",
    "\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_time_diff(row): \n",
    "    time_length = row.shape[0] - 1 \n",
    "    time_diff = [0]*time_length \n",
    "    i = 0 \n",
    "    while (i < time_length)and pd.notnull(row[i+1]): \n",
    "        time_diff[i] = (row[i+1] - row[i]) / np.timedelta64(1,'s') \n",
    "        i += 1 \n",
    "    return  time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_features(df):\n",
    "    time_df = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    hour = df['time1'].dt.hour\n",
    "    time_df['hour'] = hour\n",
    "    time_df['day_'] = df['time1'].dt.day\n",
    "    time_df['month'] = df['time1'].dt.month\n",
    "    time_df['year'] = df['time1'].dt.year\n",
    "    time_df['myear'] = df['time1'].dt.year * 12 + df['time1'].dt.month\n",
    "    \n",
    "#     time_df['morning'] = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "#     time_df['day'] = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "#     time_df['evening'] = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "\n",
    "    time_df['min'] = df['time1'] \n",
    "    time_df['max'] = df[times].max(axis=1)\n",
    "\n",
    "    for px in ['min', 'max']:\n",
    "        time_df['minutes'] = time_df[px].dt.hour * 60 + time_df[px].dt.minute\n",
    "        time_df['sin_'+px] = np.sin(2*np.pi*time_df['minutes']/1440.)\n",
    "        time_df['cos_'+px] = np.cos(2*np.pi*time_df['minutes']/1440.)\n",
    "\n",
    "    time_df['dow'] = time_df['min'].apply(lambda ts: ts.date().weekday())\n",
    "    time_df['weekend'] = (time_df['dow'] > 4).astype('int')\n",
    "    time_df['n_null'] = df[times].isnull().sum(axis=1)\n",
    "\n",
    "    time_df['dt'] = time_df['max'] - time_df['min']\n",
    "    for time in times[1:]:\n",
    "        dt_ = (df[time] - time_df['min']).fillna(time_df['dt'])\n",
    "        time_df['dt_' + time] = np.log1p(np.abs(dt_.astype('timedelta64[s]')))\n",
    "    time_df['dt'] = np.log1p(np.abs(time_df['dt'].astype('timedelta64[s]')))\n",
    "    time_df['dt_mean'] = time_df[['dt_' + time for time in times[1:]]].mean(axis=1)\n",
    "    time_df['dt_std'] = time_df[['dt_' + time for time in times[1:]]].std(axis=1)\n",
    "    time_df['dt_var'] = time_df[['dt_' + time for time in times[1:]]].var(axis=1)\n",
    "    \n",
    "    s_columns = [col for col in time_df.columns if time_df[col].dtype != '<M8[ns]']\n",
    "    \n",
    "    s_scaler = StandardScaler()\n",
    "    time_df[s_columns] = s_scaler.fit_transform(time_df[s_columns])\n",
    "\n",
    "    time_df = time_df.drop(['min', 'max'], axis=1)\n",
    "    \n",
    "    for col in time_df.columns:\n",
    "        time_df[col] = time_df[col].fillna(time_df[col].mean())\n",
    "\n",
    "    return time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               dow       weekend          day_         month       sin_min  \\\n",
      "min  -1.425540e+00 -3.842226e-01 -1.566362e+00 -1.150793e+00 -1.459027e+00   \n",
      "mean -4.028597e-14  2.643474e-13  1.188026e-13 -3.089523e-13 -8.181688e-15   \n",
      "max   2.057594e+00  2.602658e+00  1.695464e+00  1.740832e+00  1.690438e+00   \n",
      "\n",
      "           cos_min            dt        dt_std       dt_mean        n_null  \\\n",
      "min  -8.437691e-01 -1.920105e+00 -1.399868e+00 -1.609976e+00 -2.824378e-01   \n",
      "mean -2.089893e-15 -9.427659e-15 -2.642982e-15 -2.419324e-15  3.250062e-14   \n",
      "max   4.849943e+00  2.268596e+00  4.993226e+00  3.111933e+00  4.802319e+00   \n",
      "\n",
      "           sin_max       cos_max          hour          year       minutes  \\\n",
      "min  -1.451753e+00 -8.401770e-01 -1.700055e+00 -1.871975e+00 -1.655692e+00   \n",
      "mean -2.703839e-15  1.714818e-15  1.160608e-14 -3.004657e-12  1.552238e-15   \n",
      "max   1.696008e+00  4.799861e+00  3.392265e+00  5.341951e-01  3.539841e+00   \n",
      "\n",
      "             myear  (-1.705, -0.427]  (-0.427, 0.846]  (0.846, 2.119]  \\\n",
      "min  -3.249261e+00          0.000000         0.000000        0.000000   \n",
      "mean  3.818527e-13          0.350719         0.390587        0.237283   \n",
      "max   2.200295e+00          1.000000         1.000000        1.000000   \n",
      "\n",
      "      (2.119, 3.392]  \n",
      "min         0.000000  \n",
      "mean        0.021412  \n",
      "max         1.000000  \n"
     ]
    }
   ],
   "source": [
    "full_time = get_time_features(full_df[times])\n",
    "ft_columns = ['dow', 'weekend', 'day_', 'month', 'sin_min', 'cos_min', 'dt', 'dt_std', 'dt_mean', 'n_null',\n",
    "              'sin_max', 'cos_max', 'hour', 'year', 'minutes', 'myear']  # full_time.columns\n",
    "# good_cols = ['sin_min', 'cos_max', 'n_null', 'dt', 'year']\n",
    "\n",
    "full_time = full_time[ft_columns]\n",
    "\n",
    "hours_dum = pd.get_dummies(pd.cut(full_time['hour'], bins=4))\n",
    "\n",
    "full_time = pd.concat([full_time, hours_dum], axis=1)\n",
    "# full_time = pd.concat([full_time[good_cols], hours_dum], axis=1)\n",
    "print(full_time.agg(['min', 'mean', 'max']))\n",
    "full_time = full_time.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sites_tf = full_sites.copy()\n",
    "\n",
    "for col in full_sites_tf.columns:\n",
    "    full_sites_tf[col] = full_sites_tf[col].map(sites_dict.site)\n",
    "\n",
    "full_sites_tf = full_sites_tf.fillna('')\n",
    "# df_tf_col = full_sites_tf.apply(lambda x: '.'.join([i for i in x if len(i)>0]), axis=1)\n",
    "# df_tf_col = df_tf_col.str.split('[.-]').str.join(' ')\n",
    "\n",
    "df_tf_col = full_sites_tf.apply(lambda x: ' '.join([i for i in x if len(i)>0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_df=.7, sublinear_tf=True)\n",
    "df_tf = vect.fit_transform(df_tf_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split = TimeSeriesSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df_tf[:idx_split,:]\n",
    "# X_test = df_tf[idx_split:,:]\n",
    "\n",
    "\n",
    "X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = [0.01, 0.03]\n",
    "# cw_values = [{0: 0.6, 1: 0.4}, {0: 0.9, 1: 0.1}, {0: 0.8, 1: 0.2}, {0: 0.7, 1: 0.3} , {0: 0.3, 1: 0.7}]\n",
    "\n",
    "lrcv = LogisticRegressionCV(Cs=c_values, scoring='roc_auc', n_jobs=-1, cv=kfold_split,\n",
    "                            verbose=1, class_weight='balanced', max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:  8.3min remaining: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 56s, sys: 2min 36s, total: 6min 33s\n",
      "Wall time: 10min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lrcv.fit(X_train, y_train);\n",
    "lrcv.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC [0.01]: 0.9574+-0.0141\n",
      "ROC_AUC [0.03]: 0.9587+-0.0136\n",
      "Best params: [0.03]\n"
     ]
    }
   ],
   "source": [
    "cvr = lrcv.scores_[1]\n",
    "idx = cvr.mean(axis=0).argmax()\n",
    "for i in range(cvr.shape[1]):\n",
    "    print(f\"ROC_AUC [{lrcv.Cs_[i]:>4}]: {cvr[:, i].mean():.4f}+-{cvr[:, i].std():.4f}\")\n",
    "print(f\"Best params: {lrcv.C_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC_AUC [0.01]: 0.9574+-0.0141\n",
    "ROC_AUC [0.03]: 0.9587+-0.0136\n",
    "ROC_AUC [ 0.1]: 0.9586+-0.0127\n",
    "ROC_AUC [ 0.3]: 0.9578+-0.0123\n",
    "ROC_AUC [ 1.0]: 0.9559+-0.0129\n",
    "ROC_AUC [ 3.0]: 0.9531+-0.0142\n",
    "ROC_AUC [10.0]: 0.9488+-0.0167\n",
    "Best params: [0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_tf[:idx_split,:]\n",
    "X_test = df_tf[idx_split:,:]\n",
    "\n",
    "# X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "# X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "logit = LogisticRegression(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 791 ms, sys: 159 ms, total: 950 ms\n",
      "Wall time: 8.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC: 0.8537+-0.0796\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROC_AUC: {cv_scores.mean():.4f}+-{cv_scores.std():.4f}\")\n",
    "# cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(X_train, y_train)\n",
    "logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
    "write_to_submission_file(logit_test_pred, 'subm_not_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check columns importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cw {0: 0.2, 1: 0.8}: 0.9542+-0.0159\n",
      "cw {0: 0.3, 1: 0.7}: 0.9537+-0.0162\n",
      "cw {0: 0.4, 1: 0.6}: 0.9529+-0.0165\n",
      "CPU times: user 3min 28s, sys: 22.5 s, total: 3min 51s\n",
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores_arr = list()\n",
    "\n",
    "for cw in [{0: 0.2, 1: 0.8}, {0: 0.3, 1: 0.7}, {0: 0.4, 1: 0.6}]:\n",
    "    vect = TfidfVectorizer(max_df=0.9, sublinear_tf=True)\n",
    "    df_tf = vect.fit_transform(df_tf_col)\n",
    "    params = {'C': 0.1, 'class_weight': cw, 'random_state':17, 'n_jobs':1}\n",
    "    \n",
    "    X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "    X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])\n",
    "    \n",
    "    logit = LogisticRegression(**params)\n",
    "    cv_scores_ = cross_val_score(logit, X_train, y_train, cv=kfold_split, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_scores_arr.append(cv_scores_)\n",
    "    \n",
    "    print(f\"cw {cw}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cw balanced  : 0.9586+-0.0127\n",
    "cw {0: 0.9, 1: 0.1}: 0.9390+-0.0209\n",
    "cw {0: 0.8, 1: 0.2}: 0.9451+-0.0188\n",
    "cw {0: 0.7, 1: 0.3}: 0.9483+-0.0178\n",
    "cw {0: 0.6, 1: 0.4}: 0.9504+-0.0172\n",
    "cw {0: 0.5, 1: 0.5}: 0.9518+-0.0168\n",
    "cw {0: 0.4, 1: 0.6}: 0.9529+-0.0165\n",
    "cw {0: 0.3, 1: 0.7}: 0.9537+-0.0162\n",
    "cw {0: 0.2, 1: 0.8}: 0.9542+-0.0159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define good tf-idf params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 0.5   : 0.8736+-0.1068\n",
      "max_df 0.6   : 0.8742+-0.1057\n",
      "max_df 0.7   : 0.8742+-0.1057\n",
      "max_df 0.8   : 0.8736+-0.1061\n",
      "max_df 0.9   : 0.8738+-0.1067\n",
      "max_df 1     : 0.8008+-0.0957\n",
      "CPU times: user 59.3 s, sys: 6.51 s, total: 1min 5s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "cv_scores_arr = list()\n",
    "\n",
    "for i in [.5, .6, .7, .8, .9, 1]:\n",
    "    vect = TfidfVectorizer(max_df=i, sublinear_tf=True)\n",
    "    df_tf = vect.fit_transform(df_tf_col)\n",
    "    \n",
    "    X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "    X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])\n",
    "    \n",
    "    logit = LogisticRegression(**params)\n",
    "    cv_scores_ = cross_val_score(logit, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_scores_arr.append(cv_scores_)\n",
    "    \n",
    "    print(f\"max_df {i:<6}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_df 0.0001: 0.9581+-0.0129\n",
    "min_df 0.001: 0.9560+-0.0120\n",
    "min_df 0.01: 0.9403+-0.0132\n",
    "min_df 0.1: 0.9110+-0.0209\n",
    "min_df 0.3: 0.8979+-0.0200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_df 0.50: 0.9582+-0.0125\n",
    "max_df 0.60: 0.9583+-0.0126\n",
    "max_df 0.70: 0.9583+-0.0126\n",
    "max_df 0.80: 0.9583+-0.0126\n",
    "max_df 0.85: 0.9583+-0.0126\n",
    "max_df 0.90: 0.9586+-0.0127\n",
    "max_df 0.95: 0.9586+-0.0127\n",
    "max_df 0.98: 0.9586+-0.0127\n",
    "max_df 1.00: 0.8968+-0.0200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define good hour split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC: 0.9530+-0.0141\n"
     ]
    }
   ],
   "source": [
    "good_cols = ['sin_min', 'cos_max', 'n_null', 'dt', 'year', 'morning', 'day', 'evening']\n",
    "mask = pd.Series(ft_columns).isin(good_cols).values\n",
    "\n",
    "X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask]])\n",
    "X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask]])\n",
    "\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "logit = LogisticRegression(**params)\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train, y_train, cv=kfold_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster\n",
    "\n",
    "print(f\"ROC_AUC: {cv_scores.mean():.4f}+-{cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins 2         : 0.9465+-0.0194 EXCLUDE\n",
      "Bins 3         : 0.9418+-0.0187 EXCLUDE\n",
      "Bins 4         : 0.9583+-0.0126 ADD\n",
      "Bins 5         : 0.9494+-0.0208 EXCLUDE\n",
      "Bins 6         : 0.9429+-0.0222 EXCLUDE\n",
      "Bins 7         : 0.9548+-0.0194 EXCLUDE\n",
      "Bins 8         : 0.9592+-0.0168 ADD\n",
      "CPU times: user 1min 29s, sys: 34.6 s, total: 2min 4s\n",
      "Wall time: 20min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "good_cols = ['sin_min', 'cos_max', 'n_null', 'dt', 'year']\n",
    "mask = pd.Series(ft_columns).isin(good_cols).values\n",
    "\n",
    "mask_hours = pd.Series(ft_columns).isin(['hour']).values\n",
    "hours = pd.Series(full_time[:, mask_hours].flatten())\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "cv_scores_arr = []\n",
    "\n",
    "for i in range(2, 9):\n",
    "    hours_dum = pd.get_dummies(pd.cut(hours, bins=i)).values\n",
    "    \n",
    "    X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask], hours_dum[:idx_split, :]])\n",
    "    X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask], hours_dum[idx_split:, :]])\n",
    "    \n",
    "    logit = LogisticRegression(**params)\n",
    "    cv_scores_ = cross_val_score(logit, X_train, y_train, cv=kfold_split, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_scores_arr.append(cv_scores_)\n",
    "    \n",
    "    d_cv = cv_scores_ - cv_scores\n",
    "    n_pos = (d_cv > 0).sum()\n",
    "    if not(d_cv.mean() > 0 and n_pos > 4):\n",
    "        print(f\"Bins {i:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} EXCLUDE\")\n",
    "    else:\n",
    "        cv_scores = cv_scores_.copy()\n",
    "        print(f\"Bins {i:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} ADD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete columns one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_columns = ['dow', 'weekend', 'day_', 'month', 'sin_min', 'cos_min', 'dt', 'dt_std', 'dt_mean', 'n_null',\n",
    "              'sin_max', 'cos_max', 'hour', 'year', 'minutes', 'myear', 'bin1', 'bin2', 'bin3', 'bin4']  # full_time.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8735747277102843"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "bin3      : 0.8723+-0.1060 OK  \n",
      "weekend   : 0.8803+-0.1304 EXCLUDE  \n",
      "bin4      : 0.8800+-0.1307 OK  \n",
      "dt_mean   : 0.8804+-0.1302 EXCLUDE  \n",
      "sin_max   : 0.8804+-0.1304 OK  \n",
      "bin2      : 0.8813+-0.1266 OK  \n",
      "dt        : 0.8802+-0.1307 OK  \n",
      "year      : 0.8803+-0.1301 OK  \n",
      "sin_min   : 0.8803+-0.1304 OK  \n",
      "day_      : 0.8803+-0.1300 OK  \n",
      "cos_min   : 0.8803+-0.1301 OK  \n",
      "minutes   : 0.8801+-0.1309 OK  \n",
      "n_null    : 0.8812+-0.1328 OK  \n",
      "dt_std    : 0.8804+-0.1303 OK  \n",
      "bin1      : 0.8804+-0.1304 OK  \n",
      "cos_max   : 0.8803+-0.1304 OK  \n",
      "month     : 0.8803+-0.1303 OK  \n",
      "dow       : 0.8799+-0.1290 OK  \n",
      "myear     : 0.8804+-0.1300 OK  \n",
      "hour      : 0.8806+-0.1304 EXCLUDE  \n",
      "******************************\n",
      "Iter 1\n",
      "month     : 0.8731+-0.1065 OK  \n",
      "bin1      : 0.8744+-0.1054 OK  \n",
      "dt        : 0.8736+-0.1061 OK  \n",
      "sin_max   : 0.8736+-0.1062 OK  \n",
      "day_      : 0.8744+-0.1061 OK  \n",
      "minutes   : 0.8736+-0.1062 OK  \n",
      "sin_min   : 0.8735+-0.1062 OK  \n",
      "bin2      : 0.8748+-0.0999 OK  \n",
      "dt_std    : 0.8736+-0.1061 OK  \n",
      "weekend   : 0.8803+-0.1304 EXCLUDE  \n",
      "year      : 0.8802+-0.1302 OK  \n",
      "dow       : 0.8798+-0.1291 OK  \n",
      "bin4      : 0.8800+-0.1307 OK  \n",
      "bin3      : 0.8803+-0.1290 OK  \n",
      "n_null    : 0.8811+-0.1330 OK  \n",
      "myear     : 0.8803+-0.1301 OK  \n",
      "dt_mean   : 0.8804+-0.1302 EXCLUDE  \n",
      "hour      : 0.8806+-0.1304 EXCLUDE  \n",
      "cos_max   : 0.8805+-0.1305 OK  \n",
      "cos_min   : 0.8805+-0.1302 OK  \n",
      "******************************\n",
      "Iter 2\n",
      "hour      : 0.8738+-0.1064 EXCLUDE  \n",
      "sin_min   : 0.8738+-0.1064 OK  \n",
      "bin3      : 0.8726+-0.1062 OK  \n",
      "dow       : 0.8674+-0.1234 OK  \n",
      "n_null    : 0.8742+-0.1094 OK  \n",
      "cos_min   : 0.8737+-0.1062 OK  \n",
      "month     : 0.8733+-0.1067 OK  \n",
      "sin_max   : 0.8738+-0.1064 OK  \n",
      "weekend   : 0.8805+-0.1305 EXCLUDE  \n",
      "bin2      : 0.8815+-0.1268 OK  \n",
      "dt_std    : 0.8805+-0.1305 OK  \n",
      "bin1      : 0.8805+-0.1307 OK  \n",
      "minutes   : 0.8806+-0.1312 OK  \n",
      "day_      : 0.8805+-0.1303 OK  \n",
      "cos_max   : 0.8804+-0.1306 OK  \n",
      "dt        : 0.8804+-0.1306 OK  \n",
      "bin4      : 0.8802+-0.1309 OK  \n",
      "year      : 0.8804+-0.1303 OK  \n",
      "myear     : 0.8805+-0.1302 OK  \n",
      "dt_mean   : 0.8806+-0.1304 EXCLUDE  \n",
      "******************************\n",
      "Iter 3\n",
      "minutes   : 0.8736+-0.1062 OK  \n",
      "day_      : 0.8744+-0.1061 OK  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-508:\n",
      "Process ForkPoolWorker-507:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "cv_scores_all = list()\n",
    "delete_dict = {col:0 for col in ft_columns}\n",
    "boundary = time_split.n_splits * 7 // 10\n",
    "\n",
    "for iter_ in range(10):\n",
    "    print(f\"Iter {iter_}\")\n",
    "    idx_order = list(range(n_cols))\n",
    "    np.random.seed(iter_)\n",
    "    np.random.shuffle(idx_order)\n",
    "    cv_scores_n_ = cv_scores.copy()\n",
    "    cv_scores_arr = list()\n",
    "    mask = np.ones(n_cols, dtype='bool')\n",
    "    \n",
    "    for n_ in range(-n_cols, 0):\n",
    "        i = idx_order[n_]\n",
    "        mask[i] = False\n",
    "        X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask]])\n",
    "        X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask]])\n",
    "        logit = LogisticRegression(**params)\n",
    "        cv_scores_ = cross_val_score(logit, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "        cv_scores_arr.append(cv_scores_)\n",
    "\n",
    "        d_cv = cv_scores_ - cv_scores_n_\n",
    "        n_neg = (d_cv > 0).sum()\n",
    "        if d_cv.mean() > 0 and n_neg >= boundary:\n",
    "            delete_dict[ft_columns[i]] += 1\n",
    "            cv_scores_n_ = cv_scores_.copy()\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} EXCLUDE  \")\n",
    "        else:\n",
    "            mask[i] = True\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} OK  \")\n",
    "    cv_scores_all.append(cv_scores_arr)\n",
    "    print('*' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "cv_scores_arr = []\n",
    "mask = np.zeros(n_cols, dtype='bool')\n",
    "for i in range(-n_cols, 0):\n",
    "    if 'dt_time' not in ft_columns[i]:\n",
    "        mask[i] = True\n",
    "        X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask]])\n",
    "        X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask]])\n",
    "        logit = LogisticRegression(**params)\n",
    "        cv_scores_ = cross_val_score(logit, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "        cv_scores_arr.append(cv_scores_)\n",
    "\n",
    "        d_cv = cv_scores_ - cv_scores\n",
    "        n_pos = (d_cv > 0).sum()\n",
    "        if not(d_cv.mean() > 0 and n_pos > d_cv.shape[0]/2):\n",
    "            mask[i] = False\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} EXCLUDE  \")\n",
    "        else:\n",
    "            cv_scores = cv_scores_.copy()\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} ADD  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dow       : 0.8544+-0.0874 EXCLUDE\n",
    "weekend   : 0.8399+-0.0972 EXCLUDE\n",
    "day_      : 0.8523+-0.0798 EXCLUDE\n",
    "month     : 0.8552+-0.0807 ADD\n",
    "sin_min   : 0.9028+-0.0783 ADD\n",
    "cos_min   : 0.8915+-0.0949 EXCLUDE\n",
    "dt        : 0.9019+-0.0794 EXCLUDE\n",
    "dt_std    : 0.9028+-0.0788 EXCLUDE\n",
    "dt_mean   : 0.9016+-0.0794 EXCLUDE\n",
    "n_null    : 0.9020+-0.0756 EXCLUDE\n",
    "morning   : 0.8923+-0.0966 EXCLUDE\n",
    "day       : 0.9008+-0.0817 EXCLUDE\n",
    "evening   : 0.9057+-0.0756 ADD\n",
    "sin_max   : 0.9057+-0.0756 ADD\n",
    "cos_max   : 0.8854+-0.1113 EXCLUDE\n",
    "hour      : 0.9007+-0.0837 EXCLUDE\n",
    "year      : 0.9099+-0.0767 ADD\n",
    "minutes   : 0.9054+-0.0844 EXCLUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols = ['sin_min', 'cos_max', 'n_null', 'dt', 'year', 'morning', 'day', 'evening']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer df_tf + time  max_df=.7 sublinear_tf=True\n",
    "ROC_AUC: 0.9168+-0.0542\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time  max_df=.7\n",
    "ROC_AUC: 0.9148+-0.0504\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time  max_df=.8\n",
    "ROC_AUC: 0.9125+-0.0538\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time\n",
    "ROC_AUC: 0.9115+-0.0546\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time (sites name full)\n",
    "ROC_AUC: 0.9115+-0.0546\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf\n",
    "ROC_AUC: 0.8575+-0.0753\n",
    "Best params: {'C': 20, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "CountVectorizer df_tf\n",
    "ROC_AUC: 0.8351+-0.0763\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred = logit_grid_searcher.predict_proba(X_test)[:, 1]\n",
    "write_to_submission_file(logit_test_pred, 'pred/a_sub_new_df_tfidf_drop_dub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets watch origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User sessions are chosen in the way they are not longer than half an hour or/and contain more than ten websites. I.e. a session is considered as ended either if a user has visited ten websites or if a session has lasted over thirty minutes.\n",
    "\n",
    "There are some empty values in the table, it means that some sessions contain less than ten websites. Replace empty values with 0 and change columns types to integer. Also load the websites dictionary and check how it looks like:\n",
    "\n",
    "**ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ðµ ÑÐµÑÑÐ¸Ð¸ Ð²Ñ‹Ð±Ð¸Ñ€Ð°ÑŽÑ‚ÑÑ Ñ‚Ð°Ðº, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¾Ð½Ð¸ Ð½Ðµ Ð¿Ñ€ÐµÐ²Ñ‹ÑˆÐ°Ð»Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÑÐ° Ð¸Ð»Ð¸ / Ð¸ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð»Ð¸ Ð±Ð¾Ð»ÐµÐµ Ð´ÐµÑÑÑ‚Ð¸ Ð²ÐµÐ±-ÑÐ°Ð¹Ñ‚Ð¾Ð². Ð¢Ð¾ ÐµÑÑ‚ÑŒ ÑÐµÐ°Ð½Ñ ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ÑÑ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð½Ñ‹Ð¼, ÐµÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¿Ð¾ÑÐµÑ‚Ð¸Ð» Ð´ÐµÑÑÑ‚ÑŒ Ð²ÐµÐ±-ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð¸Ð»Ð¸ ÐµÑÐ»Ð¸ ÑÐµÐ°Ð½Ñ Ð´Ð»Ð¸Ñ‚ÑÑ Ð±Ð¾Ð»ÐµÐµ Ñ‚Ñ€Ð¸Ð´Ñ†Ð°Ñ‚Ð¸ Ð¼Ð¸Ð½ÑƒÑ‚.**  \n",
    "\n",
    "**Ð’ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ ÐµÑÑ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿ÑƒÑÑ‚Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹, ÑÑ‚Ð¾ Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚, Ñ‡Ñ‚Ð¾ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÑÐµÐ°Ð½ÑÑ‹ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ Ð¼ÐµÐ½ÐµÐµ Ð´ÐµÑÑÑ‚Ð¸ Ð²ÐµÐ±-ÑÐ°Ð¹Ñ‚Ð¾Ð². Ð—Ð°Ð¼ÐµÐ½Ð¸Ñ‚Ðµ Ð¿ÑƒÑÑ‚Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð½Ð° 0 Ð¸ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚Ðµ Ñ‚Ð¸Ð¿Ñ‹ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð² Ð½Ð° integer. Ð¢Ð°ÐºÐ¶Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð²ÐµÐ±-ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ, ÐºÐ°Ðº ÑÑ‚Ð¾ Ð²Ñ‹Ð³Ð»ÑÐ´Ð¸Ñ‚:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-12 16:25:10</td>\n",
       "      <td>api.bing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-12 16:25:11</td>\n",
       "      <td>api.bing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>api.bing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>www.google.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>www.google.fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp           site\n",
       "0  2013-02-12 16:25:10   api.bing.com\n",
       "1  2013-02-12 16:25:11   api.bing.com\n",
       "2  2013-02-12 16:32:10   api.bing.com\n",
       "3  2013-02-12 16:32:11  www.google.fr\n",
       "4  2013-02-12 16:32:24  www.google.fr"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alice = pd.read_csv('data/train/Alice_log.csv')\n",
    "df_alice.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-18 10:19:27</td>\n",
       "      <td>ocsp.digicert.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-18 10:19:28</td>\n",
       "      <td>ocsp.digicert.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-18 10:19:28</td>\n",
       "      <td>clients1.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-18 10:19:29</td>\n",
       "      <td>gtglobal-ocsp.geotrust.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-18 10:19:29</td>\n",
       "      <td>clients1.google.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                        site\n",
       "0  2013-12-18 10:19:27           ocsp.digicert.com\n",
       "1  2013-12-18 10:19:28           ocsp.digicert.com\n",
       "2  2013-12-18 10:19:28         clients1.google.com\n",
       "3  2013-12-18 10:19:29  gtglobal-ocsp.geotrust.com\n",
       "4  2013-12-18 10:19:29         clients1.google.com"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user0010 = pd.read_csv('data/train/other_user_logs/user0010.csv')\n",
    "df_user0010.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>site6</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>952</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57     55 2013-01-12 08:05:57      0   \n",
       "54843          56 2013-01-12 08:37:23     55 2013-01-12 08:37:23     56   \n",
       "77292         946 2013-01-12 08:50:13    946 2013-01-12 08:50:14    951   \n",
       "114021        945 2013-01-12 08:50:17    948 2013-01-12 08:50:17    949   \n",
       "146670        947 2013-01-12 08:50:20    950 2013-01-12 08:50:20    948   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843      2013-01-12 09:07:07     55 2013-01-12 09:07:09      0   \n",
       "77292      2013-01-12 08:50:15    946 2013-01-12 08:50:15    946   \n",
       "114021     2013-01-12 08:50:18    948 2013-01-12 08:50:18    945   \n",
       "146670     2013-01-12 08:50:20    947 2013-01-12 08:50:21    950   \n",
       "\n",
       "                         time5  site6               time6  site7  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843                      NaT      0                 NaT      0   \n",
       "77292      2013-01-12 08:50:16    945 2013-01-12 08:50:16    948   \n",
       "114021     2013-01-12 08:50:18    946 2013-01-12 08:50:18    947   \n",
       "146670     2013-01-12 08:50:21    952 2013-01-12 08:50:21    946   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843                      NaT      0                 NaT      0   \n",
       "77292      2013-01-12 08:50:16    784 2013-01-12 08:50:16    949   \n",
       "114021     2013-01-12 08:50:19    945 2013-01-12 08:50:19    946   \n",
       "146670     2013-01-12 08:50:21    951 2013-01-12 08:50:22    946   \n",
       "\n",
       "                         time9  site10              time10  \n",
       "session_id                                                  \n",
       "21669                      NaT       0                 NaT  \n",
       "54843                      NaT       0                 NaT  \n",
       "77292      2013-01-12 08:50:17     946 2013-01-12 08:50:17  \n",
       "114021     2013-01-12 08:50:19     946 2013-01-12 08:50:20  \n",
       "146670     2013-01-12 08:50:22     947 2013-01-12 08:50:22  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2297 entries, 251175 to 244233\n",
      "Data columns (total 21 columns):\n",
      "site1     2297 non-null int32\n",
      "time1     2297 non-null datetime64[ns]\n",
      "site2     2297 non-null int32\n",
      "time2     2294 non-null datetime64[ns]\n",
      "site3     2297 non-null int32\n",
      "time3     2287 non-null datetime64[ns]\n",
      "site4     2297 non-null int32\n",
      "time4     2286 non-null datetime64[ns]\n",
      "site5     2297 non-null int32\n",
      "time5     2280 non-null datetime64[ns]\n",
      "site6     2297 non-null int32\n",
      "time6     2273 non-null datetime64[ns]\n",
      "site7     2297 non-null int32\n",
      "time7     2269 non-null datetime64[ns]\n",
      "site8     2297 non-null int32\n",
      "time8     2263 non-null datetime64[ns]\n",
      "site9     2297 non-null int32\n",
      "time9     2262 non-null datetime64[ns]\n",
      "site10    2297 non-null int32\n",
      "time10    2258 non-null datetime64[ns]\n",
      "target    2297 non-null int64\n",
      "dtypes: datetime64[ns](10), int32(10), int64(1)\n",
      "memory usage: 305.1 KB\n"
     ]
    }
   ],
   "source": [
    "train_df[train_df['target']==1].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "      <th>timestamp2</th>\n",
       "      <th>site2</th>\n",
       "      <th>timestamp3</th>\n",
       "      <th>site3</th>\n",
       "      <th>timestamp4</th>\n",
       "      <th>site4</th>\n",
       "      <th>timestamp5</th>\n",
       "      <th>site5</th>\n",
       "      <th>timestamp6</th>\n",
       "      <th>site6</th>\n",
       "      <th>timestamp7</th>\n",
       "      <th>site7</th>\n",
       "      <th>timestamp8</th>\n",
       "      <th>site8</th>\n",
       "      <th>timestamp9</th>\n",
       "      <th>site9</th>\n",
       "      <th>timestamp10</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-12 16:25:10</td>\n",
       "      <td>270</td>\n",
       "      <td>2013-02-12 16:25:11</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-12 16:25:11</td>\n",
       "      <td>270</td>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>270</td>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2013-02-12 16:32:28</td>\n",
       "      <td>7832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2013-02-12 16:32:28</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:29</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2013-02-12 16:32:28</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:29</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2013-02-12 16:32:34</td>\n",
       "      <td>7832.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  site          timestamp2   site2          timestamp3  \\\n",
       "0 2013-02-12 16:25:10   270 2013-02-12 16:25:11   270.0 2013-02-12 16:32:10   \n",
       "1 2013-02-12 16:25:11   270 2013-02-12 16:32:10   270.0 2013-02-12 16:32:11   \n",
       "2 2013-02-12 16:32:10   270 2013-02-12 16:32:11    21.0 2013-02-12 16:32:24   \n",
       "3 2013-02-12 16:32:11    21 2013-02-12 16:32:24    21.0 2013-02-12 16:32:25   \n",
       "4 2013-02-12 16:32:24    21 2013-02-12 16:32:25  7832.0 2013-02-12 16:32:25   \n",
       "\n",
       "    site3          timestamp4   site4          timestamp5   site5  \\\n",
       "0   270.0 2013-02-12 16:32:11    21.0 2013-02-12 16:32:24    21.0   \n",
       "1    21.0 2013-02-12 16:32:24    21.0 2013-02-12 16:32:25  7832.0   \n",
       "2    21.0 2013-02-12 16:32:25  7832.0 2013-02-12 16:32:25    21.0   \n",
       "3  7832.0 2013-02-12 16:32:25    21.0 2013-02-12 16:32:26  7832.0   \n",
       "4    21.0 2013-02-12 16:32:26  7832.0 2013-02-12 16:32:27    30.0   \n",
       "\n",
       "           timestamp6   site6          timestamp7   site7          timestamp8  \\\n",
       "0 2013-02-12 16:32:25  7832.0 2013-02-12 16:32:25    21.0 2013-02-12 16:32:26   \n",
       "1 2013-02-12 16:32:25    21.0 2013-02-12 16:32:26  7832.0 2013-02-12 16:32:27   \n",
       "2 2013-02-12 16:32:26  7832.0 2013-02-12 16:32:27    30.0 2013-02-12 16:32:27   \n",
       "3 2013-02-12 16:32:27    30.0 2013-02-12 16:32:27  7832.0 2013-02-12 16:32:27   \n",
       "4 2013-02-12 16:32:27  7832.0 2013-02-12 16:32:27    29.0 2013-02-12 16:32:28   \n",
       "\n",
       "    site8          timestamp9   site9         timestamp10  site10  \n",
       "0  7832.0 2013-02-12 16:32:27    30.0 2013-02-12 16:32:27  7832.0  \n",
       "1    30.0 2013-02-12 16:32:27  7832.0 2013-02-12 16:32:27    29.0  \n",
       "2  7832.0 2013-02-12 16:32:27    29.0 2013-02-12 16:32:28  7832.0  \n",
       "3    29.0 2013-02-12 16:32:28  7832.0 2013-02-12 16:32:29    37.0  \n",
       "4  7832.0 2013-02-12 16:32:29    37.0 2013-02-12 16:32:34  7832.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT = 30\n",
    "\n",
    "df_alice = pd.read_csv('data/train/Alice_log.csv')\n",
    "df_alice['timestamp'] = df_alice['timestamp'].apply(pd.to_datetime)\n",
    "for i in range(-1, -10, -1):\n",
    "    df_alice['timestamp' + str(-i+1)] = df_alice['timestamp'].shift(i)\n",
    "    df_alice['site' + str(-i+1)] = df_alice['site'].shift(i)\n",
    "    \n",
    "    df_alice['dt'] = (df_alice['timestamp' + str(-i+1)] - df_alice['timestamp']).dt.seconds / 60\n",
    "    df_alice.loc[df_alice['dt']>DT, ['timestamp' + str(-i+1), 'site' + str(-i+1)]] = None\n",
    "\n",
    "del df_alice['dt']\n",
    "\n",
    "to_int = dict(zip(sites_dict['site'], sites_dict.index))\n",
    "for col in df_alice.columns:\n",
    "    if 'site' in col:\n",
    "        df_alice[col] = df_alice[col].map(to_int)\n",
    "\n",
    "# df_alice['dt'] = (df_alice['timestamp'].shift(-1) - df_alice['timestamp']).dt.seconds / 60\n",
    "# df_alice['dt_10sites'] = (df_alice['timestamp'].shift(-10) - df_alice['timestamp']).dt.seconds / 60\n",
    "df_alice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
