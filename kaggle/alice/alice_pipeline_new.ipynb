{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set desired options\n",
    "\n",
    "from __future__ import division, print_function\n",
    "# Disable Anaconda warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, FastICA, FactorAnalysis\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances, manhattan_distances, euclidean_distances\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function for writing predictions to a file\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(cv_res):\n",
    "    import re \n",
    "    \n",
    "    results = pd.DataFrame(cv_res['params'])\n",
    "    results['mean_score'] = cv_res['mean_test_score']\n",
    "    results['std_score'] = cv_res['std_test_score']\n",
    "    results['rank'] = cv_res['rank_test_score']\n",
    "#     results = results.sort_values('rank')\n",
    "    \n",
    "    n_splits = len(cv_res['split0_test_score'])\n",
    "    cv_results = np.r_[[clf.cv_results_[k] for k in clf.cv_results_.keys() if re.match(r'split\\d+_test', k)]]\n",
    "    cv_results = pd.DataFrame(cv_results)\n",
    "    melted = cv_results.melt()\n",
    "    melted['split_num'] = list(range(cv_results.shape[0])) * cv_results.shape[1]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10), gridspec_kw={'width_ratios':[2, 1]})\n",
    "    \n",
    "    sns.barplot(x='split_num', y='value', hue='variable', data=melted, ax=axes[0, 0]);\n",
    "    axes[0, 0].set_ylim(melted['value'].min()-.01, 1);\n",
    "    \n",
    "    sns.violinplot(x='variable', y='value', hue='variable', data=cv_results.melt(), ax=axes[0, 1], dodge=False);\n",
    "    sns.boxplot(x='variable', y='value', data=melted, ax=axes[1, 0]);\n",
    "    sns.barplot(x=results.index, y='std_score', data=results, ax=axes[1, 1]);\n",
    "    \n",
    "    sns.despine()\n",
    "    return results, cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites total: 48371\n"
     ]
    }
   ],
   "source": [
    "# Load websites dictionary\n",
    "with open(r\"data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# Create dataframe for the dictionary\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "\n",
    "# sites_dict['zone'] = sites_dict['site'].str.split('.').apply(lambda x: x[-1])\n",
    "# sites_dict.loc[sites_dict['zone'].str.isnumeric(), 'zone'] = 'ip_address'\n",
    "# sites_dict['zone_le'] = LabelEncoder().fit_transform(sites_dict['zone'])\n",
    "\n",
    "print(u'Websites total:', sites_dict.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training and test data sets\n",
    "train_df = pd.read_csv('data/data_like_origin.csv',\n",
    "                      index_col=0)\n",
    "test_df = pd.read_csv('data/test_sessions.csv',\n",
    "                      index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch time1, ..., time10 columns to datetime type\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# Sort the data by time\n",
    "# train_df = train_df.sort_values(by='time1')\n",
    "train_df = train_df.sort_values(by='for_folds')\n",
    "train_df = train_df[train_df['time3'].notnull()]\n",
    "\n",
    "\n",
    "# Change site1, ..., site10 columns type to integer and fill NA-values with zeros\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target variable\n",
    "y_train = train_df['target']\n",
    "\n",
    "# United dataframe of the initial data \n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# Dataframe with indices of visited websites in session\n",
    "full_sites = full_df[sites]\n",
    "\n",
    "# Index to split the training and test data sets\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_features(df):\n",
    "    time_df = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    hour = df['time1'].dt.hour\n",
    "    time_df['hour'] = hour\n",
    "    time_df['day_'] = df['time1'].dt.day\n",
    "    time_df['month'] = df['time1'].dt.month\n",
    "    time_df['year'] = df['time1'].dt.year\n",
    "    time_df['myear'] = df['time1'].dt.year * 12 + df['time1'].dt.month\n",
    "    \n",
    "    time_df['morning'] = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "    time_df['day'] = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "    time_df['evening'] = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "\n",
    "    time_df['min'] = df['time1'] \n",
    "    time_df['max'] = df[times].max(axis=1)\n",
    "\n",
    "    for px in ['min', 'max']:\n",
    "        time_df['minutes'] = time_df[px].dt.hour * 60 + time_df[px].dt.minute\n",
    "        time_df['sin_'+px] = np.sin(2*np.pi*time_df['minutes']/1440.)\n",
    "        time_df['cos_'+px] = np.cos(2*np.pi*time_df['minutes']/1440.)\n",
    "\n",
    "    time_df['dow'] = time_df['min'].apply(lambda ts: ts.date().weekday())\n",
    "    time_df['weekend'] = (time_df['dow'] > 4).astype('int')\n",
    "    time_df['n_null'] = df[times].isnull().sum(axis=1)\n",
    "\n",
    "    time_df['dt'] = time_df['max'] - time_df['min']\n",
    "    for time in times[1:]:\n",
    "        dt_ = (df[time] - time_df['min']).fillna(time_df['dt'])\n",
    "        time_df['dt_' + time] = np.log1p(np.abs(dt_.astype('timedelta64[s]')))\n",
    "    time_df['dt'] = np.log1p(np.abs(time_df['dt'].astype('timedelta64[s]')))\n",
    "    time_df['dt_mean'] = time_df[['dt_' + time for time in times[1:]]].mean(axis=1)\n",
    "    time_df['dt_std'] = time_df[['dt_' + time for time in times[1:]]].std(axis=1)\n",
    "    time_df['dt_var'] = time_df[['dt_' + time for time in times[1:]]].var(axis=1)\n",
    "    \n",
    "    s_columns = [col for col in time_df.columns if time_df[col].dtype != '<M8[ns]']\n",
    "    \n",
    "#     s_scaler = StandardScaler()\n",
    "#     time_df[s_columns] = s_scaler.fit_transform(time_df[s_columns])\n",
    "\n",
    "    time_df = time_df.drop(['min', 'max'], axis=1)\n",
    "    time_df = time_df.drop(['dt_' + time for time in times[1:]], axis=1)\n",
    "    \n",
    "    for col in time_df.columns:\n",
    "        time_df[col] = time_df[col].fillna(time_df[col].mean())\n",
    "\n",
    "    return time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hour', 'day_', 'month', 'year', 'myear', 'morning', 'day', 'evening',\n",
      "       'minutes', 'sin_min', 'cos_min', 'sin_max', 'cos_max', 'dow', 'weekend',\n",
      "       'n_null', 'dt', 'dt_mean', 'dt_std', 'dt_var'],\n",
      "      dtype='object')\n",
      "Index(['spl1', 'spl2', 'spl3', 'spl4'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "full_time = get_time_features(full_df[times])\n",
    "ft_columns = full_time.columns\n",
    "\n",
    "hours_dum = pd.get_dummies(pd.cut(full_time['hour'], bins=4, labels=['1', '2', '3', '4']), prefix='spl', prefix_sep='')\n",
    "full_time = pd.concat([full_time, hours_dum], axis=1)\n",
    "print(ft_columns)\n",
    "print(hours_dum.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get site features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sites_tf = full_sites.copy()\n",
    "\n",
    "for col in full_sites_tf.columns:\n",
    "    full_sites_tf[col] = full_sites_tf[col].map(sites_dict.site)\n",
    "\n",
    "full_sites_tf = full_sites_tf.fillna('')\n",
    "# df_tf_col = full_sites_tf.apply(lambda x: '.'.join([i for i in x if len(i)>0]), axis=1)\n",
    "# df_tf_col = df_tf_col.str.split('[.-]').str.join(' ')\n",
    "\n",
    "text_cols = ['sites', 'sites_ds', 'sites_dms', 'sites_num']\n",
    "df_text = pd.DataFrame(columns=text_cols)\n",
    "\n",
    "df_text['sites'] = full_sites_tf.apply(lambda x: ' '.join([i for i in x if len(i)>0]), axis=1)\n",
    "df_text['sites_ds'] = df_text['sites'].str.split('[.]').str.join(' ')   # dot split\n",
    "df_text['sites_dms'] = df_text['sites'].str.split('[.-]').str.join(' ')   # dot, minus split\n",
    "df_text['sites_num'] = full_sites.astype('str').apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270 270 270 21 21 7832 21 7832 30 7832 29 7832...</td>\n",
       "      <td>Alice_log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63 66 53 52 49 52 21 196 52 197 52 55 56 55 58...</td>\n",
       "      <td>user2227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 63 167 23 21 23 22 812 22 676 39 21 21 679 2...</td>\n",
       "      <td>user1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66 781 781 781 781 781 167 167 167 167 359 167...</td>\n",
       "      <td>user2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 66 67 68 71 70 69 21 21 22 23 21 23 22 973 3...</td>\n",
       "      <td>user3733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data       user\n",
       "0  270 270 270 21 21 7832 21 7832 30 7832 29 7832...  Alice_log\n",
       "1  63 66 53 52 49 52 21 196 52 197 52 55 56 55 58...   user2227\n",
       "2  1 63 167 23 21 23 22 812 22 676 39 21 21 679 2...   user1666\n",
       "3  66 781 781 781 781 781 167 167 167 167 359 167...   user2458\n",
       "4  1 66 67 68 71 70 69 21 21 22 23 21 23 22 973 3...   user3733"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = pd.read_csv('data/data_users.csv', index_col=0)\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs_tfidf = TfidfVectorizer()\n",
    "# u_df = pairs_tfidf.fit_transform(users_df['data'])\n",
    "\n",
    "# s_df = pairs_tfidf.transform(df_text['sites_num'])\n",
    "# # s_df = cosine_similarity(s_df, u_df, dense_output=True)\n",
    "# s_df = pd.DataFrame(cosine_similarity(s_df, u_df), columns=users_df['user'], index=df_text.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sites</th>\n",
       "      <th>sites_ds</th>\n",
       "      <th>sites_dms</th>\n",
       "      <th>sites_num</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>myear</th>\n",
       "      <th>morning</th>\n",
       "      <th>...</th>\n",
       "      <th>weekend</th>\n",
       "      <th>n_null</th>\n",
       "      <th>dt</th>\n",
       "      <th>dt_mean</th>\n",
       "      <th>dt_std</th>\n",
       "      <th>dt_var</th>\n",
       "      <th>spl1</th>\n",
       "      <th>spl2</th>\n",
       "      <th>spl3</th>\n",
       "      <th>spl4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>fr.wikipedia.org fr.wikipedia.org meta.wikimed...</td>\n",
       "      <td>fr wikipedia org fr wikipedia org meta wikimed...</td>\n",
       "      <td>fr wikipedia org fr wikipedia org meta wikimed...</td>\n",
       "      <td>177 177 178 177 48 0 0 0 0 0</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>24172</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.779123</td>\n",
       "      <td>3.974791</td>\n",
       "      <td>1.206813</td>\n",
       "      <td>1.456397</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sites  \\\n",
       "91  fr.wikipedia.org fr.wikipedia.org meta.wikimed...   \n",
       "\n",
       "                                             sites_ds  \\\n",
       "91  fr wikipedia org fr wikipedia org meta wikimed...   \n",
       "\n",
       "                                            sites_dms  \\\n",
       "91  fr wikipedia org fr wikipedia org meta wikimed...   \n",
       "\n",
       "                       sites_num  hour  day_  month  year  myear  morning  \\\n",
       "91  177 177 178 177 48 0 0 0 0 0    13    24      4  2014  24172        0   \n",
       "\n",
       "    ...   weekend  n_null        dt   dt_mean    dt_std    dt_var  spl1  spl2  \\\n",
       "91  ...         0       5  4.779123  3.974791  1.206813  1.456397     0     1   \n",
       "\n",
       "    spl3  spl4  \n",
       "91     0     0  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.concat([df_text.iloc[:idx_split], full_time.iloc[:idx_split]], axis=1)\n",
    "X_test = pd.concat([df_text.iloc[idx_split:], full_time.iloc[idx_split:]], axis=1)\n",
    "\n",
    "X_train.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sites', 'sites_ds', 'sites_dms', 'sites_num', 'hour', 'day_', 'month',\n",
       "       'year', 'myear', 'morning', 'day', 'evening', 'minutes', 'sin_min',\n",
       "       'cos_min', 'sin_max', 'cos_max', 'dow', 'weekend', 'n_null', 'dt',\n",
       "       'dt_mean', 'dt_std', 'dt_var', 'spl1', 'spl2', 'spl3', 'spl4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class TransformToUsers(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "#         self.max_df = max_df\n",
    "        self.pairs_tfidf = TfidfVectorizer(max_df=.75)\n",
    "        self.u_df = self.pairs_tfidf.fit_transform(users_df['data'])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "#         print(self.max_df)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        s_df = self.pairs_tfidf.transform(X)\n",
    "        return cosine_distances(s_df, self.u_df)\n",
    "#         return cosine_similarity(s_df, self.u_df, dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_text_tfidf = Pipeline([\n",
    "                ('select', TextSelector(key='sites_num')),\n",
    "#                 ('tfidf', TfidfVectorizer(max_df=0.2, max_features=8000, smooth_idf=True, sublinear_tf=True)),\n",
    "                ('tfidf', TfidfVectorizer(max_df=0.15, max_features=25000, smooth_idf=True, sublinear_tf=True))\n",
    "                ])\n",
    "\n",
    "pl_text_count = Pipeline([\n",
    "                ('select', TextSelector(key='sites_num')),\n",
    "                ('count', CountVectorizer(max_df=0.2))\n",
    "                ])\n",
    "\n",
    "pl_text_users = Pipeline([\n",
    "                ('select', TextSelector(key='sites_num')),\n",
    "                ('transf', TransformToUsers())\n",
    "                ])\n",
    "\n",
    "# pl_text_users = Pipeline([\n",
    "#                 ('select', TextSelector(key=users_df['user'].values))\n",
    "#                 ])\n",
    "\n",
    "pl_time = Pipeline([\n",
    "                ('select', NumberSelector(key=ft_columns)),\n",
    "#                 ('scale', StandardScaler())\n",
    "                ])\n",
    "\n",
    "pl_time_scale = Pipeline([\n",
    "                ('select', NumberSelector(key=ft_columns)),\n",
    "                ('scale', StandardScaler())\n",
    "                ])\n",
    "\n",
    "pl_ica = Pipeline([\n",
    "            ('select', NumberSelector(key=ft_columns)),\n",
    "            ('scale', StandardScaler()),\n",
    "#             ('ica', FastICA(n_components=3, random_state=17)) \n",
    "#             ('ica', GaussianRandomProjection(n_components=3, eps=0.1, random_state=17))\n",
    "            ('ica', SparseRandomProjection(n_components=3, dense_output=True, random_state=17))\n",
    "#             ('ica', FactorAnalysis(n_components=3, random_state=17))\n",
    "#             ('ica', TruncatedSVD(n_components=3, random_state=17))\n",
    "#             ('ica', PCA(n_components=3, random_state=17))\n",
    "            ])\n",
    "\n",
    "feats = FeatureUnion([\n",
    "                    ('pl_text', pl_text_tfidf), \n",
    "#                     ('pl_time', pl_time),\n",
    "                    ('pl_time_scale', pl_time_scale)\n",
    "                    ])\n",
    "\n",
    "\n",
    "feats_ns = FeatureUnion([\n",
    "                    ('pl_text', pl_text_tfidf), \n",
    "                    ('pl_time', pl_time),\n",
    "#                     ('pl_time_scale', pl_time_scale)\n",
    "                    ])\n",
    "\n",
    "feats_all = FeatureUnion([\n",
    "                    ('pl_text', pl_text_tfidf), \n",
    "                    ('pl_time', pl_time),\n",
    "                    ('pl_time_scale', pl_time_scale),\n",
    "#                     ('pl_ica', pl_ica),\n",
    "                    ('similar', pl_text_users)\n",
    "                    ])\n",
    "\n",
    "\n",
    "pl = Pipeline([\n",
    "                ('feats', feats),\n",
    "                ('clf', LogisticRegression(C=3, random_state=17))\n",
    "              ])\n",
    "\n",
    "pl_ns = Pipeline([\n",
    "                ('feats', feats_ns),\n",
    "                ('clf', LogisticRegression(C=3, random_state=17))\n",
    "              ])\n",
    "\n",
    "pl_all = Pipeline([\n",
    "                ('feats', feats_all),\n",
    "                ('clf', LogisticRegression(C=3, random_state=17))\n",
    "#                 ('clf', LogisticRegression(C=1.4, random_state=17))\n",
    "#                 ('clf', lgb.LGBMClassifier(random_state=17))\n",
    "              ])\n",
    "\n",
    "# pl.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.LGBMClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf',\n",
       " 'clf__C',\n",
       " 'clf__class_weight',\n",
       " 'clf__dual',\n",
       " 'clf__fit_intercept',\n",
       " 'clf__intercept_scaling',\n",
       " 'clf__max_iter',\n",
       " 'clf__multi_class',\n",
       " 'clf__n_jobs',\n",
       " 'clf__penalty',\n",
       " 'clf__random_state',\n",
       " 'clf__solver',\n",
       " 'clf__tol',\n",
       " 'clf__verbose',\n",
       " 'clf__warm_start']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[z for z in pl_all.get_params().keys() if 'clf' in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed: 12.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed: 12.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 3} 0.9289656277908451\n",
      "CPU times: user 19min 40s, sys: 2min 48s, total: 22min 29s\n",
      "Wall time: 29min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#           ['month', 'dow', 'dt', 'dt_std', 'dt_var'],\n",
    "#                ['spl1',  'spl2',  'spl3',  'spl4', 'sin_min', 'cos_min'],\n",
    "\n",
    "# not_scale_cols = ['spl1',  'spl2',  'spl3',  'spl4', 'sin_min', 'cos_min']\n",
    "# scale_cols = ['month', 'dow', 'dt', 'dt_std', 'dt_var']\n",
    "\n",
    "ns_cols = ['spl1',  'spl2',  'spl3',  'spl4', 'sin_min']\n",
    "s_cols = ['month', 'dow', 'dt', 'dt_std', 'dt_var']\n",
    "ica_cols = ['hour', 'day_', 'month', 'year', 'myear', 'minutes', 'sin_min','cos_min', 'sin_max', 'cos_max', 'dow', \n",
    "            'weekend', 'n_null', 'dt','dt_mean', 'dt_std', 'dt_var', 'spl1', 'spl2', 'spl3', 'spl4']\n",
    "\n",
    "params = {'clf__C':[3]\n",
    "#     'feats__similar__transf__max_df':[0.7],\n",
    "#     'feats__similar__transf__min_df_':[.001],\n",
    "#     'feats__similar__transf__max_features_':[100]\n",
    "#              'clf__max_depth': [3],\n",
    "#                 'clf__n_estimators':[200],\n",
    "#                 'clf__learning_rate':[0.01]\n",
    "#             'feats__pl_ica__ica__n_components':range(1, 6),\n",
    "#             'feats__pl_time__select__key': [],\n",
    "#                 'feats__pl_text__tfidf__max_features': [5000, 8000, 10000, 15000, 25000, 50000],\n",
    "#                  'feats__pl_text__tfidf__max_df': [.15, .5],\n",
    "#                  'feats__pl_text__tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "#                 'feats__pl_text__tfidf__smooth_idf': [True, False],\n",
    "#                 'feats__pl_text__tfidf__sublinear_tf': [True, False],\n",
    "        }\n",
    "\n",
    "time_split = TimeSeriesSplit(n_splits=2)\n",
    "\n",
    "clf = GridSearchCV(pl_all.set_params(feats__pl_time__select__key=ns_cols,\n",
    "                                    feats__pl_time_scale__select__key=s_cols), \n",
    "                   params, cv=time_split, verbose=1, scoring='roc_auc', n_jobs=2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92896563])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 200} 0.958313378713713\n",
    "{'clf__max_depth': 3, 'clf__n_estimators': 200} 0.9477082191663228\n",
    "{'clf__max_depth': 3} 0.9470262411800207\n",
    "{'clf__max_depth': 4} 0.9454569512683295"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'clf__C': 1.4} 0.9232859209643944  cossim\n",
    "{'clf__C': 1.4} 0.9309017654918317 cosdist\n",
    "{'clf__C': 1.4} 0.9269658614723381 eucdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'clf__C': 1.4} 0.9339107346916623\n",
    "{'ica__n_components': 1} 0.933911000055746 (n=3,  0.9339131795134564)\n",
    "{'grp__n_components': 1} 0.8650250656020491\n",
    "SparseRandomProjection   0.933438217344764 (9336488888168811)\n",
    "FactorAnalysis 0.9332971246539231\n",
    "TruncatedSVD 0.8305739744157796\n",
    "PCA 0.9332517772225442  (0.9336260979700839)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To scale or not to scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: hour       Score_s:0.90672 Score_ns:0.90664 Scale: True \n",
      "Column: day_       Score_s:0.87261 Score_ns:0.86138 Scale: True \n",
      "Column: month      Score_s:0.87545 Score_ns:0.87553 Scale: False \n",
      "Column: year       Score_s:0.87723 Score_ns:0.84114 Scale: True \n",
      "Column: myear      Score_s:0.87606 Score_ns:0.70731 Scale: True \n",
      "Column: morning    Score_s:0.92410 Score_ns:0.92411 Scale: False \n",
      "Column: day        Score_s:0.92675 Score_ns:0.92638 Scale: True \n",
      "Column: evening    Score_s:0.87861 Score_ns:0.87820 Scale: True \n",
      "Column: minutes    Score_s:0.90683 Score_ns:0.90409 Scale: True \n",
      "Column: sin_min    Score_s:0.91757 Score_ns:0.91758 Scale: False \n",
      "Column: cos_min    Score_s:0.88261 Score_ns:0.88261 Scale: False \n",
      "Column: sin_max    Score_s:0.91747 Score_ns:0.91747 Scale: False \n",
      "Column: cos_max    Score_s:0.88274 Score_ns:0.88274 Scale: False \n",
      "Column: dow        Score_s:0.87561 Score_ns:0.87537 Scale: True \n",
      "Column: weekend    Score_s:0.86175 Score_ns:0.86448 Scale: False \n",
      "Column: n_null     Score_s:0.87416 Score_ns:0.87413 Scale: True \n",
      "Column: dt         Score_s:0.87476 Score_ns:0.87458 Scale: True \n",
      "Column: dt_mean    Score_s:0.87493 Score_ns:0.87480 Scale: True \n",
      "Column: dt_std     Score_s:0.87552 Score_ns:0.87541 Scale: True \n",
      "Column: dt_var     Score_s:0.87550 Score_ns:0.87539 Scale: True \n",
      "CPU times: user 5min 3s, sys: 2min 1s, total: 7min 4s\n",
      "Wall time: 12min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_split = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "ft_cols = np.array(ft_columns)\n",
    "\n",
    "mask_cols = np.zeros(len(ft_columns), dtype='bool')\n",
    "\n",
    "cv_cols = ['cv' + str(j) for j in range(10)]\n",
    "results = pd.DataFrame(np.zeros((n_cols*2, 12)), columns=['Col', 'Score'] + cv_cols)\n",
    "\n",
    "for i in range(n_cols):\n",
    "    mask_cols[i] = True\n",
    "    \n",
    "    results.loc[i, 'Col'] = ft_cols[i]\n",
    "    ts_cols = ft_cols[mask_cols]\n",
    "\n",
    "    results.loc[i, cv_cols] = cross_val_score(pl.set_params(feats__pl_time_scale__select__key=ts_cols), \n",
    "                      X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    results.loc[i+n_cols, cv_cols] = cross_val_score(pl_ns.set_params(feats__pl_time__select__key=ts_cols), \n",
    "                      X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "    s1 = results.loc[i, cv_cols].mean()\n",
    "    s2 = results.loc[i+n_cols, cv_cols].mean()\n",
    "    \n",
    "    results.loc[i, 'Score'] = s1\n",
    "    results.loc[i+n_cols, 'Score'] = s2\n",
    "\n",
    "    print(f'Column: {ft_cols[i]:<10} Score_s:{s1:.5f} Score_ns:{s2:.5f} Scale: {s1 > s2} ')\n",
    "    mask_cols[i] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column: hour       Score_s:0.90672 Score_ns:0.90664 Scale: True  \n",
    "Column: day_       Score_s:0.87261 Score_ns:0.86138 Scale: True  \n",
    "Column: month      Score_s:0.87545 Score_ns:0.87553 Scale: False  \n",
    "Column: year       Score_s:0.87723 Score_ns:0.84114 Scale: True  \n",
    "Column: myear      Score_s:0.87606 Score_ns:0.70731 Scale: True  \n",
    "Column: morning    Score_s:0.92410 Score_ns:0.92411 Scale: False  \n",
    "Column: day        Score_s:0.92675 Score_ns:0.92638 Scale: True  \n",
    "Column: evening    Score_s:0.87861 Score_ns:0.87820 Scale: True  \n",
    "Column: minutes    Score_s:0.90683 Score_ns:0.90409 Scale: True  \n",
    "Column: sin_min    Score_s:0.91757 Score_ns:0.91758 Scale: False  \n",
    "Column: cos_min    Score_s:0.88261 Score_ns:0.88261 Scale: False  \n",
    "Column: sin_max    Score_s:0.91747 Score_ns:0.91747 Scale: False  \n",
    "Column: cos_max    Score_s:0.88274 Score_ns:0.88274 Scale: False  \n",
    "Column: dow        Score_s:0.87561 Score_ns:0.87537 Scale: True  \n",
    "Column: weekend    Score_s:0.86175 Score_ns:0.86448 Scale: False  \n",
    "Column: n_null     Score_s:0.87416 Score_ns:0.87413 Scale: True   \n",
    "Column: dt         Score_s:0.87476 Score_ns:0.87458 Scale: True  \n",
    "Column: dt_mean    Score_s:0.87493 Score_ns:0.87480 Scale: True  \n",
    "Column: dt_std     Score_s:0.87552 Score_ns:0.87541 Scale: True  \n",
    "Column: dt_var     Score_s:0.87550 Score_ns:0.87539 Scale: True  \n",
    "CPU times: user 5min 3s, sys: 2min 1s, total: 7min 4s   \n",
    "Wall time: 12min 31s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find useful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Column: dow        Score:0.83218 Use: False \n",
      "Column: dt_var     Score:0.82764 Use: False \n",
      "Column: myear      Score:0.82616 Use: False \n",
      "Column: dt_std     Score:0.82731 Use: False \n",
      "Column: month      Score:0.83527 Use: False \n",
      "Column: dt         Score:0.82778 Use: False \n",
      "Column: day_       Score:0.82146 Use: False \n",
      "Column: n_null     Score:0.82741 Use: False \n",
      "Column: dt_mean    Score:0.82736 Use: False \n",
      "Column: year       Score:0.81123 Use: False \n",
      "Column: hour       Score:0.88063 Use: True \n",
      "Column: minutes    Score:0.88034 Use: False \n",
      "------------------------------\n",
      "Iter 1\n",
      "Column: myear      Score:0.82659 Use: False \n",
      "Column: dt_std     Score:0.82758 Use: False \n",
      "Column: month      Score:0.83629 Use: False \n",
      "Column: hour       Score:0.88147 Use: True \n",
      "Column: dt_var     Score:0.88166 Use: True \n",
      "Column: day_       Score:0.87442 Use: False \n",
      "Column: dow        Score:0.88343 Use: True \n",
      "Column: n_null     Score:0.88411 Use: True \n",
      "Column: minutes    Score:0.88413 Use: False \n",
      "Column: year       Score:0.87060 Use: False \n",
      "Column: dt_mean    Score:0.88411 Use: False \n",
      "Column: dt         Score:0.88432 Use: True \n",
      "------------------------------\n",
      "Iter 2\n",
      "Column: year       Score:0.86617 Use: False \n",
      "Column: day_       Score:0.87842 Use: True \n",
      "Column: dt_var     Score:0.87861 Use: True \n",
      "Column: n_null     Score:0.87861 Use: False \n",
      "Column: dt_std     Score:0.87779 Use: False \n",
      "Column: dt_mean    Score:0.87812 Use: False \n",
      "Column: myear      Score:0.87764 Use: False \n",
      "Column: hour       Score:0.87387 Use: False \n",
      "Column: month      Score:0.87113 Use: False \n",
      "Column: dow        Score:0.87651 Use: False \n",
      "Column: dt         Score:0.87476 Use: False \n",
      "Column: minutes    Score:0.87409 Use: False \n",
      "------------------------------\n",
      "Iter 3\n",
      "Column: dt_mean    Score:0.82218 Use: False \n",
      "Column: dt_std     Score:0.82194 Use: False \n",
      "Column: day_       Score:0.82146 Use: False \n",
      "Column: dt_var     Score:0.82764 Use: False \n",
      "Column: minutes    Score:0.88075 Use: True \n",
      "Column: myear      Score:0.88101 Use: True \n",
      "Column: hour       Score:0.88082 Use: False \n",
      "Column: year       Score:0.86494 Use: False \n",
      "Column: n_null     Score:0.88177 Use: True \n",
      "Column: dow        Score:0.88470 Use: True \n",
      "Column: month      Score:0.86944 Use: False \n",
      "Column: dt         Score:0.88589 Use: True \n",
      "------------------------------\n",
      "Iter 4\n",
      "Column: dt_var     Score:0.80249 Use: False \n",
      "Column: minutes    Score:0.85387 Use: False \n",
      "Column: hour       Score:0.85405 Use: False \n",
      "Column: dow        Score:0.81381 Use: False \n",
      "Column: n_null     Score:0.80211 Use: False \n",
      "Column: day_       Score:0.80102 Use: False \n",
      "Column: dt         Score:0.81279 Use: False \n",
      "Column: dt_mean    Score:0.81247 Use: False \n",
      "Column: dt_std     Score:0.81197 Use: False \n",
      "Column: myear      Score:0.81153 Use: False \n",
      "Column: year       Score:0.81170 Use: False \n",
      "Column: month      Score:0.83527 Use: False \n",
      "------------------------------\n",
      "Iter 5\n",
      "Column: dt_mean    Score:0.82736 Use: False \n",
      "Column: day_       Score:0.82146 Use: False \n",
      "Column: hour       Score:0.88063 Use: True \n",
      "Column: myear      Score:0.88097 Use: True \n",
      "Column: month      Score:0.86485 Use: False \n",
      "Column: n_null     Score:0.88176 Use: True \n",
      "Column: dt_std     Score:0.88217 Use: True \n",
      "Column: minutes    Score:0.88202 Use: False \n",
      "Column: dt_var     Score:0.88232 Use: True \n",
      "Column: year       Score:0.86659 Use: False \n",
      "Column: dt         Score:0.88291 Use: True \n",
      "Column: dow        Score:0.88571 Use: True \n",
      "------------------------------\n",
      "Iter 6\n",
      "Column: dt_var     Score:0.85455 Use: False \n",
      "Column: dow        Score:0.85904 Use: False \n",
      "Column: day_       Score:0.85438 Use: False \n",
      "Column: dt_std     Score:0.86688 Use: False \n",
      "Column: dt_mean    Score:0.86686 Use: False \n",
      "Column: minutes    Score:0.86687 Use: False \n",
      "Column: n_null     Score:0.81370 Use: False \n",
      "Column: hour       Score:0.86592 Use: False \n",
      "Column: month      Score:0.81300 Use: False \n",
      "Column: myear      Score:0.81302 Use: False \n",
      "Column: year       Score:0.81254 Use: False \n",
      "Column: dt         Score:0.82778 Use: False \n",
      "------------------------------\n",
      "Iter 7\n",
      "Column: hour       Score:0.88063 Use: True \n",
      "Column: year       Score:0.86493 Use: False \n",
      "Column: day_       Score:0.87346 Use: False \n",
      "Column: minutes    Score:0.88034 Use: False \n",
      "Column: dt_var     Score:0.88111 Use: True \n",
      "Column: dow        Score:0.88286 Use: True \n",
      "Column: dt         Score:0.88355 Use: True \n",
      "Column: month      Score:0.89401 Use: True \n",
      "Column: dt_std     Score:0.89418 Use: True \n",
      "Column: n_null     Score:0.89468 Use: True \n",
      "Column: myear      Score:0.87050 Use: False \n",
      "Column: dt_mean    Score:0.89458 Use: False \n",
      "------------------------------\n",
      "Iter 8\n",
      "Column: month      Score:0.85769 Use: False \n",
      "Column: n_null     Score:0.86590 Use: False \n",
      "Column: myear      Score:0.85820 Use: False \n",
      "Column: dt_std     Score:0.86459 Use: False \n",
      "Column: dt         Score:0.86467 Use: False \n",
      "Column: dt_mean    Score:0.86451 Use: False \n",
      "Column: hour       Score:0.86385 Use: False \n",
      "Column: day_       Score:0.81932 Use: False \n",
      "Column: dow        Score:0.82272 Use: False \n",
      "Column: year       Score:0.81123 Use: False \n",
      "Column: dt_var     Score:0.82764 Use: False \n",
      "Column: minutes    Score:0.88075 Use: True \n",
      "------------------------------\n",
      "Iter 9\n",
      "Column: day_       Score:0.82197 Use: False \n",
      "Column: year       Score:0.81204 Use: False \n",
      "Column: myear      Score:0.82659 Use: False \n",
      "Column: month      Score:0.83629 Use: False \n",
      "Column: dt_std     Score:0.82758 Use: False \n",
      "Column: dt         Score:0.82754 Use: False \n",
      "Column: n_null     Score:0.82781 Use: False \n",
      "Column: minutes    Score:0.88168 Use: True \n",
      "Column: dt_var     Score:0.88191 Use: True \n",
      "Column: dow        Score:0.88386 Use: True \n",
      "Column: hour       Score:0.88348 Use: False \n",
      "Column: dt_mean    Score:0.88386 Use: False \n",
      "------------------------------\n",
      "Iter 10\n",
      "Column: myear      Score:0.80016 Use: False \n",
      "Column: n_null     Score:0.80162 Use: False \n",
      "Column: minutes    Score:0.85216 Use: False \n",
      "Column: dt         Score:0.80141 Use: False \n",
      "Column: dt_mean    Score:0.80102 Use: False \n",
      "Column: dt_var     Score:0.80124 Use: False \n",
      "Column: hour       Score:0.85236 Use: False \n",
      "Column: month      Score:0.80055 Use: False \n",
      "Column: year       Score:0.80701 Use: False \n",
      "Column: day_       Score:0.82146 Use: False \n",
      "Column: dt_std     Score:0.82731 Use: False \n",
      "Column: dow        Score:0.83218 Use: False \n",
      "------------------------------\n",
      "Iter 11\n",
      "Column: hour       Score:0.88063 Use: True \n",
      "Column: dt         Score:0.88174 Use: True \n",
      "Column: year       Score:0.86584 Use: False \n",
      "Column: dt_std     Score:0.88173 Use: False \n",
      "Column: minutes    Score:0.88161 Use: False \n",
      "Column: dow        Score:0.88351 Use: True \n",
      "Column: dt_mean    Score:0.88341 Use: False \n",
      "Column: dt_var     Score:0.88355 Use: False \n",
      "Column: month      Score:0.89399 Use: True \n",
      "Column: n_null     Score:0.89456 Use: True \n",
      "Column: myear      Score:0.87040 Use: False \n",
      "Column: day_       Score:0.87621 Use: False \n",
      "------------------------------\n",
      "Iter 12\n",
      "Column: myear      Score:0.86973 Use: False \n",
      "Column: dow        Score:0.86985 Use: False \n",
      "Column: n_null     Score:0.86679 Use: False \n",
      "Column: month      Score:0.86590 Use: False \n",
      "Column: hour       Score:0.86568 Use: False \n",
      "Column: minutes    Score:0.86580 Use: False \n",
      "Column: dt_var     Score:0.81262 Use: False \n",
      "Column: dt_std     Score:0.81248 Use: False \n",
      "Column: year       Score:0.81254 Use: False \n",
      "Column: dt         Score:0.82778 Use: False \n",
      "Column: dt_mean    Score:0.82736 Use: False \n",
      "Column: day_       Score:0.82146 Use: False \n",
      "------------------------------\n",
      "Iter 13\n",
      "Column: minutes    Score:0.88075 Use: True \n",
      "Column: dt         Score:0.88195 Use: True \n",
      "Column: month      Score:0.89144 Use: True \n",
      "Column: dt_std     Score:0.89145 Use: False \n",
      "Column: year       Score:0.86590 Use: False \n",
      "Column: dow        Score:0.89457 Use: True \n",
      "Column: hour       Score:0.89439 Use: False \n",
      "Column: day_       Score:0.87576 Use: False \n",
      "Column: dt_var     Score:0.89461 Use: False \n",
      "Column: dt_mean    Score:0.89456 Use: False \n",
      "Column: myear      Score:0.86951 Use: False \n",
      "Column: n_null     Score:0.89514 Use: True \n",
      "------------------------------\n",
      "Iter 14\n",
      "Column: dt_std     Score:0.86609 Use: False \n",
      "Column: myear      Score:0.86574 Use: False \n",
      "Column: minutes    Score:0.89063 Use: True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: dow        Score:0.89363 Use: True \n",
      "Column: year       Score:0.86963 Use: False \n",
      "Column: month      Score:0.89363 Use: False \n",
      "Column: dt_mean    Score:0.88427 Use: False \n",
      "Column: dt         Score:0.88469 Use: False \n",
      "Column: day_       Score:0.87692 Use: False \n",
      "Column: hour       Score:0.88301 Use: False \n",
      "Column: dt_var     Score:0.88399 Use: False \n",
      "Column: n_null     Score:0.88346 Use: False \n",
      "------------------------------\n",
      "Iter 15\n",
      "Column: n_null     Score:0.88177 Use: True \n",
      "Column: dt_mean    Score:0.88246 Use: True \n",
      "Column: minutes    Score:0.88246 Use: False \n",
      "Column: myear      Score:0.82702 Use: False \n",
      "Column: hour       Score:0.88215 Use: False \n",
      "Column: dow        Score:0.83317 Use: False \n",
      "Column: year       Score:0.81258 Use: False \n",
      "Column: dt_std     Score:0.82807 Use: False \n",
      "Column: dt         Score:0.82807 Use: False \n",
      "Column: dt_var     Score:0.82828 Use: False \n",
      "Column: month      Score:0.83671 Use: False \n",
      "Column: day_       Score:0.82248 Use: False \n",
      "------------------------------\n",
      "Iter 16\n",
      "Column: dt_std     Score:0.88114 Use: True \n",
      "Column: minutes    Score:0.88114 Use: False \n",
      "Column: n_null     Score:0.82792 Use: False \n",
      "Column: dt         Score:0.82776 Use: False \n",
      "Column: year       Score:0.81164 Use: False \n",
      "Column: month      Score:0.83587 Use: False \n",
      "Column: hour       Score:0.88099 Use: False \n",
      "Column: myear      Score:0.82662 Use: False \n",
      "Column: dt_mean    Score:0.82758 Use: False \n",
      "Column: dow        Score:0.83267 Use: False \n",
      "Column: day_       Score:0.82194 Use: False \n",
      "Column: dt_var     Score:0.82790 Use: False \n",
      "------------------------------\n",
      "Iter 17\n",
      "Column: n_null     Score:0.82741 Use: False \n",
      "Column: dt         Score:0.82778 Use: False \n",
      "Column: dt_var     Score:0.82764 Use: False \n",
      "Column: dt_mean    Score:0.82736 Use: False \n",
      "Column: myear      Score:0.82616 Use: False \n",
      "Column: year       Score:0.81123 Use: False \n",
      "Column: dow        Score:0.83218 Use: False \n",
      "Column: month      Score:0.83527 Use: False \n",
      "Column: dt_std     Score:0.82731 Use: False \n",
      "Column: day_       Score:0.82146 Use: False \n",
      "Column: hour       Score:0.88063 Use: True \n",
      "Column: minutes    Score:0.88034 Use: False \n",
      "------------------------------\n",
      "Iter 18\n",
      "Column: month      Score:0.83629 Use: False \n",
      "Column: myear      Score:0.82659 Use: False \n",
      "Column: minutes    Score:0.88168 Use: True \n",
      "Column: n_null     Score:0.88233 Use: True \n",
      "Column: day_       Score:0.87526 Use: False \n",
      "Column: dt_var     Score:0.88257 Use: True \n",
      "Column: dt         Score:0.88255 Use: False \n",
      "Column: dow        Score:0.88451 Use: True \n",
      "Column: year       Score:0.87071 Use: False \n",
      "Column: dt_std     Score:0.88461 Use: True \n",
      "Column: dt_mean    Score:0.88461 Use: False \n",
      "Column: hour       Score:0.88367 Use: False \n",
      "------------------------------\n",
      "Iter 19\n",
      "Column: dow        Score:0.86475 Use: False \n",
      "Column: myear      Score:0.85373 Use: False \n",
      "Column: dt_std     Score:0.86009 Use: False \n",
      "Column: hour       Score:0.86008 Use: False \n",
      "Column: month      Score:0.80141 Use: False \n",
      "Column: dt         Score:0.80787 Use: False \n",
      "Column: dt_mean    Score:0.80744 Use: False \n",
      "Column: day_       Score:0.80701 Use: False \n",
      "Column: n_null     Score:0.81195 Use: False \n",
      "Column: year       Score:0.81123 Use: False \n",
      "Column: minutes    Score:0.88075 Use: True \n",
      "Column: dt_var     Score:0.88130 Use: True \n",
      "------------------------------\n",
      "Iter 20\n",
      "Column: day_       Score:0.87332 Use: False \n",
      "Column: myear      Score:0.88082 Use: True \n",
      "Column: n_null     Score:0.88157 Use: True \n",
      "Column: dt         Score:0.88272 Use: True \n",
      "Column: dow        Score:0.88565 Use: True \n",
      "Column: dt_std     Score:0.88563 Use: False \n",
      "Column: dt_mean    Score:0.88548 Use: False \n",
      "Column: dt_var     Score:0.88569 Use: False \n",
      "Column: month      Score:0.87030 Use: False \n",
      "Column: year       Score:0.87054 Use: False \n",
      "Column: minutes    Score:0.88565 Use: False \n",
      "Column: hour       Score:0.88560 Use: False \n",
      "------------------------------\n",
      "Iter 21\n",
      "Column: dt_std     Score:0.88253 Use: True \n",
      "Column: dt_mean    Score:0.88253 Use: False \n",
      "Column: myear      Score:0.88217 Use: False \n",
      "Column: n_null     Score:0.88183 Use: False \n",
      "Column: hour       Score:0.88099 Use: False \n",
      "Column: dt         Score:0.82776 Use: False \n",
      "Column: dt_var     Score:0.82790 Use: False \n",
      "Column: minutes    Score:0.88114 Use: False \n",
      "Column: day_       Score:0.82194 Use: False \n",
      "Column: dow        Score:0.83267 Use: False \n",
      "Column: month      Score:0.83587 Use: False \n",
      "Column: year       Score:0.81164 Use: False \n",
      "------------------------------\n",
      "Iter 22\n",
      "Column: myear      Score:0.82616 Use: False \n",
      "Column: dt_mean    Score:0.82736 Use: False \n",
      "Column: year       Score:0.81123 Use: False \n",
      "Column: dow        Score:0.83218 Use: False \n",
      "Column: day_       Score:0.82146 Use: False \n",
      "Column: n_null     Score:0.82741 Use: False \n",
      "Column: minutes    Score:0.88075 Use: True \n",
      "Column: dt_var     Score:0.88130 Use: True \n",
      "Column: month      Score:0.89055 Use: True \n",
      "Column: dt_std     Score:0.89071 Use: True \n",
      "Column: hour       Score:0.89058 Use: False \n",
      "Column: dt         Score:0.89169 Use: True \n",
      "------------------------------\n",
      "Iter 23\n",
      "Column: dt_var     Score:0.86986 Use: False \n",
      "Column: dt_mean    Score:0.87007 Use: False \n",
      "Column: year       Score:0.86846 Use: False \n",
      "Column: dt_std     Score:0.86976 Use: False \n",
      "Column: dt         Score:0.87040 Use: False \n",
      "Column: day_       Score:0.85818 Use: False \n",
      "Column: n_null     Score:0.86942 Use: False \n",
      "Column: myear      Score:0.86841 Use: False \n",
      "Column: hour       Score:0.89253 Use: True \n",
      "Column: month      Score:0.89253 Use: False \n",
      "Column: minutes    Score:0.88222 Use: False \n",
      "Column: dow        Score:0.88236 Use: False \n",
      "------------------------------\n",
      "Iter 24\n",
      "Column: dow        Score:0.83440 Use: False \n",
      "Column: day_       Score:0.82408 Use: False \n",
      "Column: month      Score:0.81155 Use: False \n",
      "Column: minutes    Score:0.88101 Use: True \n",
      "Column: dt         Score:0.88216 Use: True \n",
      "Column: n_null     Score:0.88291 Use: True \n",
      "Column: hour       Score:0.88272 Use: False \n",
      "Column: dt_mean    Score:0.88276 Use: False \n",
      "Column: myear      Score:0.88291 Use: False \n",
      "Column: dt_var     Score:0.88277 Use: False \n",
      "Column: dt_std     Score:0.88273 Use: False \n",
      "Column: year       Score:0.86679 Use: False \n",
      "------------------------------\n",
      "Iter 25\n",
      "Column: dt_var     Score:0.83558 Use: False \n",
      "Column: day_       Score:0.83336 Use: False \n",
      "Column: minutes    Score:0.88470 Use: True \n",
      "Column: myear      Score:0.88470 Use: False \n",
      "Column: dow        Score:0.88346 Use: False \n",
      "Column: n_null     Score:0.88155 Use: False \n",
      "Column: month      Score:0.88997 Use: True \n",
      "Column: year       Score:0.86492 Use: False \n",
      "Column: dt_mean    Score:0.89120 Use: True \n",
      "Column: hour       Score:0.89109 Use: False \n",
      "Column: dt_std     Score:0.89132 Use: True \n",
      "Column: dt         Score:0.89138 Use: True \n",
      "------------------------------\n",
      "Iter 26\n",
      "Column: dt_mean    Score:0.80156 Use: False \n",
      "Column: dow        Score:0.81289 Use: False \n",
      "Column: year       Score:0.80123 Use: False \n",
      "Column: hour       Score:0.85377 Use: False \n",
      "Column: minutes    Score:0.85358 Use: False \n",
      "Column: dt         Score:0.80252 Use: False \n",
      "Column: myear      Score:0.80169 Use: False \n",
      "Column: dt_std     Score:0.81797 Use: False \n",
      "Column: day_       Score:0.81752 Use: False \n",
      "Column: dt_var     Score:0.83667 Use: False \n",
      "Column: month      Score:0.83592 Use: False \n",
      "Column: n_null     Score:0.82741 Use: False \n",
      "------------------------------\n",
      "Iter 27\n",
      "Column: year       Score:0.81123 Use: False \n",
      "Column: myear      Score:0.82616 Use: False \n",
      "Column: n_null     Score:0.82741 Use: False \n",
      "Column: minutes    Score:0.88075 Use: True \n",
      "Column: dow        Score:0.88265 Use: True \n",
      "Column: dt_std     Score:0.88308 Use: True \n",
      "Column: dt         Score:0.88391 Use: True \n",
      "Column: dt_mean    Score:0.88373 Use: False \n",
      "Column: dt_var     Score:0.88414 Use: True \n",
      "Column: month      Score:0.89479 Use: True \n",
      "Column: day_       Score:0.87601 Use: False \n",
      "Column: hour       Score:0.89463 Use: False \n",
      "------------------------------\n",
      "Iter 28\n",
      "Column: hour       Score:0.86586 Use: False \n",
      "Column: n_null     Score:0.86686 Use: False \n",
      "Column: day_       Score:0.86018 Use: False \n",
      "Column: dt_var     Score:0.86596 Use: False \n",
      "Column: dt_mean    Score:0.86570 Use: False \n",
      "Column: minutes    Score:0.86580 Use: False \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: year       Score:0.81248 Use: False \n",
      "Column: dow        Score:0.83321 Use: False \n",
      "Column: dt         Score:0.82776 Use: False \n",
      "Column: dt_std     Score:0.82731 Use: False \n",
      "Column: month      Score:0.83527 Use: False \n",
      "Column: myear      Score:0.82616 Use: False \n",
      "------------------------------\n",
      "Iter 29\n",
      "Column: dt_std     Score:0.82731 Use: False \n",
      "Column: dt_mean    Score:0.82736 Use: False \n",
      "Column: month      Score:0.83527 Use: False \n",
      "Column: myear      Score:0.82616 Use: False \n",
      "Column: dow        Score:0.83218 Use: False \n",
      "Column: year       Score:0.81123 Use: False \n",
      "Column: n_null     Score:0.82741 Use: False \n",
      "Column: hour       Score:0.88063 Use: True \n",
      "Column: dt         Score:0.88174 Use: True \n",
      "Column: day_       Score:0.87451 Use: False \n",
      "Column: dt_var     Score:0.88178 Use: False \n",
      "Column: minutes    Score:0.88161 Use: False \n",
      "------------------------------\n",
      "CPU times: user 7min 36s, sys: 4min 40s, total: 12min 17s\n",
      "Wall time: 48min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_split = 2\n",
    "time_split = TimeSeriesSplit(n_splits=n_split)\n",
    "\n",
    "sc_cols = ['hour', 'day_', 'month', 'year', 'myear', 'minutes', 'dow', 'n_null', 'dt', 'dt_mean', 'dt_std', 'dt_var']\n",
    "\n",
    "n_cols = len(sc_cols)\n",
    "ft_cols = np.array(sc_cols)\n",
    "\n",
    "mask_cols = np.zeros(len(sc_cols), dtype='bool')\n",
    "\n",
    "cv_cols = ['cv' + str(j) for j in range(n_split)]\n",
    "results = pd.DataFrame(np.zeros((n_cols, n_split+1)), columns=['Col'] + cv_cols)\n",
    "sc_dict = {x:0 for x in sc_cols}\n",
    "\n",
    "for r in range(0, 30):\n",
    "    print(f\"Iter {r}\")\n",
    "    score = 0.8758\n",
    "    np.random.seed(r)\n",
    "    np.random.shuffle(ft_cols)\n",
    "    for i in range(n_cols):\n",
    "        score_ = 0\n",
    "\n",
    "        mask_cols[i] = True\n",
    "\n",
    "        results.loc[i, 'Col'] = ft_cols[i]\n",
    "        ts_cols = ft_cols[mask_cols]\n",
    "\n",
    "        results.loc[i, cv_cols] = cross_val_score(pl.set_params(feats__pl_time_scale__select__key=ts_cols), \n",
    "                          X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "        score_ = results.loc[i, cv_cols].mean()\n",
    "\n",
    "        if score_ - score < 0.00005:\n",
    "            mask_cols[i] = False\n",
    "        else:\n",
    "            score = score_\n",
    "            sc_dict[ft_cols[i]] += 1\n",
    "\n",
    "        print(f'Column: {results.loc[i, \"Col\"]:<10} Score:{score_:.5f} Use: {mask_cols[i]} ')\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iter 7\n",
    "Column: hour       Score:0.88063 Use: True \n",
    "Column: dt_var     Score:0.88111 Use: True \n",
    "Column: dow        Score:0.88286 Use: True \n",
    "Column: dt         Score:0.88355 Use: True \n",
    "Column: month      Score:0.89401 Use: True \n",
    "Column: dt_std     Score:0.89418 Use: True \n",
    "Column: n_null     Score:0.89468 Use: True \n",
    "\n",
    "Iter 13\n",
    "Column: minutes    Score:0.88075 Use: True \n",
    "Column: dt         Score:0.88195 Use: True \n",
    "Column: month      Score:0.89144 Use: True \n",
    "Column: dow        Score:0.89457 Use: True \n",
    "Column: n_null     Score:0.89514 Use: True\n",
    "\n",
    "Iter 27\n",
    "Column: minutes    Score:0.88075 Use: True \n",
    "Column: dow        Score:0.88265 Use: True \n",
    "Column: dt_std     Score:0.88308 Use: True \n",
    "Column: dt         Score:0.88391 Use: True \n",
    "Column: dt_var     Score:0.88414 Use: True \n",
    "Column: month      Score:0.89479 Use: True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'month', 'dow', 'dt', 'dt_std', 'dt_var'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feats__pl_text__select__key',\n",
       " 'feats__pl_time__select__key',\n",
       " 'feats__pl_time_scale__select__key']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in pl_all.get_params().keys() if 'key' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Column: sin_max    Score:0.90481 Use: True \n",
      "Column: spl3       Score:0.90715 Use: True \n",
      "Column: spl2       Score:0.92991 Use: True \n",
      "Column: cos_max    Score:0.92937 Use: False \n",
      "Column: spl4       Score:0.92988 Use: False \n",
      "Column: spl1       Score:0.93213 Use: True \n",
      "Column: cos_min    Score:0.93147 Use: False \n",
      "Column: sin_min    Score:0.93228 Use: True \n",
      "------------------------------\n",
      "Iter 1\n",
      "Column: sin_min    Score:0.93229 Use: True \n",
      "Column: spl2       Score:0.93229 Use: False \n",
      "Column: spl3       Score:0.93255 Use: True \n",
      "Column: cos_min    Score:0.93218 Use: False \n",
      "Column: sin_max    Score:0.93265 Use: True \n",
      "Column: spl4       Score:0.93265 Use: False \n",
      "Column: cos_max    Score:0.93201 Use: False \n",
      "Column: spl1       Score:0.93184 Use: False \n",
      "------------------------------\n",
      "Iter 2\n",
      "Column: sin_max    Score:0.90407 Use: True \n",
      "Column: spl2       Score:0.89574 Use: False \n",
      "Column: cos_max    Score:0.90407 Use: False \n",
      "Column: spl3       Score:0.91381 Use: True \n",
      "Column: cos_min    Score:0.91381 Use: False \n",
      "Column: spl1       Score:0.93168 Use: True \n",
      "Column: spl4       Score:0.93251 Use: True \n",
      "Column: sin_min    Score:0.93265 Use: True \n",
      "------------------------------\n",
      "Iter 3\n",
      "Column: spl1       Score:0.93051 Use: True \n",
      "Column: sin_min    Score:0.93060 Use: True \n",
      "Column: cos_min    Score:0.93060 Use: False \n",
      "Column: spl4       Score:0.93060 Use: False \n",
      "Column: spl3       Score:0.93159 Use: True \n",
      "Column: spl2       Score:0.93159 Use: False \n",
      "Column: sin_max    Score:0.93201 Use: True \n",
      "Column: cos_max    Score:0.93201 Use: False \n",
      "------------------------------\n",
      "Iter 4\n",
      "Column: spl3       Score:0.91391 Use: True \n",
      "Column: cos_max    Score:0.91391 Use: False \n",
      "Column: spl4       Score:0.90832 Use: False \n",
      "Column: spl1       Score:0.93184 Use: True \n",
      "Column: sin_min    Score:0.93184 Use: False \n",
      "Column: spl2       Score:0.93213 Use: True \n",
      "Column: sin_max    Score:0.93213 Use: False \n",
      "Column: cos_min    Score:0.92584 Use: False \n",
      "------------------------------\n",
      "Iter 5\n",
      "Column: cos_min    Score:0.85821 Use: False \n",
      "Column: spl4       Score:0.87560 Use: False \n",
      "Column: sin_min    Score:0.89579 Use: True \n",
      "Column: cos_max    Score:0.89579 Use: False \n",
      "Column: spl3       Score:0.92995 Use: True \n",
      "Column: spl2       Score:0.92995 Use: False \n",
      "Column: sin_max    Score:0.90715 Use: False \n",
      "Column: spl1       Score:0.93176 Use: True \n",
      "------------------------------\n",
      "Iter 6\n",
      "Column: cos_min    Score:0.91383 Use: True \n",
      "Column: spl2       Score:0.92944 Use: True \n",
      "Column: sin_max    Score:0.92944 Use: False \n",
      "Column: spl1       Score:0.93150 Use: True \n",
      "Column: spl3       Score:0.93150 Use: False \n",
      "Column: cos_max    Score:0.92740 Use: False \n",
      "Column: spl4       Score:0.93053 Use: False \n",
      "Column: sin_min    Score:0.92733 Use: False \n",
      "------------------------------\n",
      "Iter 7\n",
      "Column: sin_max    Score:0.90405 Use: True \n",
      "Column: cos_max    Score:0.90405 Use: False \n",
      "Column: cos_min    Score:0.90408 Use: False \n",
      "Column: spl4       Score:0.90632 Use: True \n",
      "Column: spl1       Score:0.90455 Use: False \n",
      "Column: spl2       Score:0.89621 Use: False \n",
      "Column: spl3       Score:0.90832 Use: True \n",
      "Column: sin_min    Score:0.90832 Use: False \n",
      "------------------------------\n",
      "Iter 8\n",
      "Column: sin_min    Score:0.93176 Use: True \n",
      "Column: sin_max    Score:0.93184 Use: True \n",
      "Column: cos_min    Score:0.93199 Use: True \n",
      "Column: spl3       Score:0.93199 Use: False \n",
      "Column: spl2       Score:0.92734 Use: False \n",
      "Column: cos_max    Score:0.90309 Use: False \n",
      "Column: spl1       Score:0.90309 Use: False \n",
      "Column: spl4       Score:0.90413 Use: False \n",
      "------------------------------\n",
      "Iter 9\n",
      "Column: spl4       Score:0.90408 Use: True \n",
      "Column: sin_max    Score:0.90408 Use: False \n",
      "Column: cos_min    Score:0.87965 Use: False \n",
      "Column: spl3       Score:0.90391 Use: False \n",
      "Column: sin_min    Score:0.90637 Use: True \n",
      "Column: cos_max    Score:0.90408 Use: False \n",
      "Column: spl2       Score:0.89625 Use: False \n",
      "Column: spl1       Score:0.90463 Use: False \n",
      "------------------------------\n",
      "CPU times: user 1min 41s, sys: 1min 1s, total: 2min 43s\n",
      "Wall time: 11min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_split = 2\n",
    "time_split = TimeSeriesSplit(n_splits=n_split)\n",
    "\n",
    "ns_cols = ['month', 'dow', 'dt', 'dt_std', 'dt_var']\n",
    "sc_cols = ['spl1', 'spl2', 'spl3', 'spl4', 'sin_min', 'cos_min', 'sin_max', 'cos_max']\n",
    "\n",
    "n_cols = len(sc_cols)\n",
    "ft_cols = np.array(sc_cols)\n",
    "\n",
    "mask_cols = np.zeros(len(sc_cols), dtype='bool')\n",
    "\n",
    "cv_cols = ['cv' + str(j) for j in range(n_split)]\n",
    "results = pd.DataFrame(np.zeros((n_cols, n_split+1)), columns=['Col'] + cv_cols)\n",
    "sc_dict_ = {x:0 for x in sc_cols}\n",
    "\n",
    "for r in range(10):\n",
    "    print(f\"Iter {r}\")\n",
    "    score = 0.895\n",
    "    np.random.seed(r)\n",
    "    np.random.shuffle(ft_cols)\n",
    "    for i in range(n_cols):\n",
    "        score_ = 0\n",
    "\n",
    "        mask_cols[i] = True\n",
    "\n",
    "        results.loc[i, 'Col'] = ft_cols[i]\n",
    "        ts_cols = ft_cols[mask_cols]\n",
    "\n",
    "        results.loc[i, cv_cols] = cross_val_score(pl_all.set_params(feats__pl_time__select__key=ts_cols,\n",
    "                                                                   feats__pl_time_scale__select__key=ns_cols), \n",
    "                          X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "        score_ = results.loc[i, cv_cols].mean()\n",
    "\n",
    "        if score_ - score < 0.00005:\n",
    "            mask_cols[i] = False\n",
    "        else:\n",
    "            score = score_\n",
    "            sc_dict_[ft_cols[i]] += 1\n",
    "\n",
    "        print(f'Column: {results.loc[i, \"Col\"]:<10} Score:{score_:.5f} Use: {mask_cols[i]} ')\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'hour': 10,\n",
    " 'day_': 1,\n",
    " 'month': 7,\n",
    " 'year': 12,\n",
    " 'myear': 17,\n",
    " 'minutes': 17,\n",
    " 'dow': 8,\n",
    " 'n_null': 1,\n",
    " 'dt': 5,\n",
    " 'dt_mean': 4,\n",
    " 'dt_std': 6,\n",
    " 'dt_var': 15}\n",
    " \n",
    " {'morning': 23,\n",
    " 'day': 30,\n",
    " 'evening': 25,\n",
    " 'sin_min': 24,\n",
    " 'cos_min': 27,\n",
    " 'sin_max': 26,\n",
    " 'cos_max': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feats__pl_text__select__key',\n",
       " 'feats__pl_time__select__key',\n",
       " 'feats__pl_time_scale__select__key']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[z for z in pl_all.get_params().keys() if 'key' in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = [      'sites',    'sites_ds',   'sites_dms',   'sites_num',\n",
    "              'hour',        'day_',       'month',        'year',\n",
    "             'myear',     'morning',         'day',     'evening',\n",
    "           'minutes',     'sin_min',     'cos_min',     'sin_max',\n",
    "           'cos_max',         'dow',     'weekend',      'n_null',\n",
    "                'dt',     'dt_mean',      'dt_std',      'dt_var',\n",
    "       'spl1',  'spl2',  'spl3',  'spl4']\n",
    "\n",
    "X_test.columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['site1', 'time1', 'site2', 'time2', 'site3', 'time3', 'site4', 'time4',\n",
       "       'site5', 'time5', 'site6', 'time6', 'site7', 'time7', 'site8', 'time8',\n",
       "       'site9', 'time9', 'site10', 'time10', 'target', 'for_folds', 'user'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['for_folds'] = train_df['for_folds']\n",
    "X_train = X_train.sort_values('for_folds')\n",
    "del X_train['for_folds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score 0.93892\n",
    "\n",
    "s_cols = ['month', 'dow', 'dt', 'dt_std', 'dt_var']\n",
    "ns_cols = ['spl1',  'spl2',  'spl3',  'spl4', 'sin_min']\n",
    "c=1.4\n",
    "('tfidf', TfidfVectorizer(max_df=0.15, max_features=25000, smooth_idf=True, sublinear_tf=True))\n",
    "\n",
    "\n",
    "score 0.94227\n",
    "s_cols = ['dow', 'dt', 'dt_std', 'dt_var']\n",
    "ns_cols = ['spl1',  'spl2',  'spl3',  'spl4', 'sin_min']\n",
    "c=1.4\n",
    "('tfidf', TfidfVectorizer(max_df=0.75, max_features=25000, smooth_idf=True, sublinear_tf=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2\n",
      "Column: 0 Score:0.9084+-0.0412 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.9221+-0.0259 pub_lb: 0.9346  \n",
      "Column: 2 Score:0.9308+-0.0222 pub_lb: 0.9346  \n",
      "Column: 3 Score:0.9310+-0.0221 pub_lb: 0.9346  \n",
      "Column: 4 Score:0.9317+-0.0212 pub_lb: 0.9346  \n",
      "Column: 5 Score:0.9203+-0.0297 pub_lb: 0.9348  \n",
      "Column: 6 Score:0.9195+-0.0307 pub_lb: 0.9352  \n",
      "Column: 7 Score:0.9302+-0.0212 pub_lb: 0.9394  \n",
      "Column: 8 Score:0.9312+-0.0209 pub_lb: 0.9411  \n",
      "******************************\n",
      "CPU times: user 11.2 s, sys: 7.31 s, total: 18.5 s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# s_cols = ['month', 'dow', 'dt', 'dt_std', 'dt_var']\n",
    "# ns_cols = ['spl1',  'spl2',  'spl3']\n",
    "\n",
    "s_cols = [['hour', 'year', 'myear', 'minutes', 'dt_var'],\n",
    "          ['month', 'dow', 'dt', 'dt_std', 'dt_var'],\n",
    "          ['month', 'dow', 'dt', 'dt_std', 'dt_var'],\n",
    "          ['month', 'dow', 'dt', 'dt_std', 'dt_var'],\n",
    "          ['month', 'dow', 'dt', 'dt_std', 'dt_var'],\n",
    "          ['dow', 'month', 'dt_var', 'dt_mean', 'dt_std', 'day_'],\n",
    "          ['dow', 'month', 'dt_var', 'dt_mean', 'dt_std', 'day_'],\n",
    "         ['dow', 'month', 'minutes', 'dt_var'],\n",
    "         ['dow', 'month', 'minutes', 'dt_var', 'dt_mean', 'dt_std', 'day']]\n",
    "ns_cols = [['spl1',  'spl2',  'spl3',  'spl4'],\n",
    "           ['spl1',  'spl2',  'spl3'],\n",
    "           ['spl1',  'spl2',  'spl3', 'sin_min', 'cos_min'],\n",
    "           ['spl1',  'spl2',  'spl3',  'spl4', 'sin_min', 'cos_min'],\n",
    "           ['spl1',  'spl2',  'spl3',  'spl4', 'sin_min', 'cos_min'],\n",
    "           ['spl1',  'spl2',  'spl3',  'spl4', 'sin_max', 'cos_max'],\n",
    "           ['spl1',  'spl2',  'spl3',  'spl4', 'sin_max', 'cos_max'],\n",
    "          ['spl1',  'spl2',  'spl3',  'spl4'],\n",
    "          ['spl1',  'spl2',  'spl3',  'spl4']]\n",
    "\n",
    "max_df_cols = [.2,.7,.7,.7,.2, .2,.7,.2,.2]\n",
    "\n",
    "# s_cols = ['dow', 'month', 'dt_var', 'dt_mean', 'dt_std', 'day_']\n",
    "# ns_cols = ['spl1',  'spl2',  'spl3',  'spl4', 'sin_max', 'cos_max']\n",
    "\n",
    "# pl_all.set_params(feats__pl_time__select__key=ns_cols, feats__pl_time_scale__select__key=s_cols,\n",
    "#                  feats__pl_text__tfidf__max_df=0.7).fit(X_train, y_train)\n",
    "\n",
    "pub_lb = [0.9298, .9346, .9346, .9346, .9346, 0.9348, 0.9352, 0.9394, 0.9411]\n",
    "\n",
    "scores = dict()\n",
    "\n",
    "for k in range(2, 5, 8):\n",
    "    scores[k] = list()\n",
    "    print(f\"k = {k}\")\n",
    "    time_split = TimeSeriesSplit(n_splits=k)\n",
    "#     time_split = KFold(n_splits=k, shuffle=False)\n",
    "\n",
    "\n",
    "    n_cols = len(s_cols)\n",
    "    cv_cols = ['cv' + str(j) for j in range(10)]\n",
    "#     results = pd.DataFrame(np.zeros((n_cols, 11)), columns=['Col'] + cv_cols)\n",
    "\n",
    "    for i in range(n_cols):\n",
    "\n",
    "#         results.loc[i, 'Col'] = i\n",
    "\n",
    "        s = cross_val_score(pl_all.set_params(feats__pl_time__select__key=ns_cols[i],\n",
    "                                            feats__pl_time_scale__select__key=s_cols[i],\n",
    "                                             feats__pl_text__tfidf__max_df=max_df_cols[i]),\n",
    "                                                  X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "#         score_ = s.mean()\n",
    "        scores[k].append(s)\n",
    "        print(f'Column: {i} Score:{s.mean():.4f}+-{s.std():.4f} pub_lb: {pub_lb[i]:.4f}  ')\n",
    "    print('*' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [array([0.86724801, 0.94955909]),\n",
       "  array([0.89056553, 0.94998904]),\n",
       "  array([0.88879702, 0.9501845 ]),\n",
       "  array([0.90898703, 0.9514429 ]),\n",
       "  array([0.91032491, 0.95207308])],\n",
       " 3: [array([0.91825546, 0.92540581, 0.96182859]),\n",
       "  array([0.82778135, 0.92603197, 0.96769041]),\n",
       "  array([0.8271023 , 0.9255705 , 0.96797635]),\n",
       "  array([0.90056358, 0.92601281, 0.96584972]),\n",
       "  array([0.90270568, 0.92677508, 0.9664527 ])],\n",
       " 4: [array([0.7761114 , 0.866337  , 0.94718307, 0.96003797]),\n",
       "  array([0.59040514, 0.93044507, 0.93864561, 0.96768375]),\n",
       "  array([0.59046552, 0.92906583, 0.93828951, 0.96814976]),\n",
       "  array([0.62342798, 0.92519479, 0.9449721 , 0.96556956]),\n",
       "  array([0.63821638, 0.92573524, 0.94573091, 0.96626892])],\n",
       " 5: [array([0.85447541, 0.91803082, 0.91551543, 0.94434249, 0.96566775]),\n",
       "  array([0.78937353, 0.8849005 , 0.92281408, 0.94270181, 0.97260176]),\n",
       "  array([0.78849015, 0.88366971, 0.92153175, 0.94299322, 0.97294024]),\n",
       "  array([0.77752385, 0.91551329, 0.91760737, 0.94731574, 0.97086268]),\n",
       "  array([0.79135695, 0.9173645 , 0.9184144 , 0.94756739, 0.97183233])],\n",
       " 6: [array([0.89946148, 0.90445717, 0.84821313, 0.94233615, 0.94152123,\n",
       "         0.9749004 ]),\n",
       "  array([0.87942811, 0.72490921, 0.92413072, 0.93981895, 0.94406022,\n",
       "         0.98077106]),\n",
       "  array([0.87664596, 0.72428295, 0.92285658, 0.93987551, 0.94396967,\n",
       "         0.9808182 ]),\n",
       "  array([0.86119707, 0.85162212, 0.91785047, 0.94226805, 0.9451551 ,\n",
       "         0.97956284]),\n",
       "  array([0.86484956, 0.85501572, 0.91835008, 0.94306635, 0.94507191,\n",
       "         0.98036954])],\n",
       " 7: [array([0.89601765, 0.91817733, 0.92474405, 0.9040215 , 0.95739942,\n",
       "         0.94640659, 0.9797217 ]),\n",
       "  array([0.87866382, 0.77631715, 0.94955304, 0.91808699, 0.94840447,\n",
       "         0.95210647, 0.98643959]),\n",
       "  array([0.87471659, 0.77601781, 0.94883855, 0.91689247, 0.9487241 ,\n",
       "         0.95294716, 0.98621666]),\n",
       "  array([0.86040814, 0.88327466, 0.94849258, 0.90882288, 0.95661487,\n",
       "         0.95132014, 0.9845826 ]),\n",
       "  array([0.8655329 , 0.88633863, 0.94876562, 0.9094058 , 0.95735852,\n",
       "         0.95173974, 0.98514044])],\n",
       " 8: [array([0.95234906, 0.91835069, 0.93595615, 0.82140954, 0.94656915,\n",
       "         0.95777018, 0.94006524, 0.98352543]),\n",
       "  array([0.94539734, 0.85384441, 0.84322716, 0.90709259, 0.94642809,\n",
       "         0.95105187, 0.94777161, 0.98992386]),\n",
       "  array([0.94427131, 0.853951  , 0.84144231, 0.90555587, 0.94608576,\n",
       "         0.95163796, 0.94869314, 0.98999592]),\n",
       "  array([0.93685568, 0.88647471, 0.89777201, 0.89777781, 0.94506339,\n",
       "         0.95927631, 0.94619992, 0.98807601]),\n",
       "  array([0.93934238, 0.88930671, 0.9004896 , 0.89843586, 0.94586731,\n",
       "         0.95954642, 0.94701421, 0.98834525])],\n",
       " 9: [array([0.9960092 , 0.87523934, 0.88757124, 0.91797845, 0.90491377,\n",
       "         0.94662286, 0.9561274 , 0.93590617, 0.98363731]),\n",
       "  array([0.9976161 , 0.84868583, 0.67528904, 0.95791906, 0.92101011,\n",
       "         0.94265523, 0.95358655, 0.94568856, 0.9900164 ]),\n",
       "  array([0.99744839, 0.84759014, 0.67262029, 0.95752447, 0.91980875,\n",
       "         0.94203917, 0.95356289, 0.94683125, 0.99000697]),\n",
       "  array([0.99612101, 0.80342854, 0.82121797, 0.95430875, 0.91047131,\n",
       "         0.94583064, 0.95846958, 0.94385244, 0.98790741]),\n",
       "  array([0.99612207, 0.80682808, 0.82546317, 0.95459372, 0.91112204,\n",
       "         0.94665321, 0.9585996 , 0.9449553 , 0.98817599])],\n",
       " 10: [array([0.99695205, 0.87190528, 0.9179603 , 0.96800274, 0.81269968,\n",
       "         0.93928003, 0.96637228, 0.95345382, 0.93044931, 0.98639135]),\n",
       "  array([0.99821812, 0.85418844, 0.78732163, 0.94689968, 0.90736339,\n",
       "         0.94246302, 0.96219435, 0.95526805, 0.94205609, 0.99207432]),\n",
       "  array([0.99804261, 0.85439959, 0.78605666, 0.94643633, 0.90634248,\n",
       "         0.94178956, 0.96244126, 0.95488586, 0.94284767, 0.99216454]),\n",
       "  array([0.99691304, 0.80904962, 0.88388635, 0.95479823, 0.89568824,\n",
       "         0.93845276, 0.96850865, 0.95746079, 0.93954938, 0.98994078]),\n",
       "  array([0.99704591, 0.81554345, 0.88644255, 0.95490352, 0.89668124,\n",
       "         0.93914028, 0.9691313 , 0.95766254, 0.94127273, 0.990166  ])],\n",
       " 11: [array([0.99758599, 0.86431409, 0.94106095, 0.91469199, 0.91336016,\n",
       "         0.90555843, 0.93358257, 0.95840783, 0.96118083, 0.94481093,\n",
       "         0.98550938]),\n",
       "  array([0.99868616, 0.84811357, 0.87765939, 0.78897222, 0.96586044,\n",
       "         0.91933041, 0.9360887 , 0.95079174, 0.96815358, 0.95251128,\n",
       "         0.99157153]),\n",
       "  array([0.99854345, 0.84681411, 0.87815466, 0.78658995, 0.96607717,\n",
       "         0.91786255, 0.93531997, 0.95182821, 0.9682718 , 0.95318388,\n",
       "         0.99163219]),\n",
       "  array([0.99743209, 0.80521998, 0.92068197, 0.86559674, 0.96252077,\n",
       "         0.90932599, 0.93417087, 0.95963854, 0.96668115, 0.95178651,\n",
       "         0.98927667]),\n",
       "  array([0.99776787, 0.81420333, 0.92217083, 0.86935474, 0.96287714,\n",
       "         0.90968906, 0.93504291, 0.96008941, 0.96682919, 0.95371076,\n",
       "         0.98952905])],\n",
       " 12: [array([0.99763951, 0.88595089, 0.96705989, 0.89077094, 0.95872278,\n",
       "         0.83545087, 0.90759008, 0.96828437, 0.94935494, 0.95135615,\n",
       "         0.9522675 , 0.98496572]),\n",
       "  array([0.99892403, 0.86998686, 0.9354806 , 0.72089413, 0.94295747,\n",
       "         0.91381699, 0.92551633, 0.96117998, 0.94375542, 0.95994173,\n",
       "         0.95820387, 0.99122859]),\n",
       "  array([0.99896646, 0.86669392, 0.9375908 , 0.71738363, 0.94188901,\n",
       "         0.9121255 , 0.92513682, 0.96107604, 0.94413986, 0.96037322,\n",
       "         0.95905119, 0.99130262]),\n",
       "  array([0.99731979, 0.84027969, 0.94986856, 0.83140736, 0.94373989,\n",
       "         0.90195631, 0.91561334, 0.96663881, 0.95158154, 0.95790699,\n",
       "         0.95852267, 0.98888837]),\n",
       "  array([0.99784747, 0.84952639, 0.95001128, 0.83672659, 0.94371916,\n",
       "         0.9030323 , 0.91622944, 0.96743983, 0.9515464 , 0.95804749,\n",
       "         0.96037205, 0.98914611])]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 2  \n",
    "Column: 0 Score:0.9071+-0.0413 pub_lb: 0.9298  \n",
    "Column: 1 Score:0.9191+-0.0297 pub_lb: 0.9348  \n",
    "Column: 2 Score:0.9188+-0.0303 pub_lb: 0.9352  \n",
    "Column: 3 Score:0.9292+-0.0211 pub_lb: 0.9394  \n",
    "Column: 4 Score:0.9301+-0.0209 pub_lb: 0.9411  \n",
    "******************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 4\n",
    "Column: 0 Score:0.9314+-0.0490 pub_lb: 0.9230\n",
    "Column: 1 Score:0.9260+-0.0630 pub_lb: 0.9350\n",
    "Column: 2 Score:0.9371+-0.0421 pub_lb: 0.9390\n",
    "Column: 3 Score:0.9381+-0.0411 pub_lb: 0.9410\n",
    "++++++++++++++++++++++++++++++\n",
    "k = 8\n",
    "Column: 0 Score:0.9059+-0.0939 pub_lb: 0.9230\n",
    "Column: 1 Score:0.9059+-0.0916 pub_lb: 0.9350\n",
    "Column: 2 Score:0.9069+-0.0926 pub_lb: 0.9390\n",
    "Column: 3 Score:0.9078+-0.0918 pub_lb: 0.9410\n",
    "++++++++++++++++++++++++++++++\n",
    "k = 10\n",
    "Column: 0 Score:0.9153+-0.0936 pub_lb: 0.9230\n",
    "Column: 1 Score:0.9043+-0.1090 pub_lb: 0.9350\n",
    "Column: 2 Score:0.9119+-0.0996 pub_lb: 0.9390\n",
    "Column: 3 Score:0.9127+-0.0994 pub_lb: 0.9410\n",
    "++++++++++++++++++++++++++++++\n",
    "CPU times: user 1min 9s, sys: 28.7 s, total: 1min 37s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.012, 0.004, 0.002])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_lb = np.array(pub_lb)\n",
    "pub_lb[1:] - pub_lb[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_temp = scores.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00125215  0.00227488  0.00061319]\n",
      "[-0.00125215  0.00227488  0.00061319]\n"
     ]
    }
   ],
   "source": [
    "z = np.array(scores[10])\n",
    "mask = [False,  False,  False,  True,  True,  False,  True,  True,  True, True]\n",
    "print((z.T[mask, 1:] - z.T[mask, :3]).mean(axis=0))\n",
    "mask = [False,  False,  False,  True,  True,  False,  True,  True,  True, True]\n",
    "print((z.T[mask, 1:] - z.T[mask, :3]).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02991923,  0.00396873, -0.00046342,  0.00454786],\n",
       "       [ 0.04861634, -0.00537681,  0.00240264, -0.00128582],\n",
       "       [ 0.00276791,  0.00038948,  0.00061672,  0.00050791]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[1:, :] - z[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6699654  0.64219609 0.65135411 0.65104944]\n",
      "[-0.02776931  0.00915802 -0.00030467]\n",
      "\n",
      "[0.81788942 0.75120815 0.80683067 0.81101446]\n",
      "[-0.06668127  0.05562252  0.00418379]\n",
      "\n",
      "[0.96978259 0.96340632 0.96131689 0.96171718]\n",
      "[-0.00637627 -0.00208943  0.00040029]\n",
      "\n",
      "[0.96861404 0.96893535 0.97096088 0.97035083]\n",
      "[ 0.00032131  0.00202553 -0.00061005]\n",
      "\n",
      "[0.924379   0.9308179  0.92470623 0.9245789 ]\n",
      "[ 0.00643891 -0.00611168 -0.00012732]\n",
      "\n",
      "[0.97675274 0.97537204 0.97515072 0.9756117 ]\n",
      "[-0.0013807  -0.00022132  0.00046099]\n",
      "\n",
      "[0.92717744 0.90323302 0.92379128 0.92558811]\n",
      "[-0.02394442  0.02055826  0.00179684]\n",
      "\n",
      "[0.9500498  0.95135484 0.95156365 0.95257039]\n",
      "[0.00130504 0.00020881 0.00100674]\n",
      "\n",
      "[0.97442405 0.97562234 0.97442985 0.97563684]\n",
      "[ 0.00119829 -0.0011925   0.00120699]\n",
      "\n",
      "[0.97364177 0.98080977 0.9789706  0.97937653]\n",
      "[ 0.007168   -0.00183917  0.00040593]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(z[0])):\n",
    "    print(z[:, i])\n",
    "    print(z[1:, i] - z[:3, i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 3\n",
    "Column: 0 Score:0.9490+-0.0181 pub_lb: 0.929\n",
    "Column: 1 Score:0.9490+-0.0173 pub_lb: 0.939\n",
    "Column: 2 Score:0.9496+-0.0173 pub_lb: 0.941\n",
    "*------------------------------\n",
    "k = 4\n",
    "Column: 0 Score:0.9314+-0.0490 pub_lb: 0.929\n",
    "Column: 1 Score:0.9371+-0.0421 pub_lb: 0.939\n",
    "Column: 2 Score:0.9381+-0.0411 pub_lb: 0.941\n",
    "*------------------------------\n",
    "k = 5\n",
    "Column: 0 Score:0.9199+-0.0661 pub_lb: 0.929\n",
    "Column: 1 Score:0.9197+-0.0679 pub_lb: 0.939\n",
    "Column: 2 Score:0.9210+-0.0661 pub_lb: 0.941\n",
    "*------------------------------\n",
    "k = 8\n",
    "Column: 0 Score:0.9059+-0.0939 pub_lb: 0.929\n",
    "Column: 1 Score:0.9069+-0.0926 pub_lb: 0.939\n",
    "Column: 2 Score:0.9078+-0.0918 pub_lb: 0.941\n",
    "*------------------------------\n",
    "k = 10\n",
    "Column: 0 Score:0.9153+-0.0936 pub_lb: 0.929\n",
    "Column: 1 Score:0.9119+-0.0996 pub_lb: 0.939\n",
    "Column: 2 Score:0.9127+-0.0994 pub_lb: 0.941\n",
    "*------------------------------\n",
    "CPU times: user 1min 9s, sys: 30.6 s, total: 1min 40s\n",
    "Wall time: 4min 14s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 2\n",
    "Column: 0 Score:0.9512+-0.0089 \n",
    "Column: 1 Score:0.9509+-0.0100 \n",
    "*------------------------------\n",
    "k = 3\n",
    "Column: 0 Score:0.9490+-0.0181 \n",
    "Column: 1 Score:0.9490+-0.0173 \n",
    "*------------------------------\n",
    "k = 4\n",
    "Column: 0 Score:0.9314+-0.0490 \n",
    "Column: 1 Score:0.9371+-0.0421 \n",
    "*------------------------------\n",
    "k = 5\n",
    "Column: 0 Score:0.9199+-0.0661 \n",
    "Column: 1 Score:0.9197+-0.0679 \n",
    "*------------------------------\n",
    "k = 6\n",
    "Column: 0 Score:0.9199+-0.0904 \n",
    "Column: 1 Score:0.9173+-0.0974 \n",
    "*------------------------------\n",
    "k = 7\n",
    "Column: 0 Score:0.9125+-0.0750 \n",
    "Column: 1 Score:0.9099+-0.0821 \n",
    "*------------------------------\n",
    "k = 8\n",
    "Column: 0 Score:0.9059+-0.0939 \n",
    "Column: 1 Score:0.9069+-0.0926 \n",
    "*------------------------------\n",
    "k = 9\n",
    "Column: 0 Score:0.9054+-0.0951 \n",
    "Column: 1 Score:0.9039+-0.0999 \n",
    "*------------------------------\n",
    "k = 10\n",
    "Column: 0 Score:0.9153+-0.0936 \n",
    "Column: 1 Score:0.9119+-0.0996 \n",
    "*------------------------------\n",
    "k = 11\n",
    "Column: 0 Score:0.9096+-0.0875 \n",
    "Column: 1 Score:0.9052+-0.0975 \n",
    "*------------------------------\n",
    "k = 12\n",
    "Column: 0 Score:0.9153+-0.0935 \n",
    "Column: 1 Score:0.9123+-0.1007 \n",
    "*------------------------------\n",
    "k = 13\n",
    "Column: 0 Score:0.9096+-0.0774 \n",
    "Column: 1 Score:0.9077+-0.0844 \n",
    "*------------------------------\n",
    "CPU times: user 1min 59s, sys: 51.2 s, total: 2min 50s\n",
    "Wall time: 6min 41s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sites', 'sites_ds', 'sites_dms', 'sites_num', 'hour', 'day_', 'month',\n",
       "       'year', 'myear', 'morning', 'day', 'evening', 'minutes', 'sin_min',\n",
       "       'cos_min', 'sin_max', 'cos_max', 'dow', 'weekend', 'n_null', 'dt',\n",
       "       'dt_mean', 'dt_std', 'dt_var', 'spl1', 'spl2', 'spl3', 'spl4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cols = ['hour', 'year', 'myear', 'minutes', 'dt_var']\n",
    "ns_cols = ['spl1',  'spl2',  'spl3',  'spl4']\n",
    "\n",
    "s_cols = ['dow', 'month', 'minutes', 'dt_var']\n",
    "ns_cols = ['spl1',  'spl2',  'spl3',  'spl4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sites', 'sites_ds', 'sites_dms', 'sites_num', 'hour', 'day_', 'month',\n",
       "       'year', 'myear', 'morning', 'day', 'evening', 'minutes', 'sin_min',\n",
       "       'cos_min', 'sin_max', 'cos_max', 'dow', 'weekend', 'n_null', 'dt',\n",
       "       'dt_mean', 'dt_std', 'dt_var', 'spl1', 'spl2', 'spl3', 'spl4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feats__pl_text__tfidf__max_df']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in pl_all.get_params().keys() if 'max_df' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cols = ['dow', 'dt', 'dt_std', 'dt_var']\n",
    "ns_cols = ['spl1',  'spl2',  'spl3',  'spl4', 'sin_min']\n",
    "\n",
    "# not_scale_cols = ['spl1',  'spl2',  'spl3',  'spl4', 'sin_min']\n",
    "# scale_cols = ['month', 'dow', 'dt', 'dt_std', 'dt_var']\n",
    "\n",
    "pl_all.set_params(feats__pl_time__select__key=ns_cols, feats__pl_time_scale__select__key=s_cols).fit(X_train, y_train)\n",
    "\n",
    "pred = pl_all.predict_proba(X_test)[:, 1]\n",
    "\n",
    "write_to_submission_file(pred, 'pl_optim_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['minutes', 'dt_mean', 'day', 'myear', 'month', 'dt', 'year'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_cols[mask_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/runpy.py in _run_code(code=<code object <module> at 0x7f51c89065d0, file \"/...3.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ningen.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f51c89065d0, file \"/...3.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ningen.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    518         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    519                                finalizer=self._asyncgen_finalizer_hook)\n    520         try:\n    521             events._set_running_loop(self)\n    522             while True:\n--> 523                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    524                 if self._stopping:\n    525                     break\n    526         finally:\n    527             self._stopping = False\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1753                         logger.warning('Executing %s took %.3f seconds',\n   1754                                        _format_handle(handle), dt)\n   1755                 finally:\n   1756                     self._current_handle = None\n   1757             else:\n-> 1758                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(11, 1)>>\n   1759         handle = None  # Needed to break cycles when an exception occurs.\n   1760 \n   1761     def _set_coroutine_origin_tracking(self, enabled):\n   1762         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(11, 1)>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (11, 1)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=11, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'217cf8f80628413383ef242969270edf']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'217cf8f80628413383ef242969270edf'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-526-812aaa518a46>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>)\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n   2906                 code = compiler(mod, cell_name, \"single\")\n-> 2907                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>\n        result = <ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>\n   2908                     return True\n   2909 \n   2910             # Flush softspace\n   2911             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>, result=<ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\n/home/ningenkun/alicization/<ipython-input-526-812aaa518a46> in <module>()\n----> 1 get_ipython().run_cell_magic('time', '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_cols = len(ft_columns)\\nft_cols = np.array(ft_columns)\\nmask_cols = np.zeros(len(ft_columns), dtype='bool')\\nmask_scale = np.zeros(len(ft_columns), dtype='bool')\\ncv_cols = ['cv' + str(j) for j in range(10)]\\nresults = pd.DataFrame(np.zeros((n_cols*2, 12)), columns=['Col', 'Scale'] + cv_cols)\\n\\nscore = 0.8758\\nnp.random.seed(0)\\nnp.random.shuffle(ft_cols)\\nfor i in range(n_cols):\\n    score_ = [0, 0]\\n    for use_scaler in [0, 1]:\\n        mask_cols[i] = True\\n        mask_scale[i] = True if use_scaler else False\\n        k = i + use_scaler\\n        \\n        results.iloc[k, 0] = ft_cols[i]\\n        results.iloc[k, 1] = use_scaler\\n        t_cols = ft_cols[mask_cols & ~mask_scale]\\n        ts_cols = ft_cols[mask_cols & mask_scale]\\n\\n        results.iloc[k, cv_cols] = cross_val_score(pl.set_params(feats__pl_time__select__key=t_cols, feats__pl_time_scale__select__key=ts_cols), \\n                          X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\\n        \\n        score_[use_scaler] = results.iloc[k, cv_cols].mean()\\n        \\n    if score_[0] < score and score_[1] < score:\\n        mask_cols[i] = False\\n        mask_scale[i] = False\\n        \\n    if score_[0] > score and score_[1] < score:\\n        mask_scale[i] = False\\n        \\n    if score_[0] > score or score_[1] > score:\\n        score = max(score_)\\n    \\n    print(f'Column: {results.iloc[k, 0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\")\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\")\n   2162             # This will need to be updated if the internal calling logic gets\n   2163             # refactored, or else we'll be expanding the wrong variables.\n   2164             stack_depth = 2\n   2165             magic_arg_s = self.var_expand(line, stack_depth)\n   2166             with self.builtin_trap:\n-> 2167                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n   2168             return result\n   2169 \n   2170     def find_line_magic(self, magic_name):\n   2171         \"\"\"Find and return a line magic by name.\n\n...........................................................................\n/home/ningenkun/alicization/<decorator-gen-62> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", local_ns=None)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", None), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", None)\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", local_ns=None)\n   1232                 return\n   1233             end = clock2()\n   1234         else:\n   1235             st = clock2()\n   1236             try:\n-> 1237                 exec(code, glob, local_ns)\n        code = <code object <module> at 0x7f51799dbed0, file \"<timed exec>\", line 2>\n        glob = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n        local_ns = None\n   1238             except:\n   1239                 self.shell.showtraceback()\n   1240                 return\n   1241             end = clock2()\n\n...........................................................................\n/home/ningenkun/alicization/<timed exec> in <module>()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, groups=None, scoring='roc_auc', cv=TimeSeriesSplit(max_train_size=None, n_splits=10), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    338                                 scoring={'score': scorer}, cv=cv,\n    339                                 return_train_score=False,\n    340                                 n_jobs=n_jobs, verbose=verbose,\n    341                                 fit_params=fit_params,\n--> 342                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    343     return cv_results['test_score']\n    344 \n    345 \n    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, groups=None, scoring={'score': make_scorer(roc_auc_score, needs_threshold=True)}, cv=TimeSeriesSplit(max_train_size=None, n_splits=10), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method TimeSeriesSplit.split of TimeSeriesSplit(max_train_size=None, n_splits=10)>\n        X =                                                 ...    0             1  \n\n[253561 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Oct 24 14:13:48 2018\nPID: 7490                Python 3.7.0: /home/ningenkun/anaconda3/bin/python\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 23048, 23049, 23050]), test=array([23051, 23052, 23053, ..., 46099, 46100, 46101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y_train = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'feats': {}}\n        name = 'feats'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f517d4db400>), *args=(FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method FeatureUnion.fit_transform of Feat...std=True))]))],\n       transformer_weights=None)>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    734         \"\"\"\n    735         self._validate_transformers()\n    736         result = Parallel(n_jobs=self.n_jobs)(\n    737             delayed(_fit_transform_one)(trans, weight, X, y,\n    738                                         **fit_params)\n--> 739             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...std=True))]))],\n       transformer_weights=None)>\n    740 \n    741         if not result:\n    742             # All transformers are None\n    743             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object FeatureUnion.fit_transform.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method Pipeline.fit_transform of Pipeline...ler(copy=True, with_mean=True, with_std=True))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    278             Transformed samples\n    279         \"\"\"\n    280         last_step = self._final_estimator\n    281         Xt, fit_params = self._fit(X, y, **fit_params)\n    282         if hasattr(last_step, 'fit_transform'):\n--> 283             return last_step.fit_transform(Xt, y, **fit_params)\n        last_step.fit_transform = <bound method TransformerMixin.fit_transform of ...Scaler(copy=True, with_mean=True, with_std=True)>\n        Xt = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    284         elif last_step is None:\n    285             return Xt\n    286         else:\n    287             return last_step.fit(Xt, y, **fit_params).transform(Xt)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/base.py in fit_transform(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method StandardScaler.fit of StandardScaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    585         y : Passthrough for ``Pipeline`` compatibility.\n    586         \"\"\"\n    587 \n    588         # Reset internal state before fitting\n    589         self._reset()\n--> 590         return self.partial_fit(X, y)\n        self.partial_fit = <bound method StandardScaler.partial_fit of Stan...Scaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    591 \n    592     def partial_fit(self, X, y=None):\n    593         \"\"\"Online computation of mean and std on X for later scaling.\n    594         All of X is processed as a single batch. This is intended for cases\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in partial_fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    607             used for later scaling along the features axis.\n    608 \n    609         y : Passthrough for ``Pipeline`` compatibility.\n    610         \"\"\"\n    611         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n--> 612                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n        self = StandardScaler(copy=True, with_mean=True, with_std=True)\n    613 \n    614         # Even in the case of `with_mean=False`, we update the mean anyway\n    615         # This is needed for the incremental computation of the var\n    616         # See incr_mean_variance_axis and _incremental_mean_variance_axis\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(23051, 0), dtype=float64), accept_sparse=('csr', 'csc'), dtype=<class 'numpy.float64'>, order=None, copy=True, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=True, estimator=StandardScaler(copy=True, with_mean=True, with_std=True))\n    465         n_features = array.shape[1]\n    466         if n_features < ensure_min_features:\n    467             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    468                              \" a minimum of %d is required%s.\"\n    469                              % (n_features, shape_repr, ensure_min_features,\n--> 470                                 context))\n        context = ' by StandardScaler'\n    471 \n    472     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    473         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    474                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(23051, 0)) while a minimum of 1 is required by StandardScaler.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 248, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 213, in _fit\n    **fit_params_steps[name])\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py\", line 362, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 581, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 739, in fit_transform\n    for name, trans, weight in self._iter())\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n    self.results = batch()\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 581, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 283, in fit_transform\n    return last_step.fit_transform(Xt, y, **fit_params)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/base.py\", line 520, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\", line 590, in fit\n    return self.partial_fit(X, y)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\", line 612, in partial_fit\n    warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 470, in check_array\n    context))\nValueError: Found array with 0 feature(s) (shape=(23051, 0)) while a minimum of 1 is required by StandardScaler.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ningenkun/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Oct 24 14:13:48 2018\nPID: 7490                Python 3.7.0: /home/ningenkun/anaconda3/bin/python\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 23048, 23049, 23050]), test=array([23051, 23052, 23053, ..., 46099, 46100, 46101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y_train = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'feats': {}}\n        name = 'feats'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f517d4db400>), *args=(FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method FeatureUnion.fit_transform of Feat...std=True))]))],\n       transformer_weights=None)>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    734         \"\"\"\n    735         self._validate_transformers()\n    736         result = Parallel(n_jobs=self.n_jobs)(\n    737             delayed(_fit_transform_one)(trans, weight, X, y,\n    738                                         **fit_params)\n--> 739             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...std=True))]))],\n       transformer_weights=None)>\n    740 \n    741         if not result:\n    742             # All transformers are None\n    743             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object FeatureUnion.fit_transform.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method Pipeline.fit_transform of Pipeline...ler(copy=True, with_mean=True, with_std=True))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    278             Transformed samples\n    279         \"\"\"\n    280         last_step = self._final_estimator\n    281         Xt, fit_params = self._fit(X, y, **fit_params)\n    282         if hasattr(last_step, 'fit_transform'):\n--> 283             return last_step.fit_transform(Xt, y, **fit_params)\n        last_step.fit_transform = <bound method TransformerMixin.fit_transform of ...Scaler(copy=True, with_mean=True, with_std=True)>\n        Xt = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    284         elif last_step is None:\n    285             return Xt\n    286         else:\n    287             return last_step.fit(Xt, y, **fit_params).transform(Xt)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/base.py in fit_transform(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method StandardScaler.fit of StandardScaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    585         y : Passthrough for ``Pipeline`` compatibility.\n    586         \"\"\"\n    587 \n    588         # Reset internal state before fitting\n    589         self._reset()\n--> 590         return self.partial_fit(X, y)\n        self.partial_fit = <bound method StandardScaler.partial_fit of Stan...Scaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    591 \n    592     def partial_fit(self, X, y=None):\n    593         \"\"\"Online computation of mean and std on X for later scaling.\n    594         All of X is processed as a single batch. This is intended for cases\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in partial_fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    607             used for later scaling along the features axis.\n    608 \n    609         y : Passthrough for ``Pipeline`` compatibility.\n    610         \"\"\"\n    611         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n--> 612                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n        self = StandardScaler(copy=True, with_mean=True, with_std=True)\n    613 \n    614         # Even in the case of `with_mean=False`, we update the mean anyway\n    615         # This is needed for the incremental computation of the var\n    616         # See incr_mean_variance_axis and _incremental_mean_variance_axis\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(23051, 0), dtype=float64), accept_sparse=('csr', 'csc'), dtype=<class 'numpy.float64'>, order=None, copy=True, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=True, estimator=StandardScaler(copy=True, with_mean=True, with_std=True))\n    465         n_features = array.shape[1]\n    466         if n_features < ensure_min_features:\n    467             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    468                              \" a minimum of %d is required%s.\"\n    469                              % (n_features, shape_repr, ensure_min_features,\n--> 470                                 context))\n        context = ' by StandardScaler'\n    471 \n    472     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    473         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    474                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(23051, 0)) while a minimum of 1 is required by StandardScaler.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Oct 24 14:13:48 2018\nPID: 7490                Python 3.7.0: /home/ningenkun/anaconda3/bin/python\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 23048, 23049, 23050]), test=array([23051, 23052, 23053, ..., 46099, 46100, 46101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y_train = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'feats': {}}\n        name = 'feats'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f517d4db400>), *args=(FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method FeatureUnion.fit_transform of Feat...std=True))]))],\n       transformer_weights=None)>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    734         \"\"\"\n    735         self._validate_transformers()\n    736         result = Parallel(n_jobs=self.n_jobs)(\n    737             delayed(_fit_transform_one)(trans, weight, X, y,\n    738                                         **fit_params)\n--> 739             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...std=True))]))],\n       transformer_weights=None)>\n    740 \n    741         if not result:\n    742             # All transformers are None\n    743             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object FeatureUnion.fit_transform.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method Pipeline.fit_transform of Pipeline...ler(copy=True, with_mean=True, with_std=True))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    278             Transformed samples\n    279         \"\"\"\n    280         last_step = self._final_estimator\n    281         Xt, fit_params = self._fit(X, y, **fit_params)\n    282         if hasattr(last_step, 'fit_transform'):\n--> 283             return last_step.fit_transform(Xt, y, **fit_params)\n        last_step.fit_transform = <bound method TransformerMixin.fit_transform of ...Scaler(copy=True, with_mean=True, with_std=True)>\n        Xt = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    284         elif last_step is None:\n    285             return Xt\n    286         else:\n    287             return last_step.fit(Xt, y, **fit_params).transform(Xt)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/base.py in fit_transform(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method StandardScaler.fit of StandardScaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    585         y : Passthrough for ``Pipeline`` compatibility.\n    586         \"\"\"\n    587 \n    588         # Reset internal state before fitting\n    589         self._reset()\n--> 590         return self.partial_fit(X, y)\n        self.partial_fit = <bound method StandardScaler.partial_fit of Stan...Scaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    591 \n    592     def partial_fit(self, X, y=None):\n    593         \"\"\"Online computation of mean and std on X for later scaling.\n    594         All of X is processed as a single batch. This is intended for cases\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in partial_fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    607             used for later scaling along the features axis.\n    608 \n    609         y : Passthrough for ``Pipeline`` compatibility.\n    610         \"\"\"\n    611         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n--> 612                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n        self = StandardScaler(copy=True, with_mean=True, with_std=True)\n    613 \n    614         # Even in the case of `with_mean=False`, we update the mean anyway\n    615         # This is needed for the incremental computation of the var\n    616         # See incr_mean_variance_axis and _incremental_mean_variance_axis\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(23051, 0), dtype=float64), accept_sparse=('csr', 'csc'), dtype=<class 'numpy.float64'>, order=None, copy=True, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=True, estimator=StandardScaler(copy=True, with_mean=True, with_std=True))\n    465         n_features = array.shape[1]\n    466         if n_features < ensure_min_features:\n    467             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    468                              \" a minimum of %d is required%s.\"\n    469                              % (n_features, shape_repr, ensure_min_features,\n--> 470                                 context))\n        context = ' by StandardScaler'\n    471 \n    472     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    473         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    474                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(23051, 0)) while a minimum of 1 is required by StandardScaler.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/runpy.py in _run_code(code=<code object <module> at 0x7f51c89065d0, file \"/...3.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ningen.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f51c89065d0, file \"/...3.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ningen.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    518         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    519                                finalizer=self._asyncgen_finalizer_hook)\n    520         try:\n    521             events._set_running_loop(self)\n    522             while True:\n--> 523                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    524                 if self._stopping:\n    525                     break\n    526         finally:\n    527             self._stopping = False\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1753                         logger.warning('Executing %s took %.3f seconds',\n   1754                                        _format_handle(handle), dt)\n   1755                 finally:\n   1756                     self._current_handle = None\n   1757             else:\n-> 1758                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(11, 1)>>\n   1759         handle = None  # Needed to break cycles when an exception occurs.\n   1760 \n   1761     def _set_coroutine_origin_tracking(self, enabled):\n   1762         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(11, 1)>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (11, 1)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=11, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'217cf8f80628413383ef242969270edf']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'217cf8f80628413383ef242969270edf'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-526-812aaa518a46>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>)\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n   2906                 code = compiler(mod, cell_name, \"single\")\n-> 2907                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>\n        result = <ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>\n   2908                     return True\n   2909 \n   2910             # Flush softspace\n   2911             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>, result=<ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\n/home/ningenkun/alicization/<ipython-input-526-812aaa518a46> in <module>()\n----> 1 get_ipython().run_cell_magic('time', '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_cols = len(ft_columns)\\nft_cols = np.array(ft_columns)\\nmask_cols = np.zeros(len(ft_columns), dtype='bool')\\nmask_scale = np.zeros(len(ft_columns), dtype='bool')\\ncv_cols = ['cv' + str(j) for j in range(10)]\\nresults = pd.DataFrame(np.zeros((n_cols*2, 12)), columns=['Col', 'Scale'] + cv_cols)\\n\\nscore = 0.8758\\nnp.random.seed(0)\\nnp.random.shuffle(ft_cols)\\nfor i in range(n_cols):\\n    score_ = [0, 0]\\n    for use_scaler in [0, 1]:\\n        mask_cols[i] = True\\n        mask_scale[i] = True if use_scaler else False\\n        k = i + use_scaler\\n        \\n        results.iloc[k, 0] = ft_cols[i]\\n        results.iloc[k, 1] = use_scaler\\n        t_cols = ft_cols[mask_cols & ~mask_scale]\\n        ts_cols = ft_cols[mask_cols & mask_scale]\\n\\n        results.iloc[k, cv_cols] = cross_val_score(pl.set_params(feats__pl_time__select__key=t_cols, feats__pl_time_scale__select__key=ts_cols), \\n                          X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\\n        \\n        score_[use_scaler] = results.iloc[k, cv_cols].mean()\\n        \\n    if score_[0] < score and score_[1] < score:\\n        mask_cols[i] = False\\n        mask_scale[i] = False\\n        \\n    if score_[0] > score and score_[1] < score:\\n        mask_scale[i] = False\\n        \\n    if score_[0] > score or score_[1] > score:\\n        score = max(score_)\\n    \\n    print(f'Column: {results.iloc[k, 0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\")\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\")\n   2162             # This will need to be updated if the internal calling logic gets\n   2163             # refactored, or else we'll be expanding the wrong variables.\n   2164             stack_depth = 2\n   2165             magic_arg_s = self.var_expand(line, stack_depth)\n   2166             with self.builtin_trap:\n-> 2167                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n   2168             return result\n   2169 \n   2170     def find_line_magic(self, magic_name):\n   2171         \"\"\"Find and return a line magic by name.\n\n...........................................................................\n/home/ningenkun/alicization/<decorator-gen-62> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", local_ns=None)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", None), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", None)\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", local_ns=None)\n   1232                 return\n   1233             end = clock2()\n   1234         else:\n   1235             st = clock2()\n   1236             try:\n-> 1237                 exec(code, glob, local_ns)\n        code = <code object <module> at 0x7f51799dbed0, file \"<timed exec>\", line 2>\n        glob = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n        local_ns = None\n   1238             except:\n   1239                 self.shell.showtraceback()\n   1240                 return\n   1241             end = clock2()\n\n...........................................................................\n/home/ningenkun/alicization/<timed exec> in <module>()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, groups=None, scoring='roc_auc', cv=TimeSeriesSplit(max_train_size=None, n_splits=10), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    338                                 scoring={'score': scorer}, cv=cv,\n    339                                 return_train_score=False,\n    340                                 n_jobs=n_jobs, verbose=verbose,\n    341                                 fit_params=fit_params,\n--> 342                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    343     return cv_results['test_score']\n    344 \n    345 \n    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, groups=None, scoring={'score': make_scorer(roc_auc_score, needs_threshold=True)}, cv=TimeSeriesSplit(max_train_size=None, n_splits=10), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method TimeSeriesSplit.split of TimeSeriesSplit(max_train_size=None, n_splits=10)>\n        X =                                                 ...    0             1  \n\n[253561 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Oct 24 14:13:48 2018\nPID: 7490                Python 3.7.0: /home/ningenkun/anaconda3/bin/python\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 23048, 23049, 23050]), test=array([23051, 23052, 23053, ..., 46099, 46100, 46101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y_train = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'feats': {}}\n        name = 'feats'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f517d4db400>), *args=(FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method FeatureUnion.fit_transform of Feat...std=True))]))],\n       transformer_weights=None)>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    734         \"\"\"\n    735         self._validate_transformers()\n    736         result = Parallel(n_jobs=self.n_jobs)(\n    737             delayed(_fit_transform_one)(trans, weight, X, y,\n    738                                         **fit_params)\n--> 739             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...std=True))]))],\n       transformer_weights=None)>\n    740 \n    741         if not result:\n    742             # All transformers are None\n    743             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object FeatureUnion.fit_transform.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method Pipeline.fit_transform of Pipeline...ler(copy=True, with_mean=True, with_std=True))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    278             Transformed samples\n    279         \"\"\"\n    280         last_step = self._final_estimator\n    281         Xt, fit_params = self._fit(X, y, **fit_params)\n    282         if hasattr(last_step, 'fit_transform'):\n--> 283             return last_step.fit_transform(Xt, y, **fit_params)\n        last_step.fit_transform = <bound method TransformerMixin.fit_transform of ...Scaler(copy=True, with_mean=True, with_std=True)>\n        Xt = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    284         elif last_step is None:\n    285             return Xt\n    286         else:\n    287             return last_step.fit(Xt, y, **fit_params).transform(Xt)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/base.py in fit_transform(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method StandardScaler.fit of StandardScaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    585         y : Passthrough for ``Pipeline`` compatibility.\n    586         \"\"\"\n    587 \n    588         # Reset internal state before fitting\n    589         self._reset()\n--> 590         return self.partial_fit(X, y)\n        self.partial_fit = <bound method StandardScaler.partial_fit of Stan...Scaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    591 \n    592     def partial_fit(self, X, y=None):\n    593         \"\"\"Online computation of mean and std on X for later scaling.\n    594         All of X is processed as a single batch. This is intended for cases\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in partial_fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    607             used for later scaling along the features axis.\n    608 \n    609         y : Passthrough for ``Pipeline`` compatibility.\n    610         \"\"\"\n    611         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n--> 612                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n        self = StandardScaler(copy=True, with_mean=True, with_std=True)\n    613 \n    614         # Even in the case of `with_mean=False`, we update the mean anyway\n    615         # This is needed for the incremental computation of the var\n    616         # See incr_mean_variance_axis and _incremental_mean_variance_axis\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(23051, 0), dtype=float64), accept_sparse=('csr', 'csc'), dtype=<class 'numpy.float64'>, order=None, copy=True, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=True, estimator=StandardScaler(copy=True, with_mean=True, with_std=True))\n    465         n_features = array.shape[1]\n    466         if n_features < ensure_min_features:\n    467             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    468                              \" a minimum of %d is required%s.\"\n    469                              % (n_features, shape_repr, ensure_min_features,\n--> 470                                 context))\n        context = ' by StandardScaler'\n    471 \n    472     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    473         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    474                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(23051, 0)) while a minimum of 1 is required by StandardScaler.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_split = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "ft_cols = np.array(ft_columns)\n",
    "mask_cols = np.zeros(len(ft_columns), dtype='bool')\n",
    "mask_scale = np.zeros(len(ft_columns), dtype='bool')\n",
    "cv_cols = ['cv' + str(j) for j in range(10)]\n",
    "results = pd.DataFrame(np.zeros((n_cols*2, 12)), columns=['Col', 'Scale'] + cv_cols)\n",
    "\n",
    "score = 0.8758\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(ft_cols)\n",
    "for i in range(n_cols):\n",
    "    score_ = [0, 0]\n",
    "    for use_scaler in [0, 1]:\n",
    "        mask_cols[i] = True\n",
    "        mask_scale[i] = True if use_scaler else False\n",
    "        k = i + use_scaler\n",
    "        \n",
    "        results.iloc[k, 0] = ft_cols[i]\n",
    "        results.iloc[k, 1] = use_scaler\n",
    "        t_cols = ft_cols[mask_cols & ~mask_scale]\n",
    "        ts_cols = ft_cols[mask_cols & mask_scale]\n",
    "\n",
    "        results.iloc[k, cv_cols] = cross_val_score(pl.set_params(feats__pl_time__select__key=t_cols, feats__pl_time_scale__select__key=ts_cols), \n",
    "                          X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "        \n",
    "        score_[use_scaler] = results.iloc[k, cv_cols].mean()\n",
    "        \n",
    "    if score_[0] < score and score_[1] < score:\n",
    "        mask_cols[i] = False\n",
    "        mask_scale[i] = False\n",
    "        \n",
    "    if score_[0] > score and score_[1] < score:\n",
    "        mask_scale[i] = False\n",
    "        \n",
    "    if score_[0] > score or score_[1] > score:\n",
    "        score = max(score_)\n",
    "    \n",
    "    print(f'Column: {results.iloc[k, 0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyze_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8fad53d10fff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'analyze_results' is not defined"
     ]
    }
   ],
   "source": [
    "results, cv_results = analyze_results(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf__C</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.872588</td>\n",
       "      <td>0.074915</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.875889</td>\n",
       "      <td>0.074876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.875592</td>\n",
       "      <td>0.073643</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0.873039</td>\n",
       "      <td>0.071317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clf__C  mean_score  std_score  rank\n",
       "0       1    0.872588   0.074915     4\n",
       "1       3    0.875889   0.074876     1\n",
       "2      10    0.875592   0.073643     2\n",
       "3      30    0.873039   0.071317     3"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf C\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__count__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.866710</td>\n",
       "      <td>0.079719</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.868556</td>\n",
       "      <td>0.079310</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.869854</td>\n",
       "      <td>0.080480</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.870058</td>\n",
       "      <td>0.080325</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.870057</td>\n",
       "      <td>0.080277</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25000</td>\n",
       "      <td>0.870272</td>\n",
       "      <td>0.080233</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.870328</td>\n",
       "      <td>0.080248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__count__max_features  mean_score  std_score  rank\n",
       "0                                 5000    0.866710   0.079719     7\n",
       "1                                 8000    0.868556   0.079310     6\n",
       "2                                10000    0.869854   0.080480     5\n",
       "3                                15000    0.870058   0.080325     3\n",
       "4                                20000    0.870057   0.080277     4\n",
       "5                                25000    0.870272   0.080233     2\n",
       "6                                50000    0.870328   0.080248     1"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COUNT on sites_num find max_feat\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__count__max_df</th>\n",
       "      <th>feats__pl_text__count__ngram_range</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.868690</td>\n",
       "      <td>0.081518</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.864770</td>\n",
       "      <td>0.084686</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.869854</td>\n",
       "      <td>0.080480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.865331</td>\n",
       "      <td>0.084242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.865640</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.864722</td>\n",
       "      <td>0.083968</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__count__max_df feats__pl_text__count__ngram_range  \\\n",
       "0                            0.1                             (1, 1)   \n",
       "1                            0.1                             (1, 2)   \n",
       "2                            0.2                             (1, 1)   \n",
       "3                            0.2                             (1, 2)   \n",
       "4                            0.3                             (1, 1)   \n",
       "5                            0.3                             (1, 2)   \n",
       "\n",
       "   mean_score  std_score  rank  \n",
       "0    0.868690   0.081518     2  \n",
       "1    0.864770   0.084686     5  \n",
       "2    0.869854   0.080480     1  \n",
       "3    0.865331   0.084242     4  \n",
       "4    0.865640   0.075904     3  \n",
       "5    0.864722   0.083968     6  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COUNT on sites_num find max_df and n_gram\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__norm</th>\n",
       "      <th>feats__pl_text__tfidf__use_idf</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.851279</td>\n",
       "      <td>0.081743</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.845603</td>\n",
       "      <td>0.078184</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.872588</td>\n",
       "      <td>0.074915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.869540</td>\n",
       "      <td>0.075021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feats__pl_text__tfidf__norm  feats__pl_text__tfidf__use_idf  mean_score  \\\n",
       "0                          l1                            True    0.851279   \n",
       "1                          l1                           False    0.845603   \n",
       "2                          l2                            True    0.872588   \n",
       "3                          l2                           False    0.869540   \n",
       "\n",
       "   std_score  rank  \n",
       "0   0.081743     3  \n",
       "1   0.078184     4  \n",
       "2   0.074915     1  \n",
       "3   0.075021     2  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num find binary features\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__binary</th>\n",
       "      <th>feats__pl_text__tfidf__smooth_idf</th>\n",
       "      <th>feats__pl_text__tfidf__sublinear_tf</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.872248</td>\n",
       "      <td>0.077487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.872248</td>\n",
       "      <td>0.077487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.872588</td>\n",
       "      <td>0.074915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.869938</td>\n",
       "      <td>0.075274</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.872584</td>\n",
       "      <td>0.074907</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.869920</td>\n",
       "      <td>0.075279</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__binary  feats__pl_text__tfidf__smooth_idf  \\\n",
       "0                           True                               True   \n",
       "1                           True                               True   \n",
       "2                           True                              False   \n",
       "3                           True                              False   \n",
       "4                          False                               True   \n",
       "5                          False                               True   \n",
       "6                          False                              False   \n",
       "7                          False                              False   \n",
       "\n",
       "   feats__pl_text__tfidf__sublinear_tf  mean_score  std_score  rank  \n",
       "0                                 True    0.872248   0.077487     3  \n",
       "1                                False    0.872248   0.077487     3  \n",
       "2                                 True    0.872236   0.077471     5  \n",
       "3                                False    0.872236   0.077471     5  \n",
       "4                                 True    0.872588   0.074915     1  \n",
       "5                                False    0.869938   0.075274     7  \n",
       "6                                 True    0.872584   0.074907     2  \n",
       "7                                False    0.869920   0.075279     8  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num find binary features\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.868928</td>\n",
       "      <td>0.075332</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.869938</td>\n",
       "      <td>0.075274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.869377</td>\n",
       "      <td>0.074591</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.869607</td>\n",
       "      <td>0.074615</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.869721</td>\n",
       "      <td>0.074630</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25000</td>\n",
       "      <td>0.869725</td>\n",
       "      <td>0.074622</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.869728</td>\n",
       "      <td>0.074671</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_features  mean_score  std_score  rank\n",
       "0                                 5000    0.868928   0.075332     7\n",
       "1                                 8000    0.869938   0.075274     1\n",
       "2                                10000    0.869377   0.074591     6\n",
       "3                                15000    0.869607   0.074615     5\n",
       "4                                20000    0.869721   0.074630     4\n",
       "5                                25000    0.869725   0.074622     3\n",
       "6                                50000    0.869728   0.074671     2"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num find max_feat\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_df</th>\n",
       "      <th>feats__pl_text__tfidf__ngram_range</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.869420</td>\n",
       "      <td>0.076220</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.867631</td>\n",
       "      <td>0.079379</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.864607</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.869728</td>\n",
       "      <td>0.074671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.867434</td>\n",
       "      <td>0.078435</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.863854</td>\n",
       "      <td>0.080793</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.863373</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.863557</td>\n",
       "      <td>0.081261</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.859794</td>\n",
       "      <td>0.084414</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_df feats__pl_text__tfidf__ngram_range  \\\n",
       "0                            0.1                             (1, 1)   \n",
       "1                            0.1                             (1, 2)   \n",
       "2                            0.1                             (1, 3)   \n",
       "3                            0.2                             (1, 1)   \n",
       "4                            0.2                             (1, 2)   \n",
       "5                            0.2                             (1, 3)   \n",
       "6                            0.3                             (1, 1)   \n",
       "7                            0.3                             (1, 2)   \n",
       "8                            0.3                             (1, 3)   \n",
       "\n",
       "   mean_score  std_score  rank  \n",
       "0    0.869420   0.076220     2  \n",
       "1    0.867631   0.079379     3  \n",
       "2    0.864607   0.081646     5  \n",
       "3    0.869728   0.074671     1  \n",
       "4    0.867434   0.078435     4  \n",
       "5    0.863854   0.080793     6  \n",
       "6    0.863373   0.078525     8  \n",
       "7    0.863557   0.081261     7  \n",
       "8    0.859794   0.084414     9  "
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num find max_df and n_gram\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_df</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.869420</td>\n",
       "      <td>0.076220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.869512</td>\n",
       "      <td>0.076091</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.869728</td>\n",
       "      <td>0.074671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.866681</td>\n",
       "      <td>0.077613</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.863373</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_df  mean_score  std_score  rank\n",
       "0                           0.10    0.869420   0.076220     3\n",
       "1                           0.15    0.869512   0.076091     2\n",
       "2                           0.20    0.869728   0.074671     1\n",
       "3                           0.25    0.866681   0.077613     4\n",
       "4                           0.30    0.863373   0.078525     5"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num find max_df\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.839395</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.848638</td>\n",
       "      <td>0.080481</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.849106</td>\n",
       "      <td>0.079854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.848911</td>\n",
       "      <td>0.079858</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_features  mean_score  std_score  rank\n",
       "0                               1000.0    0.839395   0.077396     6\n",
       "1                               5000.0    0.848638   0.080481     5\n",
       "2                              10000.0    0.849106   0.079854     1\n",
       "3                              25000.0    0.848911   0.079858     4\n",
       "4                              50000.0    0.848937   0.079883     2\n",
       "5                                  NaN    0.848937   0.079883     2"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_dms\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.848638</td>\n",
       "      <td>0.080481</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.849106</td>\n",
       "      <td>0.079854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.848911</td>\n",
       "      <td>0.079858</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_features  mean_score  std_score  rank\n",
       "0                               5000.0    0.848638   0.080481     6\n",
       "1                              10000.0    0.849106   0.079854     1\n",
       "2                              25000.0    0.848911   0.079858     5\n",
       "3                              50000.0    0.848937   0.079883     2\n",
       "4                             100000.0    0.848937   0.079883     2\n",
       "5                                  NaN    0.848937   0.079883     2"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_ds\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.863212</td>\n",
       "      <td>0.078470</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.863428</td>\n",
       "      <td>0.078527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.863373</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.863373</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_features  mean_score  std_score  rank\n",
       "0                              10000.0    0.863212   0.078470     4\n",
       "1                              25000.0    0.863428   0.078527     1\n",
       "2                             100000.0    0.863373   0.078525     2\n",
       "3                                  NaN    0.863373   0.078525     2"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.839395</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.848638</td>\n",
       "      <td>0.080481</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.849106</td>\n",
       "      <td>0.079854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25000</td>\n",
       "      <td>0.848911</td>\n",
       "      <td>0.079858</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_features  mean_score  std_score  rank\n",
       "0                                 1000    0.839395   0.077396     6\n",
       "1                                 5000    0.848638   0.080481     5\n",
       "2                                10000    0.849106   0.079854     1\n",
       "3                                25000    0.848911   0.079858     4\n",
       "4                                50000    0.848937   0.079883     2\n",
       "5                               100000    0.848937   0.079883     2"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__count__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.863764</td>\n",
       "      <td>0.075713</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7500</td>\n",
       "      <td>0.864520</td>\n",
       "      <td>0.074875</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.865640</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.865493</td>\n",
       "      <td>0.075473</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.865668</td>\n",
       "      <td>0.075458</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__count__max_features  mean_score  std_score  rank\n",
       "0                                 5000    0.863764   0.075713     5\n",
       "1                                 7500    0.864520   0.074875     4\n",
       "2                                10000    0.865640   0.075904     2\n",
       "3                                20000    0.865493   0.075473     3\n",
       "4                                50000    0.865668   0.075458     1"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COUNT on sites_num \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.refit\n",
    "\n",
    "pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "write_to_submission_file(pred, 'pl_lr_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>split_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.989991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.996261</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.992144</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.991079</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.992333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable     value  split_num\n",
       "0         0  0.989991          1\n",
       "1         0  0.996261          2\n",
       "2         0  0.992144          3\n",
       "3         0  0.991079          4\n",
       "4         0  0.992333          5"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 408.375x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "melted = cv_results.melt()\n",
    "melted['split_num'] = list(range(cv_results.shape[0])) * cv_results.shape[1]\n",
    "\n",
    "sns.lmplot(x='split_num', y='value', data=melted, fit_reg=True, hue='variable');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sites_tf = full_sites.copy()\n",
    "\n",
    "for col in full_sites_tf.columns:\n",
    "    full_sites_tf[col] = full_sites_tf[col].map(sites_dict.site)\n",
    "\n",
    "full_sites_tf = full_sites_tf.fillna('')\n",
    "# df_tf_col = full_sites_tf.apply(lambda x: '.'.join([i for i in x if len(i)>0]), axis=1)\n",
    "# df_tf_col = df_tf_col.str.split('[.-]').str.join(' ')\n",
    "\n",
    "df_tf_col = full_sites_tf.apply(lambda x: ' '.join([i for i in x if len(i)>0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_df=.7, sublinear_tf=True)\n",
    "df_tf = vect.fit_transform(df_tf_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split = TimeSeriesSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df_tf[:idx_split,:]\n",
    "# X_test = df_tf[idx_split:,:]\n",
    "\n",
    "\n",
    "X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = [0.01, 0.03]\n",
    "# cw_values = [{0: 0.6, 1: 0.4}, {0: 0.9, 1: 0.1}, {0: 0.8, 1: 0.2}, {0: 0.7, 1: 0.3} , {0: 0.3, 1: 0.7}]\n",
    "\n",
    "lrcv = LogisticRegressionCV(Cs=c_values, scoring='roc_auc', n_jobs=-1, cv=kfold_split,\n",
    "                            verbose=1, class_weight='balanced', max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:  8.3min remaining: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 56s, sys: 2min 36s, total: 6min 33s\n",
      "Wall time: 10min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lrcv.fit(X_train, y_train);\n",
    "lrcv.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC [0.01]: 0.9574+-0.0141\n",
      "ROC_AUC [0.03]: 0.9587+-0.0136\n",
      "Best params: [0.03]\n"
     ]
    }
   ],
   "source": [
    "cvr = lrcv.scores_[1]\n",
    "idx = cvr.mean(axis=0).argmax()\n",
    "for i in range(cvr.shape[1]):\n",
    "    print(f\"ROC_AUC [{lrcv.Cs_[i]:>4}]: {cvr[:, i].mean():.4f}+-{cvr[:, i].std():.4f}\")\n",
    "print(f\"Best params: {lrcv.C_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC_AUC [0.01]: 0.9574+-0.0141\n",
    "ROC_AUC [0.03]: 0.9587+-0.0136\n",
    "ROC_AUC [ 0.1]: 0.9586+-0.0127\n",
    "ROC_AUC [ 0.3]: 0.9578+-0.0123\n",
    "ROC_AUC [ 1.0]: 0.9559+-0.0129\n",
    "ROC_AUC [ 3.0]: 0.9531+-0.0142\n",
    "ROC_AUC [10.0]: 0.9488+-0.0167\n",
    "Best params: [0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_tf[:idx_split,:]\n",
    "X_test = df_tf[idx_split:,:]\n",
    "\n",
    "# X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "# X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "logit = LogisticRegression(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 791 ms, sys: 159 ms, total: 950 ms\n",
      "Wall time: 8.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC: 0.8537+-0.0796\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROC_AUC: {cv_scores.mean():.4f}+-{cv_scores.std():.4f}\")\n",
    "# cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(X_train, y_train)\n",
    "logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
    "write_to_submission_file(logit_test_pred, 'subm_not_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check columns importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cw {0: 0.2, 1: 0.8}: 0.9542+-0.0159\n",
      "cw {0: 0.3, 1: 0.7}: 0.9537+-0.0162\n",
      "cw {0: 0.4, 1: 0.6}: 0.9529+-0.0165\n",
      "CPU times: user 3min 28s, sys: 22.5 s, total: 3min 51s\n",
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores_arr = list()\n",
    "\n",
    "for cw in [{0: 0.2, 1: 0.8}, {0: 0.3, 1: 0.7}, {0: 0.4, 1: 0.6}]:\n",
    "    vect = TfidfVectorizer(max_df=0.9, sublinear_tf=True)\n",
    "    df_tf = vect.fit_transform(df_tf_col)\n",
    "    params = {'C': 0.1, 'class_weight': cw, 'random_state':17, 'n_jobs':1}\n",
    "    \n",
    "    X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "    X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])\n",
    "    \n",
    "    logit = LogisticRegression(**params)\n",
    "    cv_scores_ = cross_val_score(logit, X_train, y_train, cv=kfold_split, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_scores_arr.append(cv_scores_)\n",
    "    \n",
    "    print(f\"cw {cw}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cw balanced  : 0.9586+-0.0127\n",
    "cw {0: 0.9, 1: 0.1}: 0.9390+-0.0209\n",
    "cw {0: 0.8, 1: 0.2}: 0.9451+-0.0188\n",
    "cw {0: 0.7, 1: 0.3}: 0.9483+-0.0178\n",
    "cw {0: 0.6, 1: 0.4}: 0.9504+-0.0172\n",
    "cw {0: 0.5, 1: 0.5}: 0.9518+-0.0168\n",
    "cw {0: 0.4, 1: 0.6}: 0.9529+-0.0165\n",
    "cw {0: 0.3, 1: 0.7}: 0.9537+-0.0162\n",
    "cw {0: 0.2, 1: 0.8}: 0.9542+-0.0159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define good tf-idf params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 0.5   : 0.8736+-0.1068\n",
      "max_df 0.6   : 0.8742+-0.1057\n",
      "max_df 0.7   : 0.8742+-0.1057\n",
      "max_df 0.8   : 0.8736+-0.1061\n",
      "max_df 0.9   : 0.8738+-0.1067\n",
      "max_df 1     : 0.8008+-0.0957\n",
      "CPU times: user 59.3 s, sys: 6.51 s, total: 1min 5s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "cv_scores_arr = list()\n",
    "\n",
    "for i in [.5, .6, .7, .8, .9, 1]:\n",
    "    vect = TfidfVectorizer(max_df=i, sublinear_tf=True)\n",
    "    df_tf = vect.fit_transform(df_tf_col)\n",
    "    \n",
    "    X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "    X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])\n",
    "    \n",
    "    logit = LogisticRegression(**params)\n",
    "    cv_scores_ = cross_val_score(logit, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_scores_arr.append(cv_scores_)\n",
    "    \n",
    "    print(f\"max_df {i:<6}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_df 0.0001: 0.9581+-0.0129\n",
    "min_df 0.001: 0.9560+-0.0120\n",
    "min_df 0.01: 0.9403+-0.0132\n",
    "min_df 0.1: 0.9110+-0.0209\n",
    "min_df 0.3: 0.8979+-0.0200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_df 0.50: 0.9582+-0.0125\n",
    "max_df 0.60: 0.9583+-0.0126\n",
    "max_df 0.70: 0.9583+-0.0126\n",
    "max_df 0.80: 0.9583+-0.0126\n",
    "max_df 0.85: 0.9583+-0.0126\n",
    "max_df 0.90: 0.9586+-0.0127\n",
    "max_df 0.95: 0.9586+-0.0127\n",
    "max_df 0.98: 0.9586+-0.0127\n",
    "max_df 1.00: 0.8968+-0.0200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define good hour split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC: 0.9530+-0.0141\n"
     ]
    }
   ],
   "source": [
    "good_cols = ['sin_min', 'cos_max', 'n_null', 'dt', 'year', 'morning', 'day', 'evening']\n",
    "mask = pd.Series(ft_columns).isin(good_cols).values\n",
    "\n",
    "X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask]])\n",
    "X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask]])\n",
    "\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "logit = LogisticRegression(**params)\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train, y_train, cv=kfold_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster\n",
    "\n",
    "print(f\"ROC_AUC: {cv_scores.mean():.4f}+-{cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins 2         : 0.9465+-0.0194 EXCLUDE\n",
      "Bins 3         : 0.9418+-0.0187 EXCLUDE\n",
      "Bins 4         : 0.9583+-0.0126 ADD\n",
      "Bins 5         : 0.9494+-0.0208 EXCLUDE\n",
      "Bins 6         : 0.9429+-0.0222 EXCLUDE\n",
      "Bins 7         : 0.9548+-0.0194 EXCLUDE\n",
      "Bins 8         : 0.9592+-0.0168 ADD\n",
      "CPU times: user 1min 29s, sys: 34.6 s, total: 2min 4s\n",
      "Wall time: 20min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "good_cols = ['sin_min', 'cos_max', 'n_null', 'dt', 'year']\n",
    "mask = pd.Series(ft_columns).isin(good_cols).values\n",
    "\n",
    "mask_hours = pd.Series(ft_columns).isin(['hour']).values\n",
    "hours = pd.Series(full_time[:, mask_hours].flatten())\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "cv_scores_arr = []\n",
    "\n",
    "for i in range(2, 9):\n",
    "    hours_dum = pd.get_dummies(pd.cut(hours, bins=i)).values\n",
    "    \n",
    "    X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask], hours_dum[:idx_split, :]])\n",
    "    X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask], hours_dum[idx_split:, :]])\n",
    "    \n",
    "    logit = LogisticRegression(**params)\n",
    "    cv_scores_ = cross_val_score(logit, X_train, y_train, cv=kfold_split, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_scores_arr.append(cv_scores_)\n",
    "    \n",
    "    d_cv = cv_scores_ - cv_scores\n",
    "    n_pos = (d_cv > 0).sum()\n",
    "    if not(d_cv.mean() > 0 and n_pos > 4):\n",
    "        print(f\"Bins {i:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} EXCLUDE\")\n",
    "    else:\n",
    "        cv_scores = cv_scores_.copy()\n",
    "        print(f\"Bins {i:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} ADD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete columns one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_columns = ['dow', 'weekend', 'day_', 'month', 'sin_min', 'cos_min', 'dt', 'dt_std', 'dt_mean', 'n_null',\n",
    "              'sin_max', 'cos_max', 'hour', 'year', 'minutes', 'myear', 'bin1', 'bin2', 'bin3', 'bin4']  # full_time.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8735747277102843"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "bin3      : 0.8723+-0.1060 OK  \n",
      "weekend   : 0.8803+-0.1304 EXCLUDE  \n",
      "bin4      : 0.8800+-0.1307 OK  \n",
      "dt_mean   : 0.8804+-0.1302 EXCLUDE  \n",
      "sin_max   : 0.8804+-0.1304 OK  \n",
      "bin2      : 0.8813+-0.1266 OK  \n",
      "dt        : 0.8802+-0.1307 OK  \n",
      "year      : 0.8803+-0.1301 OK  \n",
      "sin_min   : 0.8803+-0.1304 OK  \n",
      "day_      : 0.8803+-0.1300 OK  \n",
      "cos_min   : 0.8803+-0.1301 OK  \n",
      "minutes   : 0.8801+-0.1309 OK  \n",
      "n_null    : 0.8812+-0.1328 OK  \n",
      "dt_std    : 0.8804+-0.1303 OK  \n",
      "bin1      : 0.8804+-0.1304 OK  \n",
      "cos_max   : 0.8803+-0.1304 OK  \n",
      "month     : 0.8803+-0.1303 OK  \n",
      "dow       : 0.8799+-0.1290 OK  \n",
      "myear     : 0.8804+-0.1300 OK  \n",
      "hour      : 0.8806+-0.1304 EXCLUDE  \n",
      "******************************\n",
      "Iter 1\n",
      "month     : 0.8731+-0.1065 OK  \n",
      "bin1      : 0.8744+-0.1054 OK  \n",
      "dt        : 0.8736+-0.1061 OK  \n",
      "sin_max   : 0.8736+-0.1062 OK  \n",
      "day_      : 0.8744+-0.1061 OK  \n",
      "minutes   : 0.8736+-0.1062 OK  \n",
      "sin_min   : 0.8735+-0.1062 OK  \n",
      "bin2      : 0.8748+-0.0999 OK  \n",
      "dt_std    : 0.8736+-0.1061 OK  \n",
      "weekend   : 0.8803+-0.1304 EXCLUDE  \n",
      "year      : 0.8802+-0.1302 OK  \n",
      "dow       : 0.8798+-0.1291 OK  \n",
      "bin4      : 0.8800+-0.1307 OK  \n",
      "bin3      : 0.8803+-0.1290 OK  \n",
      "n_null    : 0.8811+-0.1330 OK  \n",
      "myear     : 0.8803+-0.1301 OK  \n",
      "dt_mean   : 0.8804+-0.1302 EXCLUDE  \n",
      "hour      : 0.8806+-0.1304 EXCLUDE  \n",
      "cos_max   : 0.8805+-0.1305 OK  \n",
      "cos_min   : 0.8805+-0.1302 OK  \n",
      "******************************\n",
      "Iter 2\n",
      "hour      : 0.8738+-0.1064 EXCLUDE  \n",
      "sin_min   : 0.8738+-0.1064 OK  \n",
      "bin3      : 0.8726+-0.1062 OK  \n",
      "dow       : 0.8674+-0.1234 OK  \n",
      "n_null    : 0.8742+-0.1094 OK  \n",
      "cos_min   : 0.8737+-0.1062 OK  \n",
      "month     : 0.8733+-0.1067 OK  \n",
      "sin_max   : 0.8738+-0.1064 OK  \n",
      "weekend   : 0.8805+-0.1305 EXCLUDE  \n",
      "bin2      : 0.8815+-0.1268 OK  \n",
      "dt_std    : 0.8805+-0.1305 OK  \n",
      "bin1      : 0.8805+-0.1307 OK  \n",
      "minutes   : 0.8806+-0.1312 OK  \n",
      "day_      : 0.8805+-0.1303 OK  \n",
      "cos_max   : 0.8804+-0.1306 OK  \n",
      "dt        : 0.8804+-0.1306 OK  \n",
      "bin4      : 0.8802+-0.1309 OK  \n",
      "year      : 0.8804+-0.1303 OK  \n",
      "myear     : 0.8805+-0.1302 OK  \n",
      "dt_mean   : 0.8806+-0.1304 EXCLUDE  \n",
      "******************************\n",
      "Iter 3\n",
      "minutes   : 0.8736+-0.1062 OK  \n",
      "day_      : 0.8744+-0.1061 OK  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-508:\n",
      "Process ForkPoolWorker-507:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "cv_scores_all = list()\n",
    "delete_dict = {col:0 for col in ft_columns}\n",
    "boundary = time_split.n_splits * 7 // 10\n",
    "\n",
    "for iter_ in range(10):\n",
    "    print(f\"Iter {iter_}\")\n",
    "    idx_order = list(range(n_cols))\n",
    "    np.random.seed(iter_)\n",
    "    np.random.shuffle(idx_order)\n",
    "    cv_scores_n_ = cv_scores.copy()\n",
    "    cv_scores_arr = list()\n",
    "    mask = np.ones(n_cols, dtype='bool')\n",
    "    \n",
    "    for n_ in range(-n_cols, 0):\n",
    "        i = idx_order[n_]\n",
    "        mask[i] = False\n",
    "        X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask]])\n",
    "        X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask]])\n",
    "        logit = LogisticRegression(**params)\n",
    "        cv_scores_ = cross_val_score(logit, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "        cv_scores_arr.append(cv_scores_)\n",
    "\n",
    "        d_cv = cv_scores_ - cv_scores_n_\n",
    "        n_neg = (d_cv > 0).sum()\n",
    "        if d_cv.mean() > 0 and n_neg >= boundary:\n",
    "            delete_dict[ft_columns[i]] += 1\n",
    "            cv_scores_n_ = cv_scores_.copy()\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} EXCLUDE  \")\n",
    "        else:\n",
    "            mask[i] = True\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} OK  \")\n",
    "    cv_scores_all.append(cv_scores_arr)\n",
    "    print('*' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "cv_scores_arr = []\n",
    "mask = np.zeros(n_cols, dtype='bool')\n",
    "for i in range(-n_cols, 0):\n",
    "    if 'dt_time' not in ft_columns[i]:\n",
    "        mask[i] = True\n",
    "        X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask]])\n",
    "        X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask]])\n",
    "        logit = LogisticRegression(**params)\n",
    "        cv_scores_ = cross_val_score(logit, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "        cv_scores_arr.append(cv_scores_)\n",
    "\n",
    "        d_cv = cv_scores_ - cv_scores\n",
    "        n_pos = (d_cv > 0).sum()\n",
    "        if not(d_cv.mean() > 0 and n_pos > d_cv.shape[0]/2):\n",
    "            mask[i] = False\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} EXCLUDE  \")\n",
    "        else:\n",
    "            cv_scores = cv_scores_.copy()\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} ADD  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dow       : 0.8544+-0.0874 EXCLUDE\n",
    "weekend   : 0.8399+-0.0972 EXCLUDE\n",
    "day_      : 0.8523+-0.0798 EXCLUDE\n",
    "month     : 0.8552+-0.0807 ADD\n",
    "sin_min   : 0.9028+-0.0783 ADD\n",
    "cos_min   : 0.8915+-0.0949 EXCLUDE\n",
    "dt        : 0.9019+-0.0794 EXCLUDE\n",
    "dt_std    : 0.9028+-0.0788 EXCLUDE\n",
    "dt_mean   : 0.9016+-0.0794 EXCLUDE\n",
    "n_null    : 0.9020+-0.0756 EXCLUDE\n",
    "morning   : 0.8923+-0.0966 EXCLUDE\n",
    "day       : 0.9008+-0.0817 EXCLUDE\n",
    "evening   : 0.9057+-0.0756 ADD\n",
    "sin_max   : 0.9057+-0.0756 ADD\n",
    "cos_max   : 0.8854+-0.1113 EXCLUDE\n",
    "hour      : 0.9007+-0.0837 EXCLUDE\n",
    "year      : 0.9099+-0.0767 ADD\n",
    "minutes   : 0.9054+-0.0844 EXCLUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols = ['sin_min', 'cos_max', 'n_null', 'dt', 'year', 'morning', 'day', 'evening']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer df_tf + time  max_df=.7 sublinear_tf=True\n",
    "ROC_AUC: 0.9168+-0.0542\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time  max_df=.7\n",
    "ROC_AUC: 0.9148+-0.0504\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time  max_df=.8\n",
    "ROC_AUC: 0.9125+-0.0538\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time\n",
    "ROC_AUC: 0.9115+-0.0546\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time (sites name full)\n",
    "ROC_AUC: 0.9115+-0.0546\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf\n",
    "ROC_AUC: 0.8575+-0.0753\n",
    "Best params: {'C': 20, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "CountVectorizer df_tf\n",
    "ROC_AUC: 0.8351+-0.0763\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred = logit_grid_searcher.predict_proba(X_test)[:, 1]\n",
    "write_to_submission_file(logit_test_pred, 'pred/a_sub_new_df_tfidf_drop_dub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets watch origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User sessions are chosen in the way they are not longer than half an hour or/and contain more than ten websites. I.e. a session is considered as ended either if a user has visited ten websites or if a session has lasted over thirty minutes.\n",
    "\n",
    "There are some empty values in the table, it means that some sessions contain less than ten websites. Replace empty values with 0 and change columns types to integer. Also load the websites dictionary and check how it looks like:\n",
    "\n",
    "**ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ðµ ÑÐµÑÑÐ¸Ð¸ Ð²Ñ‹Ð±Ð¸Ñ€Ð°ÑŽÑ‚ÑÑ Ñ‚Ð°Ðº, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¾Ð½Ð¸ Ð½Ðµ Ð¿Ñ€ÐµÐ²Ñ‹ÑˆÐ°Ð»Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÑÐ° Ð¸Ð»Ð¸ / Ð¸ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð»Ð¸ Ð±Ð¾Ð»ÐµÐµ Ð´ÐµÑÑÑ‚Ð¸ Ð²ÐµÐ±-ÑÐ°Ð¹Ñ‚Ð¾Ð². Ð¢Ð¾ ÐµÑÑ‚ÑŒ ÑÐµÐ°Ð½Ñ ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ÑÑ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð½Ñ‹Ð¼, ÐµÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¿Ð¾ÑÐµÑ‚Ð¸Ð» Ð´ÐµÑÑÑ‚ÑŒ Ð²ÐµÐ±-ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð¸Ð»Ð¸ ÐµÑÐ»Ð¸ ÑÐµÐ°Ð½Ñ Ð´Ð»Ð¸Ñ‚ÑÑ Ð±Ð¾Ð»ÐµÐµ Ñ‚Ñ€Ð¸Ð´Ñ†Ð°Ñ‚Ð¸ Ð¼Ð¸Ð½ÑƒÑ‚.**  \n",
    "\n",
    "**Ð’ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ ÐµÑÑ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿ÑƒÑÑ‚Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹, ÑÑ‚Ð¾ Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚, Ñ‡Ñ‚Ð¾ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÑÐµÐ°Ð½ÑÑ‹ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ Ð¼ÐµÐ½ÐµÐµ Ð´ÐµÑÑÑ‚Ð¸ Ð²ÐµÐ±-ÑÐ°Ð¹Ñ‚Ð¾Ð². Ð—Ð°Ð¼ÐµÐ½Ð¸Ñ‚Ðµ Ð¿ÑƒÑÑ‚Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð½Ð° 0 Ð¸ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚Ðµ Ñ‚Ð¸Ð¿Ñ‹ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð² Ð½Ð° integer. Ð¢Ð°ÐºÐ¶Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð²ÐµÐ±-ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ, ÐºÐ°Ðº ÑÑ‚Ð¾ Ð²Ñ‹Ð³Ð»ÑÐ´Ð¸Ñ‚:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-12 16:25:10</td>\n",
       "      <td>api.bing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-12 16:25:11</td>\n",
       "      <td>api.bing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>api.bing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>www.google.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>www.google.fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp           site\n",
       "0  2013-02-12 16:25:10   api.bing.com\n",
       "1  2013-02-12 16:25:11   api.bing.com\n",
       "2  2013-02-12 16:32:10   api.bing.com\n",
       "3  2013-02-12 16:32:11  www.google.fr\n",
       "4  2013-02-12 16:32:24  www.google.fr"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alice = pd.read_csv('data/train/Alice_log.csv')\n",
    "df_alice.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-18 10:19:27</td>\n",
       "      <td>ocsp.digicert.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-18 10:19:28</td>\n",
       "      <td>ocsp.digicert.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-18 10:19:28</td>\n",
       "      <td>clients1.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-18 10:19:29</td>\n",
       "      <td>gtglobal-ocsp.geotrust.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-18 10:19:29</td>\n",
       "      <td>clients1.google.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                        site\n",
       "0  2013-12-18 10:19:27           ocsp.digicert.com\n",
       "1  2013-12-18 10:19:28           ocsp.digicert.com\n",
       "2  2013-12-18 10:19:28         clients1.google.com\n",
       "3  2013-12-18 10:19:29  gtglobal-ocsp.geotrust.com\n",
       "4  2013-12-18 10:19:29         clients1.google.com"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user0010 = pd.read_csv('data/train/other_user_logs/user0010.csv')\n",
    "df_user0010.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>site6</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>952</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57     55 2013-01-12 08:05:57      0   \n",
       "54843          56 2013-01-12 08:37:23     55 2013-01-12 08:37:23     56   \n",
       "77292         946 2013-01-12 08:50:13    946 2013-01-12 08:50:14    951   \n",
       "114021        945 2013-01-12 08:50:17    948 2013-01-12 08:50:17    949   \n",
       "146670        947 2013-01-12 08:50:20    950 2013-01-12 08:50:20    948   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843      2013-01-12 09:07:07     55 2013-01-12 09:07:09      0   \n",
       "77292      2013-01-12 08:50:15    946 2013-01-12 08:50:15    946   \n",
       "114021     2013-01-12 08:50:18    948 2013-01-12 08:50:18    945   \n",
       "146670     2013-01-12 08:50:20    947 2013-01-12 08:50:21    950   \n",
       "\n",
       "                         time5  site6               time6  site7  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843                      NaT      0                 NaT      0   \n",
       "77292      2013-01-12 08:50:16    945 2013-01-12 08:50:16    948   \n",
       "114021     2013-01-12 08:50:18    946 2013-01-12 08:50:18    947   \n",
       "146670     2013-01-12 08:50:21    952 2013-01-12 08:50:21    946   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843                      NaT      0                 NaT      0   \n",
       "77292      2013-01-12 08:50:16    784 2013-01-12 08:50:16    949   \n",
       "114021     2013-01-12 08:50:19    945 2013-01-12 08:50:19    946   \n",
       "146670     2013-01-12 08:50:21    951 2013-01-12 08:50:22    946   \n",
       "\n",
       "                         time9  site10              time10  \n",
       "session_id                                                  \n",
       "21669                      NaT       0                 NaT  \n",
       "54843                      NaT       0                 NaT  \n",
       "77292      2013-01-12 08:50:17     946 2013-01-12 08:50:17  \n",
       "114021     2013-01-12 08:50:19     946 2013-01-12 08:50:20  \n",
       "146670     2013-01-12 08:50:22     947 2013-01-12 08:50:22  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2297 entries, 251175 to 244233\n",
      "Data columns (total 21 columns):\n",
      "site1     2297 non-null int32\n",
      "time1     2297 non-null datetime64[ns]\n",
      "site2     2297 non-null int32\n",
      "time2     2294 non-null datetime64[ns]\n",
      "site3     2297 non-null int32\n",
      "time3     2287 non-null datetime64[ns]\n",
      "site4     2297 non-null int32\n",
      "time4     2286 non-null datetime64[ns]\n",
      "site5     2297 non-null int32\n",
      "time5     2280 non-null datetime64[ns]\n",
      "site6     2297 non-null int32\n",
      "time6     2273 non-null datetime64[ns]\n",
      "site7     2297 non-null int32\n",
      "time7     2269 non-null datetime64[ns]\n",
      "site8     2297 non-null int32\n",
      "time8     2263 non-null datetime64[ns]\n",
      "site9     2297 non-null int32\n",
      "time9     2262 non-null datetime64[ns]\n",
      "site10    2297 non-null int32\n",
      "time10    2258 non-null datetime64[ns]\n",
      "target    2297 non-null int64\n",
      "dtypes: datetime64[ns](10), int32(10), int64(1)\n",
      "memory usage: 305.1 KB\n"
     ]
    }
   ],
   "source": [
    "train_df[train_df['target']==1].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "      <th>timestamp2</th>\n",
       "      <th>site2</th>\n",
       "      <th>timestamp3</th>\n",
       "      <th>site3</th>\n",
       "      <th>timestamp4</th>\n",
       "      <th>site4</th>\n",
       "      <th>timestamp5</th>\n",
       "      <th>site5</th>\n",
       "      <th>timestamp6</th>\n",
       "      <th>site6</th>\n",
       "      <th>timestamp7</th>\n",
       "      <th>site7</th>\n",
       "      <th>timestamp8</th>\n",
       "      <th>site8</th>\n",
       "      <th>timestamp9</th>\n",
       "      <th>site9</th>\n",
       "      <th>timestamp10</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-12 16:25:10</td>\n",
       "      <td>270</td>\n",
       "      <td>2013-02-12 16:25:11</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-12 16:25:11</td>\n",
       "      <td>270</td>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>270</td>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2013-02-12 16:32:28</td>\n",
       "      <td>7832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2013-02-12 16:32:28</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:29</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2013-02-12 16:32:28</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:29</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2013-02-12 16:32:34</td>\n",
       "      <td>7832.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  site          timestamp2   site2          timestamp3  \\\n",
       "0 2013-02-12 16:25:10   270 2013-02-12 16:25:11   270.0 2013-02-12 16:32:10   \n",
       "1 2013-02-12 16:25:11   270 2013-02-12 16:32:10   270.0 2013-02-12 16:32:11   \n",
       "2 2013-02-12 16:32:10   270 2013-02-12 16:32:11    21.0 2013-02-12 16:32:24   \n",
       "3 2013-02-12 16:32:11    21 2013-02-12 16:32:24    21.0 2013-02-12 16:32:25   \n",
       "4 2013-02-12 16:32:24    21 2013-02-12 16:32:25  7832.0 2013-02-12 16:32:25   \n",
       "\n",
       "    site3          timestamp4   site4          timestamp5   site5  \\\n",
       "0   270.0 2013-02-12 16:32:11    21.0 2013-02-12 16:32:24    21.0   \n",
       "1    21.0 2013-02-12 16:32:24    21.0 2013-02-12 16:32:25  7832.0   \n",
       "2    21.0 2013-02-12 16:32:25  7832.0 2013-02-12 16:32:25    21.0   \n",
       "3  7832.0 2013-02-12 16:32:25    21.0 2013-02-12 16:32:26  7832.0   \n",
       "4    21.0 2013-02-12 16:32:26  7832.0 2013-02-12 16:32:27    30.0   \n",
       "\n",
       "           timestamp6   site6          timestamp7   site7          timestamp8  \\\n",
       "0 2013-02-12 16:32:25  7832.0 2013-02-12 16:32:25    21.0 2013-02-12 16:32:26   \n",
       "1 2013-02-12 16:32:25    21.0 2013-02-12 16:32:26  7832.0 2013-02-12 16:32:27   \n",
       "2 2013-02-12 16:32:26  7832.0 2013-02-12 16:32:27    30.0 2013-02-12 16:32:27   \n",
       "3 2013-02-12 16:32:27    30.0 2013-02-12 16:32:27  7832.0 2013-02-12 16:32:27   \n",
       "4 2013-02-12 16:32:27  7832.0 2013-02-12 16:32:27    29.0 2013-02-12 16:32:28   \n",
       "\n",
       "    site8          timestamp9   site9         timestamp10  site10  \n",
       "0  7832.0 2013-02-12 16:32:27    30.0 2013-02-12 16:32:27  7832.0  \n",
       "1    30.0 2013-02-12 16:32:27  7832.0 2013-02-12 16:32:27    29.0  \n",
       "2  7832.0 2013-02-12 16:32:27    29.0 2013-02-12 16:32:28  7832.0  \n",
       "3    29.0 2013-02-12 16:32:28  7832.0 2013-02-12 16:32:29    37.0  \n",
       "4  7832.0 2013-02-12 16:32:29    37.0 2013-02-12 16:32:34  7832.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT = 30\n",
    "\n",
    "df_alice = pd.read_csv('data/train/Alice_log.csv')\n",
    "df_alice['timestamp'] = df_alice['timestamp'].apply(pd.to_datetime)\n",
    "for i in range(-1, -10, -1):\n",
    "    df_alice['timestamp' + str(-i+1)] = df_alice['timestamp'].shift(i)\n",
    "    df_alice['site' + str(-i+1)] = df_alice['site'].shift(i)\n",
    "    \n",
    "    df_alice['dt'] = (df_alice['timestamp' + str(-i+1)] - df_alice['timestamp']).dt.seconds / 60\n",
    "    df_alice.loc[df_alice['dt']>DT, ['timestamp' + str(-i+1), 'site' + str(-i+1)]] = None\n",
    "\n",
    "del df_alice['dt']\n",
    "\n",
    "to_int = dict(zip(sites_dict['site'], sites_dict.index))\n",
    "for col in df_alice.columns:\n",
    "    if 'site' in col:\n",
    "        df_alice[col] = df_alice[col].map(to_int)\n",
    "\n",
    "# df_alice['dt'] = (df_alice['timestamp'].shift(-1) - df_alice['timestamp']).dt.seconds / 60\n",
    "# df_alice['dt_10sites'] = (df_alice['timestamp'].shift(-10) - df_alice['timestamp']).dt.seconds / 60\n",
    "df_alice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
