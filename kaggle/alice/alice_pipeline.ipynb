{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set desired options\n",
    "\n",
    "from __future__ import division, print_function\n",
    "# Disable Anaconda warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function for writing predictions to a file\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(cv_res):\n",
    "    import re \n",
    "    \n",
    "    results = pd.DataFrame(cv_res['params'])\n",
    "    results['mean_score'] = cv_res['mean_test_score']\n",
    "    results['std_score'] = cv_res['std_test_score']\n",
    "    results['rank'] = cv_res['rank_test_score']\n",
    "#     results = results.sort_values('rank')\n",
    "    \n",
    "    n_splits = len(cv_res['split0_test_score'])\n",
    "    cv_results = np.r_[[clf.cv_results_[k] for k in clf.cv_results_.keys() if re.match(r'split\\d+_test', k)]]\n",
    "    cv_results = pd.DataFrame(cv_results)\n",
    "    melted = cv_results.melt()\n",
    "    melted['split_num'] = list(range(cv_results.shape[0])) * cv_results.shape[1]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10), gridspec_kw={'width_ratios':[2, 1]})\n",
    "    \n",
    "    sns.barplot(x='split_num', y='value', hue='variable', data=melted, ax=axes[0, 0]);\n",
    "    axes[0, 0].set_ylim(melted['value'].min()-.01, 1);\n",
    "    \n",
    "    sns.violinplot(x='variable', y='value', hue='variable', data=cv_results.melt(), ax=axes[0, 1], dodge=False);\n",
    "    sns.boxplot(x='variable', y='value', data=melted, ax=axes[1, 0]);\n",
    "    sns.barplot(x=results.index, y='std_score', data=results, ax=axes[1, 1]);\n",
    "    \n",
    "    sns.despine()\n",
    "    return results, cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites total: 48371\n"
     ]
    }
   ],
   "source": [
    "# Load websites dictionary\n",
    "with open(r\"data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# Create dataframe for the dictionary\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "\n",
    "# sites_dict['zone'] = sites_dict['site'].str.split('.').apply(lambda x: x[-1])\n",
    "# sites_dict.loc[sites_dict['zone'].str.isnumeric(), 'zone'] = 'ip_address'\n",
    "# sites_dict['zone_le'] = LabelEncoder().fit_transform(sites_dict['zone'])\n",
    "\n",
    "print(u'Websites total:', sites_dict.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training and test data sets\n",
    "train_df = pd.read_csv('data/train_sessions.csv',\n",
    "                      index_col='session_id')\n",
    "test_df = pd.read_csv('data/test_sessions.csv',\n",
    "                      index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch time1, ..., time10 columns to datetime type\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# Change site1, ..., site10 columns type to integer and fill NA-values with zeros\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target variable\n",
    "y_train = train_df['target']\n",
    "\n",
    "# United dataframe of the initial data \n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# Dataframe with indices of visited websites in session\n",
    "full_sites = full_df[sites]\n",
    "\n",
    "# Index to split the training and test data sets\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_features(df):\n",
    "    time_df = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    hour = df['time1'].dt.hour\n",
    "    time_df['hour'] = hour\n",
    "    time_df['day_'] = df['time1'].dt.day\n",
    "    time_df['month'] = df['time1'].dt.month\n",
    "    time_df['year'] = df['time1'].dt.year\n",
    "    time_df['myear'] = df['time1'].dt.year * 12 + df['time1'].dt.month\n",
    "    \n",
    "    time_df['morning'] = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "    time_df['day'] = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "    time_df['evening'] = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "\n",
    "    time_df['min'] = df['time1'] \n",
    "    time_df['max'] = df[times].max(axis=1)\n",
    "\n",
    "    for px in ['min', 'max']:\n",
    "        time_df['minutes'] = time_df[px].dt.hour * 60 + time_df[px].dt.minute\n",
    "        time_df['sin_'+px] = np.sin(2*np.pi*time_df['minutes']/1440.)\n",
    "        time_df['cos_'+px] = np.cos(2*np.pi*time_df['minutes']/1440.)\n",
    "\n",
    "    time_df['dow'] = time_df['min'].apply(lambda ts: ts.date().weekday())\n",
    "    time_df['weekend'] = (time_df['dow'] > 4).astype('int')\n",
    "    time_df['n_null'] = df[times].isnull().sum(axis=1)\n",
    "\n",
    "    time_df['dt'] = time_df['max'] - time_df['min']\n",
    "    for time in times[1:]:\n",
    "        dt_ = (df[time] - time_df['min']).fillna(time_df['dt'])\n",
    "        time_df['dt_' + time] = np.log1p(np.abs(dt_.astype('timedelta64[s]')))\n",
    "    time_df['dt'] = np.log1p(np.abs(time_df['dt'].astype('timedelta64[s]')))\n",
    "    time_df['dt_mean'] = time_df[['dt_' + time for time in times[1:]]].mean(axis=1)\n",
    "    time_df['dt_std'] = time_df[['dt_' + time for time in times[1:]]].std(axis=1)\n",
    "    time_df['dt_var'] = time_df[['dt_' + time for time in times[1:]]].var(axis=1)\n",
    "    \n",
    "    s_columns = [col for col in time_df.columns if time_df[col].dtype != '<M8[ns]']\n",
    "    \n",
    "#     s_scaler = StandardScaler()\n",
    "#     time_df[s_columns] = s_scaler.fit_transform(time_df[s_columns])\n",
    "\n",
    "    time_df = time_df.drop(['min', 'max'], axis=1)\n",
    "    time_df = time_df.drop(['dt_' + time for time in times[1:]], axis=1)\n",
    "    \n",
    "    for col in time_df.columns:\n",
    "        time_df[col] = time_df[col].fillna(time_df[col].mean())\n",
    "\n",
    "    return time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hour', 'day_', 'month', 'year', 'myear', 'morning', 'day', 'evening',\n",
      "       'minutes', 'sin_min', 'cos_min', 'sin_max', 'cos_max', 'dow', 'weekend',\n",
      "       'n_null', 'dt', 'dt_mean', 'dt_std', 'dt_var'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "full_time = get_time_features(full_df[times])\n",
    "ft_columns = full_time.columns\n",
    "\n",
    "hours_dum = pd.get_dummies(pd.cut(full_time['hour'], bins=4))\n",
    "full_time = pd.concat([full_time, hours_dum], axis=1)\n",
    "print(ft_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get site features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sites_tf = full_sites.copy()\n",
    "\n",
    "for col in full_sites_tf.columns:\n",
    "    full_sites_tf[col] = full_sites_tf[col].map(sites_dict.site)\n",
    "\n",
    "full_sites_tf = full_sites_tf.fillna('')\n",
    "# df_tf_col = full_sites_tf.apply(lambda x: '.'.join([i for i in x if len(i)>0]), axis=1)\n",
    "# df_tf_col = df_tf_col.str.split('[.-]').str.join(' ')\n",
    "\n",
    "text_cols = ['sites', 'sites_ds', 'sites_dms', 'sites_num']\n",
    "df_text = pd.DataFrame(columns=text_cols)\n",
    "\n",
    "df_text['sites'] = full_sites_tf.apply(lambda x: ' '.join([i for i in x if len(i)>0]), axis=1)\n",
    "df_text['sites_ds'] = df_text['sites'].str.split('[.]').str.join(' ')   # dot split\n",
    "df_text['sites_dms'] = df_text['sites'].str.split('[.-]').str.join(' ')   # dot, minus split\n",
    "df_text['sites_num'] = full_sites.astype('str').apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sites</th>\n",
       "      <th>sites_ds</th>\n",
       "      <th>sites_dms</th>\n",
       "      <th>sites_num</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>myear</th>\n",
       "      <th>morning</th>\n",
       "      <th>...</th>\n",
       "      <th>weekend</th>\n",
       "      <th>n_null</th>\n",
       "      <th>dt</th>\n",
       "      <th>dt_mean</th>\n",
       "      <th>dt_std</th>\n",
       "      <th>dt_var</th>\n",
       "      <th>(6.984, 11.0]</th>\n",
       "      <th>(11.0, 15.0]</th>\n",
       "      <th>(15.0, 19.0]</th>\n",
       "      <th>(19.0, 23.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204762</th>\n",
       "      <td>ocsp.thawte.com www.dropbox.com www.dropbox.co...</td>\n",
       "      <td>ocsp thawte com www dropbox com www dropbox co...</td>\n",
       "      <td>ocsp thawte com www dropbox com www dropbox co...</td>\n",
       "      <td>222 3346 3346 3359 55 2891 3346 0 0 0</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>24172</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.442222</td>\n",
       "      <td>0.245807</td>\n",
       "      <td>0.060421</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        sites  \\\n",
       "session_id                                                      \n",
       "204762      ocsp.thawte.com www.dropbox.com www.dropbox.co...   \n",
       "\n",
       "                                                     sites_ds  \\\n",
       "session_id                                                      \n",
       "204762      ocsp thawte com www dropbox com www dropbox co...   \n",
       "\n",
       "                                                    sites_dms  \\\n",
       "session_id                                                      \n",
       "204762      ocsp thawte com www dropbox com www dropbox co...   \n",
       "\n",
       "                                        sites_num  hour  day_  month  year  \\\n",
       "session_id                                                                   \n",
       "204762      222 3346 3346 3359 55 2891 3346 0 0 0    23    30      4  2014   \n",
       "\n",
       "            myear  morning      ...       weekend  n_null        dt   dt_mean  \\\n",
       "session_id                      ...                                             \n",
       "204762      24172        0      ...             0       3  2.564949  2.442222   \n",
       "\n",
       "              dt_std    dt_var  (6.984, 11.0]  (11.0, 15.0]  (15.0, 19.0]  \\\n",
       "session_id                                                                  \n",
       "204762      0.245807  0.060421              0             0             0   \n",
       "\n",
       "            (19.0, 23.0]  \n",
       "session_id                \n",
       "204762                 1  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.concat([df_text.iloc[:idx_split], full_time.iloc[:idx_split]], axis=1)\n",
    "X_test = pd.concat([df_text.iloc[idx_split:], full_time.iloc[idx_split:]], axis=1)\n",
    "\n",
    "X_train.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_text_tfidf = Pipeline([\n",
    "                ('select', TextSelector(key='sites_num')),\n",
    "                ('tfidf', TfidfVectorizer(max_df=0.2, max_features=8000, smooth_idf=True, sublinear_tf=True))\n",
    "                ])\n",
    "\n",
    "pl_text_count = Pipeline([\n",
    "                ('select', TextSelector(key='sites_num')),\n",
    "                ('count', CountVectorizer(max_df=0.2))\n",
    "                ])\n",
    "\n",
    "pl_time = Pipeline([\n",
    "                ('select', NumberSelector(key=ft_columns)),\n",
    "#                 ('scale', StandardScaler())\n",
    "                ])\n",
    "\n",
    "pl_time_scale = Pipeline([\n",
    "                ('select', NumberSelector(key=ft_columns)),\n",
    "                ('scale', StandardScaler())\n",
    "                ])\n",
    "\n",
    "feats = FeatureUnion([\n",
    "                    ('pl_text', pl_text_tfidf), \n",
    "#                     ('pl_time', pl_time),\n",
    "                    ('pl_time_scale', pl_time_scale)\n",
    "                    ])\n",
    "\n",
    "\n",
    "feats_ns = FeatureUnion([\n",
    "                    ('pl_text', pl_text_tfidf), \n",
    "                    ('pl_time', pl_time),\n",
    "#                     ('pl_time_scale', pl_time_scale)\n",
    "                    ])\n",
    "\n",
    "feats_all = FeatureUnion([\n",
    "                    ('pl_text', pl_text_tfidf), \n",
    "                    ('pl_time', pl_time),\n",
    "                    ('pl_time_scale', pl_time_scale)\n",
    "                    ])\n",
    "\n",
    "\n",
    "pl = Pipeline([\n",
    "                ('feats', feats),\n",
    "                ('clf', LogisticRegression(C=3, random_state=17))\n",
    "              ])\n",
    "\n",
    "pl_ns = Pipeline([\n",
    "                ('feats', feats_ns),\n",
    "                ('clf', LogisticRegression(C=3, random_state=17))\n",
    "              ])\n",
    "\n",
    "pl_all = Pipeline([\n",
    "                ('feats', feats_all),\n",
    "                ('clf', LogisticRegression(C=3, random_state=17))\n",
    "              ])\n",
    "\n",
    "# pl.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 3} 0.8758891615997804\n",
      "CPU times: user 40 s, sys: 13.7 s, total: 53.7 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "not_scale_cols = ['morning', 'day', 'evening', 'sin_min', 'cos_min', 'sin_max', 'cos_max', 'weekend']\n",
    "scale_cols = ['hour', 'day_', 'month', 'year', 'myear', 'minutes', 'dow', 'n_null',\n",
    "              'dt', 'dt_mean', 'dt_std', 'dt_var']\n",
    "\n",
    "params = {\n",
    "#             'clf__C': [1, 3, 10, 30],\n",
    "            'feats__pl_time__select__key': [],\n",
    "#                 'feats__pl_text__count__max_features': [5000, 8000, 10000, 15000, 20000, 25000, 50000],\n",
    "#                  'feats__pl_text__count__max_df': [0.1, 0.2, 0.3],\n",
    "#                  'feats__pl_text__count__ngram_range': [(1, 1), (1, 2)],\n",
    "#                 'feats__pl_text__tfidf__norm': ['l1', 'l2'],\n",
    "#                 'feats__pl_text__tfidf__use_idf': [True, False],\n",
    "        }\n",
    "\n",
    "time_split = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "clf = GridSearchCV(pl, params, cv=time_split, verbose=1, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To scale or not to scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: hour       Score_s:0.90672 Score_ns:0.90664 Scale: True \n",
      "Column: day_       Score_s:0.87261 Score_ns:0.86138 Scale: True \n",
      "Column: month      Score_s:0.87545 Score_ns:0.87553 Scale: False \n",
      "Column: year       Score_s:0.87723 Score_ns:0.84114 Scale: True \n",
      "Column: myear      Score_s:0.87606 Score_ns:0.70731 Scale: True \n",
      "Column: morning    Score_s:0.92410 Score_ns:0.92411 Scale: False \n",
      "Column: day        Score_s:0.92675 Score_ns:0.92638 Scale: True \n",
      "Column: evening    Score_s:0.87861 Score_ns:0.87820 Scale: True \n",
      "Column: minutes    Score_s:0.90683 Score_ns:0.90409 Scale: True \n",
      "Column: sin_min    Score_s:0.91757 Score_ns:0.91758 Scale: False \n",
      "Column: cos_min    Score_s:0.88261 Score_ns:0.88261 Scale: False \n",
      "Column: sin_max    Score_s:0.91747 Score_ns:0.91747 Scale: False \n",
      "Column: cos_max    Score_s:0.88274 Score_ns:0.88274 Scale: False \n",
      "Column: dow        Score_s:0.87561 Score_ns:0.87537 Scale: True \n",
      "Column: weekend    Score_s:0.86175 Score_ns:0.86448 Scale: False \n",
      "Column: n_null     Score_s:0.87416 Score_ns:0.87413 Scale: True \n",
      "Column: dt         Score_s:0.87476 Score_ns:0.87458 Scale: True \n",
      "Column: dt_mean    Score_s:0.87493 Score_ns:0.87480 Scale: True \n",
      "Column: dt_std     Score_s:0.87552 Score_ns:0.87541 Scale: True \n",
      "Column: dt_var     Score_s:0.87550 Score_ns:0.87539 Scale: True \n",
      "CPU times: user 5min 3s, sys: 2min 1s, total: 7min 4s\n",
      "Wall time: 12min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_split = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "ft_cols = np.array(ft_columns)\n",
    "\n",
    "mask_cols = np.zeros(len(ft_columns), dtype='bool')\n",
    "\n",
    "cv_cols = ['cv' + str(j) for j in range(10)]\n",
    "results = pd.DataFrame(np.zeros((n_cols*2, 12)), columns=['Col', 'Score'] + cv_cols)\n",
    "\n",
    "for i in range(n_cols):\n",
    "    mask_cols[i] = True\n",
    "    \n",
    "    results.loc[i, 'Col'] = ft_cols[i]\n",
    "    ts_cols = ft_cols[mask_cols]\n",
    "\n",
    "    results.loc[i, cv_cols] = cross_val_score(pl.set_params(feats__pl_time_scale__select__key=ts_cols), \n",
    "                      X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    results.loc[i+n_cols, cv_cols] = cross_val_score(pl_ns.set_params(feats__pl_time__select__key=ts_cols), \n",
    "                      X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "    s1 = results.loc[i, cv_cols].mean()\n",
    "    s2 = results.loc[i+n_cols, cv_cols].mean()\n",
    "    \n",
    "    results.loc[i, 'Score'] = s1\n",
    "    results.loc[i+n_cols, 'Score'] = s2\n",
    "\n",
    "    print(f'Column: {ft_cols[i]:<10} Score_s:{s1:.5f} Score_ns:{s2:.5f} Scale: {s1 > s2} ')\n",
    "    mask_cols[i] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column: hour       Score_s:0.90672 Score_ns:0.90664 Scale: True  \n",
    "Column: day_       Score_s:0.87261 Score_ns:0.86138 Scale: True  \n",
    "Column: month      Score_s:0.87545 Score_ns:0.87553 Scale: False  \n",
    "Column: year       Score_s:0.87723 Score_ns:0.84114 Scale: True  \n",
    "Column: myear      Score_s:0.87606 Score_ns:0.70731 Scale: True  \n",
    "Column: morning    Score_s:0.92410 Score_ns:0.92411 Scale: False  \n",
    "Column: day        Score_s:0.92675 Score_ns:0.92638 Scale: True  \n",
    "Column: evening    Score_s:0.87861 Score_ns:0.87820 Scale: True  \n",
    "Column: minutes    Score_s:0.90683 Score_ns:0.90409 Scale: True  \n",
    "Column: sin_min    Score_s:0.91757 Score_ns:0.91758 Scale: False  \n",
    "Column: cos_min    Score_s:0.88261 Score_ns:0.88261 Scale: False  \n",
    "Column: sin_max    Score_s:0.91747 Score_ns:0.91747 Scale: False  \n",
    "Column: cos_max    Score_s:0.88274 Score_ns:0.88274 Scale: False  \n",
    "Column: dow        Score_s:0.87561 Score_ns:0.87537 Scale: True  \n",
    "Column: weekend    Score_s:0.86175 Score_ns:0.86448 Scale: False  \n",
    "Column: n_null     Score_s:0.87416 Score_ns:0.87413 Scale: True   \n",
    "Column: dt         Score_s:0.87476 Score_ns:0.87458 Scale: True  \n",
    "Column: dt_mean    Score_s:0.87493 Score_ns:0.87480 Scale: True  \n",
    "Column: dt_std     Score_s:0.87552 Score_ns:0.87541 Scale: True  \n",
    "Column: dt_var     Score_s:0.87550 Score_ns:0.87539 Scale: True  \n",
    "CPU times: user 5min 3s, sys: 2min 1s, total: 7min 4s   \n",
    "Wall time: 12min 31s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find useful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5\n",
      "Column: n_null     Score:0.87340 Use: False \n",
      "Column: minutes    Score:0.91721 Use: True \n",
      "Column: month      Score:0.91914 Use: True \n",
      "Column: dt_mean    Score:0.91955 Use: True \n",
      "Column: dt_var     Score:0.91975 Use: True \n",
      "Column: myear      Score:0.92065 Use: True \n",
      "Column: dt         Score:0.92037 Use: False \n",
      "Column: day_       Score:0.92073 Use: True \n",
      "Column: hour       Score:0.92063 Use: False \n",
      "Column: dt_std     Score:0.92080 Use: True \n",
      "Column: dow        Score:0.92435 Use: True \n",
      "Column: year       Score:0.92436 Use: False \n",
      "******************************\n",
      "Iter 6\n",
      "Column: hour       Score:0.92057 Use: True \n",
      "Column: year       Score:0.92057 Use: False \n",
      "Column: minutes    Score:0.91888 Use: False \n",
      "Column: dt         Score:0.91913 Use: False \n",
      "Column: n_null     Score:0.91904 Use: False \n",
      "Column: day_       Score:0.91887 Use: False \n",
      "Column: myear      Score:0.92052 Use: False \n",
      "Column: month      Score:0.91956 Use: False \n",
      "Column: dt_var     Score:0.91793 Use: False \n",
      "Column: dt_mean    Score:0.91769 Use: False \n",
      "Column: dt_std     Score:0.91742 Use: False \n",
      "Column: dow        Score:0.91957 Use: False \n",
      "******************************\n",
      "Iter 7\n",
      "Column: month      Score:0.87708 Use: True \n",
      "Column: dt_std     Score:0.87725 Use: True \n",
      "Column: minutes    Score:0.91925 Use: True \n",
      "Column: day_       Score:0.91860 Use: False \n",
      "Column: hour       Score:0.91906 Use: False \n",
      "Column: year       Score:0.92017 Use: True \n",
      "Column: dow        Score:0.92350 Use: True \n",
      "Column: dt_var     Score:0.92386 Use: True \n",
      "Column: dt         Score:0.92416 Use: True \n",
      "Column: myear      Score:0.92416 Use: False \n",
      "Column: dt_mean    Score:0.92404 Use: False \n",
      "Column: n_null     Score:0.92418 Use: False \n",
      "******************************\n",
      "Iter 8\n",
      "Column: dt_var     Score:0.92075 Use: True \n",
      "Column: myear      Score:0.92075 Use: False \n",
      "Column: dt_mean    Score:0.92075 Use: False \n",
      "Column: dt         Score:0.92081 Use: True \n",
      "Column: dow        Score:0.92410 Use: True \n",
      "Column: n_null     Score:0.92410 Use: False \n",
      "Column: month      Score:0.92394 Use: False \n",
      "Column: minutes    Score:0.92398 Use: False \n",
      "Column: year       Score:0.88896 Use: False \n",
      "Column: dt_std     Score:0.88397 Use: False \n",
      "Column: hour       Score:0.92014 Use: False \n",
      "Column: day_       Score:0.88218 Use: False \n",
      "******************************\n",
      "Iter 9\n",
      "Column: minutes    Score:0.91777 Use: True \n",
      "Column: dt_std     Score:0.91798 Use: True \n",
      "Column: dt_mean    Score:0.91787 Use: False \n",
      "Column: dt_var     Score:0.91798 Use: False \n",
      "Column: dt         Score:0.91769 Use: False \n",
      "Column: dow        Score:0.91977 Use: True \n",
      "Column: myear      Score:0.92097 Use: True \n",
      "Column: day_       Score:0.91929 Use: False \n",
      "Column: hour       Score:0.92083 Use: False \n",
      "Column: year       Score:0.92350 Use: True \n",
      "Column: month      Score:0.92350 Use: False \n",
      "Column: n_null     Score:0.92355 Use: True \n",
      "******************************\n",
      "Iter 10\n",
      "Column: dt_mean    Score:0.92037 Use: True \n",
      "Column: myear      Score:0.92037 Use: False \n",
      "Column: day_       Score:0.92042 Use: True \n",
      "Column: dow        Score:0.92397 Use: True \n",
      "Column: n_null     Score:0.92383 Use: False \n",
      "Column: hour       Score:0.92397 Use: False \n",
      "Column: month      Score:0.92409 Use: True \n",
      "Column: dt_var     Score:0.92430 Use: True \n",
      "Column: dt_std     Score:0.92436 Use: True \n",
      "Column: minutes    Score:0.92436 Use: False \n",
      "Column: dt         Score:0.89001 Use: False \n",
      "Column: year       Score:0.89023 Use: False \n",
      "******************************\n",
      "Iter 11\n",
      "Column: month      Score:0.92000 Use: True \n",
      "Column: dow        Score:0.92289 Use: True \n",
      "Column: dt_std     Score:0.92289 Use: False \n",
      "Column: dt         Score:0.92283 Use: False \n",
      "Column: day_       Score:0.92222 Use: False \n",
      "Column: year       Score:0.92370 Use: True \n",
      "Column: n_null     Score:0.92370 Use: False \n",
      "Column: hour       Score:0.92371 Use: False \n",
      "Column: dt_var     Score:0.88917 Use: False \n",
      "Column: myear      Score:0.88866 Use: False \n",
      "Column: dt_mean    Score:0.88898 Use: False \n",
      "Column: minutes    Score:0.92340 Use: False \n",
      "******************************\n",
      "CPU times: user 1min 56s, sys: 1min 20s, total: 3min 16s\n",
      "Wall time: 12min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_splits=2\n",
    "time_split = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "sc_cols = ['hour', 'day_', 'month', 'year', 'myear', 'minutes', 'dow', 'n_null', 'dt', 'dt_mean', 'dt_std', 'dt_var']\n",
    "\n",
    "n_cols = len(sc_cols)\n",
    "ft_cols = np.array(sc_cols)\n",
    "\n",
    "mask_cols = np.zeros(len(sc_cols), dtype='bool')\n",
    "\n",
    "cv_cols = ['cv' + str(j) for j in range(n_splits)]\n",
    "results = pd.DataFrame(np.zeros((n_cols, 1+n_splits)), columns=['Col'] + cv_cols)\n",
    "sc_dict = {x:0 for x in sc_cols}\n",
    "\n",
    "for r in range(5, 12):\n",
    "    print(f\"Iter {r}\")\n",
    "    score = 0.8758\n",
    "    np.random.seed(r)\n",
    "    np.random.shuffle(ft_cols)\n",
    "    for i in range(n_cols):\n",
    "        score_ = 0\n",
    "\n",
    "        mask_cols[i] = True\n",
    "\n",
    "        results.loc[i, 'Col'] = ft_cols[i]\n",
    "        ts_cols = ft_cols[mask_cols]\n",
    "\n",
    "        results.loc[i, cv_cols] = cross_val_score(pl.set_params(feats__pl_time_scale__select__key=ts_cols), \n",
    "                          X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "        score_ = results.loc[i, cv_cols].mean()\n",
    "\n",
    "        if score_ - score < 0.00005:\n",
    "            mask_cols[i] = False\n",
    "        else:\n",
    "            score = score_\n",
    "            sc_dict[ft_cols[i]] += 1\n",
    "\n",
    "        print(f'Column: {results.loc[i, \"Col\"]:<10} Score:{score_:.5f} Use: {mask_cols[i]} ')\n",
    "    print('*' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column: dow        Score:0.88317 Use: True \n",
    "Column: dt_var     Score:0.88370 Use: True \n",
    "Column: myear      Score:0.88550 Use: True \n",
    "Column: dt_std     Score:0.88570 Use: True \n",
    "Column: month      Score:0.88938 Use: True \n",
    "Column: dt         Score:0.88948 Use: True \n",
    "Column: day_       Score:0.89017 Use: True \n",
    "Column: n_null     Score:0.88972 Use: False \n",
    "Column: dt_mean    Score:0.89001 Use: False \n",
    "Column: year       Score:0.89017 Use: False \n",
    "Column: hour       Score:0.92433 Use: True \n",
    "Column: minutes    Score:0.92427 Use: False \n",
    "------------------------------\n",
    "Iter 1\n",
    "Column: myear      Score:0.92428 Use: True \n",
    "Column: dt_std     Score:0.92428 Use: False \n",
    "Column: month      Score:0.92423 Use: False \n",
    "Column: hour       Score:0.91981 Use: False \n",
    "Column: dt_var     Score:0.88454 Use: False \n",
    "Column: day_       Score:0.88417 Use: False \n",
    "Column: dow        Score:0.88525 Use: False \n",
    "Column: n_null     Score:0.87465 Use: False \n",
    "Column: minutes    Score:0.91832 Use: False \n",
    "Column: year       Score:0.87799 Use: False \n",
    "Column: dt_mean    Score:0.87485 Use: False \n",
    "Column: dt         Score:0.87492 Use: False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "time_split = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "sc_cols = ['morning', 'day', 'evening', 'sin_min', 'cos_min', 'sin_max', 'cos_max']\n",
    "\n",
    "n_cols = len(sc_cols)\n",
    "ft_cols = np.array(sc_cols)\n",
    "\n",
    "mask_cols = np.zeros(len(sc_cols), dtype='bool')\n",
    "\n",
    "cv_cols = ['cv' + str(j) for j in range(10)]\n",
    "results = pd.DataFrame(np.zeros((n_cols, 11)), columns=['Col'] + cv_cols)\n",
    "sc_dict_ = {x:0 for x in sc_cols}\n",
    "\n",
    "for r in range(30):\n",
    "    print(f\"Iter {r}\")\n",
    "    score = 0.8758\n",
    "    np.random.seed(r)\n",
    "    np.random.shuffle(ft_cols)\n",
    "    for i in range(n_cols):\n",
    "        score_ = 0\n",
    "\n",
    "        mask_cols[i] = True\n",
    "\n",
    "        results.loc[i, 'Col'] = ft_cols[i]\n",
    "        ts_cols = ft_cols[mask_cols]\n",
    "\n",
    "        results.loc[i, cv_cols] = cross_val_score(pl_ns.set_params(feats__pl_time__select__key=ts_cols), \n",
    "                          X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "        score_ = results.loc[i, cv_cols].mean()\n",
    "\n",
    "        if score_ < score:\n",
    "            mask_cols[i] = False\n",
    "        else:\n",
    "            score = score_\n",
    "            sc_dict_[ft_cols[i]] += 1\n",
    "\n",
    "        print(f'Column: {results.loc[i, \"Col\"]:<10} Score:{score_:.5f} Use: {mask_cols[i]} ')\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'hour': 10,\n",
    " 'day_': 1,\n",
    " 'month': 7,\n",
    " 'year': 12,\n",
    " 'myear': 17,\n",
    " 'minutes': 17,\n",
    " 'dow': 8,\n",
    " 'n_null': 1,\n",
    " 'dt': 5,\n",
    " 'dt_mean': 4,\n",
    " 'dt_std': 6,\n",
    " 'dt_var': 15}\n",
    " \n",
    " {'morning': 23,\n",
    " 'day': 30,\n",
    " 'evening': 25,\n",
    " 'sin_min': 24,\n",
    " 'cos_min': 27,\n",
    " 'sin_max': 26,\n",
    " 'cos_max': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feats__pl_text__select__key',\n",
       " 'feats__pl_time__select__key',\n",
       " 'feats__pl_time_scale__select__key']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[z for z in pl_all.get_params().keys() if 'key' in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = [      'sites',    'sites_ds',   'sites_dms',   'sites_num',\n",
    "              'hour',        'day_',       'month',        'year',\n",
    "             'myear',     'morning',         'day',     'evening',\n",
    "           'minutes',     'sin_min',     'cos_min',     'sin_max',\n",
    "           'cos_max',         'dow',     'weekend',      'n_null',\n",
    "                'dt',     'dt_mean',      'dt_std',      'dt_var',\n",
    "       'spl1',  'spl2',  'spl3',  'spl4']\n",
    "\n",
    "X_test.columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2\n",
      "Column: 0 Score:0.9512+-0.0089 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.9525+-0.0072 pub_lb: 0.9348  \n",
      "Column: 2 Score:0.9523+-0.0076 pub_lb: 0.9352  \n",
      "Column: 3 Score:0.9509+-0.0100 pub_lb: 0.9394  \n",
      "Column: 4 Score:0.9514+-0.0101 pub_lb: 0.9411  \n",
      "******************************\n",
      "k = 3\n",
      "Column: 0 Score:0.9490+-0.0181 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.9503+-0.0149 pub_lb: 0.9348  \n",
      "Column: 2 Score:0.9496+-0.0157 pub_lb: 0.9352  \n",
      "Column: 3 Score:0.9490+-0.0173 pub_lb: 0.9394  \n",
      "Column: 4 Score:0.9496+-0.0173 pub_lb: 0.9411  \n",
      "******************************\n",
      "k = 4\n",
      "Column: 0 Score:0.9314+-0.0490 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.9260+-0.0630 pub_lb: 0.9348  \n",
      "Column: 2 Score:0.9253+-0.0642 pub_lb: 0.9352  \n",
      "Column: 3 Score:0.9371+-0.0421 pub_lb: 0.9394  \n",
      "Column: 4 Score:0.9381+-0.0411 pub_lb: 0.9411  \n",
      "******************************\n",
      "k = 5\n",
      "Column: 0 Score:0.9199+-0.0661 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.8988+-0.1129 pub_lb: 0.9348  \n",
      "Column: 2 Score:0.8977+-0.1143 pub_lb: 0.9352  \n",
      "Column: 3 Score:0.9197+-0.0679 pub_lb: 0.9394  \n",
      "Column: 4 Score:0.9210+-0.0661 pub_lb: 0.9411  \n",
      "******************************\n",
      "k = 6\n",
      "Column: 0 Score:0.9199+-0.0904 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.9205+-0.0941 pub_lb: 0.9348  \n",
      "Column: 2 Score:0.9195+-0.0957 pub_lb: 0.9352  \n",
      "Column: 3 Score:0.9173+-0.0974 pub_lb: 0.9394  \n",
      "Column: 4 Score:0.9184+-0.0961 pub_lb: 0.9411  \n",
      "******************************\n",
      "k = 7\n",
      "Column: 0 Score:0.9125+-0.0750 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.9048+-0.0975 pub_lb: 0.9348  \n",
      "Column: 2 Score:0.9037+-0.0989 pub_lb: 0.9352  \n",
      "Column: 3 Score:0.9099+-0.0821 pub_lb: 0.9394  \n",
      "Column: 4 Score:0.9110+-0.0809 pub_lb: 0.9411  \n",
      "******************************\n",
      "k = 8\n",
      "Column: 0 Score:0.9059+-0.0939 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.9059+-0.0916 pub_lb: 0.9348  \n",
      "Column: 2 Score:0.9054+-0.0921 pub_lb: 0.9352  \n",
      "Column: 3 Score:0.9069+-0.0926 pub_lb: 0.9394  \n",
      "Column: 4 Score:0.9078+-0.0918 pub_lb: 0.9411  \n",
      "******************************\n",
      "k = 9\n",
      "Column: 0 Score:0.9054+-0.0951 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.8936+-0.1161 pub_lb: 0.9348  \n",
      "Column: 2 Score:0.8932+-0.1168 pub_lb: 0.9352  \n",
      "Column: 3 Score:0.9039+-0.0999 pub_lb: 0.9394  \n",
      "Column: 4 Score:0.9049+-0.0995 pub_lb: 0.9411  \n",
      "******************************\n",
      "k = 10\n",
      "Column: 0 Score:0.9153+-0.0936 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.9043+-0.1090 pub_lb: 0.9348  \n",
      "Column: 2 Score:0.9037+-0.1095 pub_lb: 0.9352  \n",
      "Column: 3 Score:0.9119+-0.0996 pub_lb: 0.9394  \n",
      "Column: 4 Score:0.9127+-0.0994 pub_lb: 0.9411  \n",
      "******************************\n",
      "k = 11\n",
      "Column: 0 Score:0.9096+-0.0875 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.8947+-0.1285 pub_lb: 0.9348  \n",
      "Column: 2 Score:0.8940+-0.1293 pub_lb: 0.9352  \n",
      "Column: 3 Score:0.9052+-0.0975 pub_lb: 0.9394  \n",
      "Column: 4 Score:0.9059+-0.0964 pub_lb: 0.9411  \n",
      "******************************\n",
      "k = 12\n",
      "Column: 0 Score:0.9153+-0.0935 pub_lb: 0.9298  \n",
      "Column: 1 Score:0.9071+-0.1168 pub_lb: 0.9348  \n",
      "Column: 2 Score:0.9068+-0.1169 pub_lb: 0.9352  \n",
      "Column: 3 Score:0.9123+-0.1007 pub_lb: 0.9394  \n",
      "Column: 4 Score:0.9134+-0.0991 pub_lb: 0.9411  \n",
      "******************************\n",
      "CPU times: user 4min 57s, sys: 2min 6s, total: 7min 4s\n",
      "Wall time: 18min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "s_cols = [['hour', 'year', 'myear', 'minutes', 'dt_var'],\n",
    "          ['dow', 'month', 'dt_var', 'dt_mean', 'dt_std', 'day_'],\n",
    "          ['dow', 'month', 'dt_var', 'dt_mean', 'dt_std', 'day_'],\n",
    "         ['dow', 'month', 'minutes', 'dt_var'],\n",
    "         ['dow', 'month', 'minutes', 'dt_var', 'dt_mean', 'dt_std', 'day']]\n",
    "ns_cols = [['spl1',  'spl2',  'spl3',  'spl4'],\n",
    "           ['spl1',  'spl2',  'spl3',  'spl4', 'sin_max', 'cos_max'],\n",
    "           ['spl1',  'spl2',  'spl3',  'spl4', 'sin_max', 'cos_max'],\n",
    "          ['spl1',  'spl2',  'spl3',  'spl4'],\n",
    "          ['spl1',  'spl2',  'spl3',  'spl4']]\n",
    "\n",
    "max_df_cols = [.2,.2,.7,.2,.2]\n",
    "\n",
    "# s_cols = ['dow', 'month', 'dt_var', 'dt_mean', 'dt_std', 'day_']\n",
    "# ns_cols = ['spl1',  'spl2',  'spl3',  'spl4', 'sin_max', 'cos_max']\n",
    "\n",
    "# pl_all.set_params(feats__pl_time__select__key=ns_cols, feats__pl_time_scale__select__key=s_cols,\n",
    "#                  feats__pl_text__tfidf__max_df=0.7).fit(X_train, y_train)\n",
    "\n",
    "pub_lb = [0.9298, 0.9348, 0.9352, 0.9394, 0.9411]\n",
    "\n",
    "scores= dict()\n",
    "\n",
    "for k in range(2, 13):\n",
    "    scores[k] = list()\n",
    "    print(f\"k = {k}\")\n",
    "    time_split = TimeSeriesSplit(n_splits=k)\n",
    "#     time_split = KFold(n_splits=k, shuffle=False)\n",
    "\n",
    "\n",
    "    n_cols = len(s_cols)\n",
    "    cv_cols = ['cv' + str(j) for j in range(10)]\n",
    "#     results = pd.DataFrame(np.zeros((n_cols, 11)), columns=['Col'] + cv_cols)\n",
    "\n",
    "    for i in range(n_cols):\n",
    "\n",
    "#         results.loc[i, 'Col'] = i\n",
    "\n",
    "        s = cross_val_score(pl_all.set_params(feats__pl_time__select__key=ns_cols[i],\n",
    "                                            feats__pl_time_scale__select__key=s_cols[i],\n",
    "                                             feats__pl_text__tfidf__max_df=max_df_cols[i]),\n",
    "                                                  X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "#         score_ = s.mean()\n",
    "        scores[k].append(s)\n",
    "        print(f'Column: {i} Score:{s.mean():.4f}+-{s.std():.4f} pub_lb: {pub_lb[i]:.4f}  ')\n",
    "    print('*' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.6699654 , 0.81788942, 0.96978259, 0.96861404, 0.924379  ,\n",
       "        0.97675274, 0.92717744, 0.9500498 , 0.97442405, 0.97364177]),\n",
       " array([0.64219609, 0.75120815, 0.96340632, 0.96893535, 0.9308179 ,\n",
       "        0.97537204, 0.90323302, 0.95135484, 0.97562234, 0.98080977]),\n",
       " array([0.64003451, 0.75000135, 0.96367505, 0.96711823, 0.93007607,\n",
       "        0.97509269, 0.90240136, 0.95192411, 0.97547809, 0.9807077 ]),\n",
       " array([0.65135411, 0.80683067, 0.96131689, 0.97096088, 0.92470623,\n",
       "        0.97515072, 0.92379128, 0.95156365, 0.97442985, 0.9789706 ]),\n",
       " array([0.65104944, 0.81101446, 0.96171718, 0.97035083, 0.9245789 ,\n",
       "        0.9756117 , 0.92558811, 0.95257039, 0.97563684, 0.97937653])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 4\n",
    "Column: 0 Score:0.9314+-0.0490 pub_lb: 0.9230\n",
    "Column: 1 Score:0.9260+-0.0630 pub_lb: 0.9350\n",
    "Column: 2 Score:0.9371+-0.0421 pub_lb: 0.9390\n",
    "Column: 3 Score:0.9381+-0.0411 pub_lb: 0.9410\n",
    "++++++++++++++++++++++++++++++\n",
    "k = 8\n",
    "Column: 0 Score:0.9059+-0.0939 pub_lb: 0.9230\n",
    "Column: 1 Score:0.9059+-0.0916 pub_lb: 0.9350\n",
    "Column: 2 Score:0.9069+-0.0926 pub_lb: 0.9390\n",
    "Column: 3 Score:0.9078+-0.0918 pub_lb: 0.9410\n",
    "++++++++++++++++++++++++++++++\n",
    "k = 10\n",
    "Column: 0 Score:0.9153+-0.0936 pub_lb: 0.9230\n",
    "Column: 1 Score:0.9043+-0.1090 pub_lb: 0.9350\n",
    "Column: 2 Score:0.9119+-0.0996 pub_lb: 0.9390\n",
    "Column: 3 Score:0.9127+-0.0994 pub_lb: 0.9410\n",
    "++++++++++++++++++++++++++++++\n",
    "CPU times: user 1min 9s, sys: 28.7 s, total: 1min 37s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.012, 0.004, 0.002])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_lb = np.array(pub_lb)\n",
    "pub_lb[1:] - pub_lb[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_temp = scores.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00125215  0.00227488  0.00061319]\n",
      "[-0.00125215  0.00227488  0.00061319]\n"
     ]
    }
   ],
   "source": [
    "z = np.array(scores[10])\n",
    "mask = [False,  False,  False,  True,  True,  False,  True,  True,  True, True]\n",
    "print((z.T[mask, 1:] - z.T[mask, :3]).mean(axis=0))\n",
    "mask = [False,  False,  False,  True,  True,  False,  True,  True,  True, True]\n",
    "print((z.T[mask, 1:] - z.T[mask, :3]).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02991923,  0.00396873, -0.00046342,  0.00454786],\n",
       "       [ 0.04861634, -0.00537681,  0.00240264, -0.00128582],\n",
       "       [ 0.00276791,  0.00038948,  0.00061672,  0.00050791]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[1:, :] - z[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6699654  0.64219609 0.65135411 0.65104944]\n",
      "[-0.02776931  0.00915802 -0.00030467]\n",
      "\n",
      "[0.81788942 0.75120815 0.80683067 0.81101446]\n",
      "[-0.06668127  0.05562252  0.00418379]\n",
      "\n",
      "[0.96978259 0.96340632 0.96131689 0.96171718]\n",
      "[-0.00637627 -0.00208943  0.00040029]\n",
      "\n",
      "[0.96861404 0.96893535 0.97096088 0.97035083]\n",
      "[ 0.00032131  0.00202553 -0.00061005]\n",
      "\n",
      "[0.924379   0.9308179  0.92470623 0.9245789 ]\n",
      "[ 0.00643891 -0.00611168 -0.00012732]\n",
      "\n",
      "[0.97675274 0.97537204 0.97515072 0.9756117 ]\n",
      "[-0.0013807  -0.00022132  0.00046099]\n",
      "\n",
      "[0.92717744 0.90323302 0.92379128 0.92558811]\n",
      "[-0.02394442  0.02055826  0.00179684]\n",
      "\n",
      "[0.9500498  0.95135484 0.95156365 0.95257039]\n",
      "[0.00130504 0.00020881 0.00100674]\n",
      "\n",
      "[0.97442405 0.97562234 0.97442985 0.97563684]\n",
      "[ 0.00119829 -0.0011925   0.00120699]\n",
      "\n",
      "[0.97364177 0.98080977 0.9789706  0.97937653]\n",
      "[ 0.007168   -0.00183917  0.00040593]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(z[0])):\n",
    "    print(z[:, i])\n",
    "    print(z[1:, i] - z[:3, i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 3\n",
    "Column: 0 Score:0.9490+-0.0181 pub_lb: 0.929\n",
    "Column: 1 Score:0.9490+-0.0173 pub_lb: 0.939\n",
    "Column: 2 Score:0.9496+-0.0173 pub_lb: 0.941\n",
    "*------------------------------\n",
    "k = 4\n",
    "Column: 0 Score:0.9314+-0.0490 pub_lb: 0.929\n",
    "Column: 1 Score:0.9371+-0.0421 pub_lb: 0.939\n",
    "Column: 2 Score:0.9381+-0.0411 pub_lb: 0.941\n",
    "*------------------------------\n",
    "k = 5\n",
    "Column: 0 Score:0.9199+-0.0661 pub_lb: 0.929\n",
    "Column: 1 Score:0.9197+-0.0679 pub_lb: 0.939\n",
    "Column: 2 Score:0.9210+-0.0661 pub_lb: 0.941\n",
    "*------------------------------\n",
    "k = 8\n",
    "Column: 0 Score:0.9059+-0.0939 pub_lb: 0.929\n",
    "Column: 1 Score:0.9069+-0.0926 pub_lb: 0.939\n",
    "Column: 2 Score:0.9078+-0.0918 pub_lb: 0.941\n",
    "*------------------------------\n",
    "k = 10\n",
    "Column: 0 Score:0.9153+-0.0936 pub_lb: 0.929\n",
    "Column: 1 Score:0.9119+-0.0996 pub_lb: 0.939\n",
    "Column: 2 Score:0.9127+-0.0994 pub_lb: 0.941\n",
    "*------------------------------\n",
    "CPU times: user 1min 9s, sys: 30.6 s, total: 1min 40s\n",
    "Wall time: 4min 14s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 2\n",
    "Column: 0 Score:0.9512+-0.0089 \n",
    "Column: 1 Score:0.9509+-0.0100 \n",
    "*------------------------------\n",
    "k = 3\n",
    "Column: 0 Score:0.9490+-0.0181 \n",
    "Column: 1 Score:0.9490+-0.0173 \n",
    "*------------------------------\n",
    "k = 4\n",
    "Column: 0 Score:0.9314+-0.0490 \n",
    "Column: 1 Score:0.9371+-0.0421 \n",
    "*------------------------------\n",
    "k = 5\n",
    "Column: 0 Score:0.9199+-0.0661 \n",
    "Column: 1 Score:0.9197+-0.0679 \n",
    "*------------------------------\n",
    "k = 6\n",
    "Column: 0 Score:0.9199+-0.0904 \n",
    "Column: 1 Score:0.9173+-0.0974 \n",
    "*------------------------------\n",
    "k = 7\n",
    "Column: 0 Score:0.9125+-0.0750 \n",
    "Column: 1 Score:0.9099+-0.0821 \n",
    "*------------------------------\n",
    "k = 8\n",
    "Column: 0 Score:0.9059+-0.0939 \n",
    "Column: 1 Score:0.9069+-0.0926 \n",
    "*------------------------------\n",
    "k = 9\n",
    "Column: 0 Score:0.9054+-0.0951 \n",
    "Column: 1 Score:0.9039+-0.0999 \n",
    "*------------------------------\n",
    "k = 10\n",
    "Column: 0 Score:0.9153+-0.0936 \n",
    "Column: 1 Score:0.9119+-0.0996 \n",
    "*------------------------------\n",
    "k = 11\n",
    "Column: 0 Score:0.9096+-0.0875 \n",
    "Column: 1 Score:0.9052+-0.0975 \n",
    "*------------------------------\n",
    "k = 12\n",
    "Column: 0 Score:0.9153+-0.0935 \n",
    "Column: 1 Score:0.9123+-0.1007 \n",
    "*------------------------------\n",
    "k = 13\n",
    "Column: 0 Score:0.9096+-0.0774 \n",
    "Column: 1 Score:0.9077+-0.0844 \n",
    "*------------------------------\n",
    "CPU times: user 1min 59s, sys: 51.2 s, total: 2min 50s\n",
    "Wall time: 6min 41s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sites', 'sites_ds', 'sites_dms', 'sites_num', 'hour', 'day_', 'month',\n",
       "       'year', 'myear', 'morning', 'day', 'evening', 'minutes', 'sin_min',\n",
       "       'cos_min', 'sin_max', 'cos_max', 'dow', 'weekend', 'n_null', 'dt',\n",
       "       'dt_mean', 'dt_std', 'dt_var', 'spl1', 'spl2', 'spl3', 'spl4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cols = ['hour', 'year', 'myear', 'minutes', 'dt_var']\n",
    "ns_cols = ['spl1',  'spl2',  'spl3',  'spl4']\n",
    "\n",
    "s_cols = ['dow', 'month', 'minutes', 'dt_var']\n",
    "ns_cols = ['spl1',  'spl2',  'spl3',  'spl4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sites', 'sites_ds', 'sites_dms', 'sites_num', 'hour', 'day_', 'month',\n",
       "       'year', 'myear', 'morning', 'day', 'evening', 'minutes', 'sin_min',\n",
       "       'cos_min', 'sin_max', 'cos_max', 'dow', 'weekend', 'n_null', 'dt',\n",
       "       'dt_mean', 'dt_std', 'dt_var', 'spl1', 'spl2', 'spl3', 'spl4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feats__pl_text__tfidf__max_df']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in pl_all.get_params().keys() if 'max_df' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cols = ['dow', 'month', 'dt_var', 'dt_mean', 'dt_std', 'day_']\n",
    "ns_cols = ['spl1',  'spl2',  'spl3',  'spl4', 'sin_max', 'cos_max']\n",
    "\n",
    "pl_all.set_params(feats__pl_time__select__key=ns_cols, feats__pl_time_scale__select__key=s_cols,\n",
    "                 feats__pl_text__tfidf__max_df=0.7).fit(X_train, y_train)\n",
    "\n",
    "pred = pl_all.predict_proba(X_test)[:, 1]\n",
    "\n",
    "write_to_submission_file(pred, 'pl_optim_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['minutes', 'dt_mean', 'day', 'myear', 'month', 'dt', 'year'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_cols[mask_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/runpy.py in _run_code(code=<code object <module> at 0x7f51c89065d0, file \"/...3.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ningen.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f51c89065d0, file \"/...3.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ningen.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    518         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    519                                finalizer=self._asyncgen_finalizer_hook)\n    520         try:\n    521             events._set_running_loop(self)\n    522             while True:\n--> 523                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    524                 if self._stopping:\n    525                     break\n    526         finally:\n    527             self._stopping = False\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1753                         logger.warning('Executing %s took %.3f seconds',\n   1754                                        _format_handle(handle), dt)\n   1755                 finally:\n   1756                     self._current_handle = None\n   1757             else:\n-> 1758                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(11, 1)>>\n   1759         handle = None  # Needed to break cycles when an exception occurs.\n   1760 \n   1761     def _set_coroutine_origin_tracking(self, enabled):\n   1762         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(11, 1)>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (11, 1)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=11, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'217cf8f80628413383ef242969270edf']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'217cf8f80628413383ef242969270edf'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-526-812aaa518a46>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>)\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n   2906                 code = compiler(mod, cell_name, \"single\")\n-> 2907                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>\n        result = <ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>\n   2908                     return True\n   2909 \n   2910             # Flush softspace\n   2911             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>, result=<ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\n/home/ningenkun/alicization/<ipython-input-526-812aaa518a46> in <module>()\n----> 1 get_ipython().run_cell_magic('time', '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_cols = len(ft_columns)\\nft_cols = np.array(ft_columns)\\nmask_cols = np.zeros(len(ft_columns), dtype='bool')\\nmask_scale = np.zeros(len(ft_columns), dtype='bool')\\ncv_cols = ['cv' + str(j) for j in range(10)]\\nresults = pd.DataFrame(np.zeros((n_cols*2, 12)), columns=['Col', 'Scale'] + cv_cols)\\n\\nscore = 0.8758\\nnp.random.seed(0)\\nnp.random.shuffle(ft_cols)\\nfor i in range(n_cols):\\n    score_ = [0, 0]\\n    for use_scaler in [0, 1]:\\n        mask_cols[i] = True\\n        mask_scale[i] = True if use_scaler else False\\n        k = i + use_scaler\\n        \\n        results.iloc[k, 0] = ft_cols[i]\\n        results.iloc[k, 1] = use_scaler\\n        t_cols = ft_cols[mask_cols & ~mask_scale]\\n        ts_cols = ft_cols[mask_cols & mask_scale]\\n\\n        results.iloc[k, cv_cols] = cross_val_score(pl.set_params(feats__pl_time__select__key=t_cols, feats__pl_time_scale__select__key=ts_cols), \\n                          X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\\n        \\n        score_[use_scaler] = results.iloc[k, cv_cols].mean()\\n        \\n    if score_[0] < score and score_[1] < score:\\n        mask_cols[i] = False\\n        mask_scale[i] = False\\n        \\n    if score_[0] > score and score_[1] < score:\\n        mask_scale[i] = False\\n        \\n    if score_[0] > score or score_[1] > score:\\n        score = max(score_)\\n    \\n    print(f'Column: {results.iloc[k, 0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\")\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\")\n   2162             # This will need to be updated if the internal calling logic gets\n   2163             # refactored, or else we'll be expanding the wrong variables.\n   2164             stack_depth = 2\n   2165             magic_arg_s = self.var_expand(line, stack_depth)\n   2166             with self.builtin_trap:\n-> 2167                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n   2168             return result\n   2169 \n   2170     def find_line_magic(self, magic_name):\n   2171         \"\"\"Find and return a line magic by name.\n\n...........................................................................\n/home/ningenkun/alicization/<decorator-gen-62> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", local_ns=None)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", None), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", None)\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", local_ns=None)\n   1232                 return\n   1233             end = clock2()\n   1234         else:\n   1235             st = clock2()\n   1236             try:\n-> 1237                 exec(code, glob, local_ns)\n        code = <code object <module> at 0x7f51799dbed0, file \"<timed exec>\", line 2>\n        glob = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n        local_ns = None\n   1238             except:\n   1239                 self.shell.showtraceback()\n   1240                 return\n   1241             end = clock2()\n\n...........................................................................\n/home/ningenkun/alicization/<timed exec> in <module>()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, groups=None, scoring='roc_auc', cv=TimeSeriesSplit(max_train_size=None, n_splits=10), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    338                                 scoring={'score': scorer}, cv=cv,\n    339                                 return_train_score=False,\n    340                                 n_jobs=n_jobs, verbose=verbose,\n    341                                 fit_params=fit_params,\n--> 342                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    343     return cv_results['test_score']\n    344 \n    345 \n    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, groups=None, scoring={'score': make_scorer(roc_auc_score, needs_threshold=True)}, cv=TimeSeriesSplit(max_train_size=None, n_splits=10), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method TimeSeriesSplit.split of TimeSeriesSplit(max_train_size=None, n_splits=10)>\n        X =                                                 ...    0             1  \n\n[253561 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Oct 24 14:13:48 2018\nPID: 7490                Python 3.7.0: /home/ningenkun/anaconda3/bin/python\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 23048, 23049, 23050]), test=array([23051, 23052, 23053, ..., 46099, 46100, 46101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y_train = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'feats': {}}\n        name = 'feats'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f517d4db400>), *args=(FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method FeatureUnion.fit_transform of Feat...std=True))]))],\n       transformer_weights=None)>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    734         \"\"\"\n    735         self._validate_transformers()\n    736         result = Parallel(n_jobs=self.n_jobs)(\n    737             delayed(_fit_transform_one)(trans, weight, X, y,\n    738                                         **fit_params)\n--> 739             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...std=True))]))],\n       transformer_weights=None)>\n    740 \n    741         if not result:\n    742             # All transformers are None\n    743             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object FeatureUnion.fit_transform.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method Pipeline.fit_transform of Pipeline...ler(copy=True, with_mean=True, with_std=True))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    278             Transformed samples\n    279         \"\"\"\n    280         last_step = self._final_estimator\n    281         Xt, fit_params = self._fit(X, y, **fit_params)\n    282         if hasattr(last_step, 'fit_transform'):\n--> 283             return last_step.fit_transform(Xt, y, **fit_params)\n        last_step.fit_transform = <bound method TransformerMixin.fit_transform of ...Scaler(copy=True, with_mean=True, with_std=True)>\n        Xt = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    284         elif last_step is None:\n    285             return Xt\n    286         else:\n    287             return last_step.fit(Xt, y, **fit_params).transform(Xt)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/base.py in fit_transform(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method StandardScaler.fit of StandardScaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    585         y : Passthrough for ``Pipeline`` compatibility.\n    586         \"\"\"\n    587 \n    588         # Reset internal state before fitting\n    589         self._reset()\n--> 590         return self.partial_fit(X, y)\n        self.partial_fit = <bound method StandardScaler.partial_fit of Stan...Scaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    591 \n    592     def partial_fit(self, X, y=None):\n    593         \"\"\"Online computation of mean and std on X for later scaling.\n    594         All of X is processed as a single batch. This is intended for cases\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in partial_fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    607             used for later scaling along the features axis.\n    608 \n    609         y : Passthrough for ``Pipeline`` compatibility.\n    610         \"\"\"\n    611         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n--> 612                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n        self = StandardScaler(copy=True, with_mean=True, with_std=True)\n    613 \n    614         # Even in the case of `with_mean=False`, we update the mean anyway\n    615         # This is needed for the incremental computation of the var\n    616         # See incr_mean_variance_axis and _incremental_mean_variance_axis\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(23051, 0), dtype=float64), accept_sparse=('csr', 'csc'), dtype=<class 'numpy.float64'>, order=None, copy=True, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=True, estimator=StandardScaler(copy=True, with_mean=True, with_std=True))\n    465         n_features = array.shape[1]\n    466         if n_features < ensure_min_features:\n    467             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    468                              \" a minimum of %d is required%s.\"\n    469                              % (n_features, shape_repr, ensure_min_features,\n--> 470                                 context))\n        context = ' by StandardScaler'\n    471 \n    472     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    473         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    474                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(23051, 0)) while a minimum of 1 is required by StandardScaler.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 248, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 213, in _fit\n    **fit_params_steps[name])\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py\", line 362, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 581, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 739, in fit_transform\n    for name, trans, weight in self._iter())\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n    self.results = batch()\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 581, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 283, in fit_transform\n    return last_step.fit_transform(Xt, y, **fit_params)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/base.py\", line 520, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\", line 590, in fit\n    return self.partial_fit(X, y)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\", line 612, in partial_fit\n    warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 470, in check_array\n    context))\nValueError: Found array with 0 feature(s) (shape=(23051, 0)) while a minimum of 1 is required by StandardScaler.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ningenkun/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Oct 24 14:13:48 2018\nPID: 7490                Python 3.7.0: /home/ningenkun/anaconda3/bin/python\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 23048, 23049, 23050]), test=array([23051, 23052, 23053, ..., 46099, 46100, 46101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y_train = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'feats': {}}\n        name = 'feats'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f517d4db400>), *args=(FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method FeatureUnion.fit_transform of Feat...std=True))]))],\n       transformer_weights=None)>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    734         \"\"\"\n    735         self._validate_transformers()\n    736         result = Parallel(n_jobs=self.n_jobs)(\n    737             delayed(_fit_transform_one)(trans, weight, X, y,\n    738                                         **fit_params)\n--> 739             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...std=True))]))],\n       transformer_weights=None)>\n    740 \n    741         if not result:\n    742             # All transformers are None\n    743             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object FeatureUnion.fit_transform.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method Pipeline.fit_transform of Pipeline...ler(copy=True, with_mean=True, with_std=True))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    278             Transformed samples\n    279         \"\"\"\n    280         last_step = self._final_estimator\n    281         Xt, fit_params = self._fit(X, y, **fit_params)\n    282         if hasattr(last_step, 'fit_transform'):\n--> 283             return last_step.fit_transform(Xt, y, **fit_params)\n        last_step.fit_transform = <bound method TransformerMixin.fit_transform of ...Scaler(copy=True, with_mean=True, with_std=True)>\n        Xt = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    284         elif last_step is None:\n    285             return Xt\n    286         else:\n    287             return last_step.fit(Xt, y, **fit_params).transform(Xt)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/base.py in fit_transform(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method StandardScaler.fit of StandardScaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    585         y : Passthrough for ``Pipeline`` compatibility.\n    586         \"\"\"\n    587 \n    588         # Reset internal state before fitting\n    589         self._reset()\n--> 590         return self.partial_fit(X, y)\n        self.partial_fit = <bound method StandardScaler.partial_fit of Stan...Scaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    591 \n    592     def partial_fit(self, X, y=None):\n    593         \"\"\"Online computation of mean and std on X for later scaling.\n    594         All of X is processed as a single batch. This is intended for cases\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in partial_fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    607             used for later scaling along the features axis.\n    608 \n    609         y : Passthrough for ``Pipeline`` compatibility.\n    610         \"\"\"\n    611         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n--> 612                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n        self = StandardScaler(copy=True, with_mean=True, with_std=True)\n    613 \n    614         # Even in the case of `with_mean=False`, we update the mean anyway\n    615         # This is needed for the incremental computation of the var\n    616         # See incr_mean_variance_axis and _incremental_mean_variance_axis\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(23051, 0), dtype=float64), accept_sparse=('csr', 'csc'), dtype=<class 'numpy.float64'>, order=None, copy=True, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=True, estimator=StandardScaler(copy=True, with_mean=True, with_std=True))\n    465         n_features = array.shape[1]\n    466         if n_features < ensure_min_features:\n    467             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    468                              \" a minimum of %d is required%s.\"\n    469                              % (n_features, shape_repr, ensure_min_features,\n--> 470                                 context))\n        context = ' by StandardScaler'\n    471 \n    472     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    473         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    474                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(23051, 0)) while a minimum of 1 is required by StandardScaler.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Oct 24 14:13:48 2018\nPID: 7490                Python 3.7.0: /home/ningenkun/anaconda3/bin/python\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 23048, 23049, 23050]), test=array([23051, 23052, 23053, ..., 46099, 46100, 46101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y_train = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'feats': {}}\n        name = 'feats'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f517d4db400>), *args=(FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method FeatureUnion.fit_transform of Feat...std=True))]))],\n       transformer_weights=None)>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    734         \"\"\"\n    735         self._validate_transformers()\n    736         result = Parallel(n_jobs=self.n_jobs)(\n    737             delayed(_fit_transform_one)(trans, weight, X, y,\n    738                                         **fit_params)\n--> 739             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...std=True))]))],\n       transformer_weights=None)>\n    740 \n    741         if not result:\n    742             # All transformers are None\n    743             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object FeatureUnion.fit_transform.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method Pipeline.fit_transform of Pipeline...ler(copy=True, with_mean=True, with_std=True))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    278             Transformed samples\n    279         \"\"\"\n    280         last_step = self._final_estimator\n    281         Xt, fit_params = self._fit(X, y, **fit_params)\n    282         if hasattr(last_step, 'fit_transform'):\n--> 283             return last_step.fit_transform(Xt, y, **fit_params)\n        last_step.fit_transform = <bound method TransformerMixin.fit_transform of ...Scaler(copy=True, with_mean=True, with_std=True)>\n        Xt = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    284         elif last_step is None:\n    285             return Xt\n    286         else:\n    287             return last_step.fit(Xt, y, **fit_params).transform(Xt)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/base.py in fit_transform(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method StandardScaler.fit of StandardScaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    585         y : Passthrough for ``Pipeline`` compatibility.\n    586         \"\"\"\n    587 \n    588         # Reset internal state before fitting\n    589         self._reset()\n--> 590         return self.partial_fit(X, y)\n        self.partial_fit = <bound method StandardScaler.partial_fit of Stan...Scaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    591 \n    592     def partial_fit(self, X, y=None):\n    593         \"\"\"Online computation of mean and std on X for later scaling.\n    594         All of X is processed as a single batch. This is intended for cases\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in partial_fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    607             used for later scaling along the features axis.\n    608 \n    609         y : Passthrough for ``Pipeline`` compatibility.\n    610         \"\"\"\n    611         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n--> 612                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n        self = StandardScaler(copy=True, with_mean=True, with_std=True)\n    613 \n    614         # Even in the case of `with_mean=False`, we update the mean anyway\n    615         # This is needed for the incremental computation of the var\n    616         # See incr_mean_variance_axis and _incremental_mean_variance_axis\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(23051, 0), dtype=float64), accept_sparse=('csr', 'csc'), dtype=<class 'numpy.float64'>, order=None, copy=True, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=True, estimator=StandardScaler(copy=True, with_mean=True, with_std=True))\n    465         n_features = array.shape[1]\n    466         if n_features < ensure_min_features:\n    467             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    468                              \" a minimum of %d is required%s.\"\n    469                              % (n_features, shape_repr, ensure_min_features,\n--> 470                                 context))\n        context = ' by StandardScaler'\n    471 \n    472     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    473         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    474                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(23051, 0)) while a minimum of 1 is required by StandardScaler.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/runpy.py in _run_code(code=<code object <module> at 0x7f51c89065d0, file \"/...3.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ningen.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f51c89065d0, file \"/...3.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/__pycache__/ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.7/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ningen.../python3.7/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    518         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    519                                finalizer=self._asyncgen_finalizer_hook)\n    520         try:\n    521             events._set_running_loop(self)\n    522             while True:\n--> 523                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    524                 if self._stopping:\n    525                     break\n    526         finally:\n    527             self._stopping = False\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1753                         logger.warning('Executing %s took %.3f seconds',\n   1754                                        _format_handle(handle), dt)\n   1755                 finally:\n   1756                     self._current_handle = None\n   1757             else:\n-> 1758                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(11, 1)>>\n   1759         handle = None  # Needed to break cycles when an exception occurs.\n   1760 \n   1761     def _set_coroutine_origin_tracking(self, enabled):\n   1762         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(11, 1)>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (11, 1)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=11, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'217cf8f80628413383ef242969270edf']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'217cf8f80628413383ef242969270edf'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 24, 14, 13, 44, 276856, tzinfo=tzlocal()), 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'session': '217cf8f80628413383ef242969270edf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'eec75fedec90401889f8b52178acf4f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"%%time\\n\\ntime_split = TimeSeriesSplit(n_splits=10...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-526-812aaa518a46>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>)\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n   2906                 code = compiler(mod, cell_name, \"single\")\n-> 2907                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>\n        result = <ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>\n   2908                     return True\n   2909 \n   2910             # Flush softspace\n   2911             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>, result=<ExecutionResult object at 7f5179d44518, executi...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f517d1ca030, file \"<ipython-input-526-812aaa518a46>\", line 1>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\n/home/ningenkun/alicization/<ipython-input-526-812aaa518a46> in <module>()\n----> 1 get_ipython().run_cell_magic('time', '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_cols = len(ft_columns)\\nft_cols = np.array(ft_columns)\\nmask_cols = np.zeros(len(ft_columns), dtype='bool')\\nmask_scale = np.zeros(len(ft_columns), dtype='bool')\\ncv_cols = ['cv' + str(j) for j in range(10)]\\nresults = pd.DataFrame(np.zeros((n_cols*2, 12)), columns=['Col', 'Scale'] + cv_cols)\\n\\nscore = 0.8758\\nnp.random.seed(0)\\nnp.random.shuffle(ft_cols)\\nfor i in range(n_cols):\\n    score_ = [0, 0]\\n    for use_scaler in [0, 1]:\\n        mask_cols[i] = True\\n        mask_scale[i] = True if use_scaler else False\\n        k = i + use_scaler\\n        \\n        results.iloc[k, 0] = ft_cols[i]\\n        results.iloc[k, 1] = use_scaler\\n        t_cols = ft_cols[mask_cols & ~mask_scale]\\n        ts_cols = ft_cols[mask_cols & mask_scale]\\n\\n        results.iloc[k, cv_cols] = cross_val_score(pl.set_params(feats__pl_time__select__key=t_cols, feats__pl_time_scale__select__key=ts_cols), \\n                          X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\\n        \\n        score_[use_scaler] = results.iloc[k, cv_cols].mean()\\n        \\n    if score_[0] < score and score_[1] < score:\\n        mask_cols[i] = False\\n        mask_scale[i] = False\\n        \\n    if score_[0] > score and score_[1] < score:\\n        mask_scale[i] = False\\n        \\n    if score_[0] > score or score_[1] > score:\\n        score = max(score_)\\n    \\n    print(f'Column: {results.iloc[k, 0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\")\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\")\n   2162             # This will need to be updated if the internal calling logic gets\n   2163             # refactored, or else we'll be expanding the wrong variables.\n   2164             stack_depth = 2\n   2165             magic_arg_s = self.var_expand(line, stack_depth)\n   2166             with self.builtin_trap:\n-> 2167                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\"\n   2168             return result\n   2169 \n   2170     def find_line_magic(self, magic_name):\n   2171         \"\"\"Find and return a line magic by name.\n\n...........................................................................\n/home/ningenkun/alicization/<decorator-gen-62> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", local_ns=None)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", None), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', \"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", None)\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"\\ntime_split = TimeSeriesSplit(n_splits=10)\\n\\nn_co...0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')\", local_ns=None)\n   1232                 return\n   1233             end = clock2()\n   1234         else:\n   1235             st = clock2()\n   1236             try:\n-> 1237                 exec(code, glob, local_ns)\n        code = <code object <module> at 0x7f51799dbed0, file \"<timed exec>\", line 2>\n        glob = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# Import libraries and set desired options\\n\\nfrom...tion.text import TfidfVectorizer, CountVectorizer', '# A helper function for writing predictions to a...cted_df.to_csv(out_file, index_label=index_label)', '# Load websites dictionary\\nwith open(r\"data/site...)\\n\\nprint(u\\'Websites total:\\', sites_dict.shape[0])', \"# Read the training and test data sets\\ntrain_df ...v',\\n                      index_col='session_id')\", \"# Switch time1, ..., time10 columns to datetime ...f[sites] = test_df[sites].fillna(0).astype('int')\", \"# Our target variable\\ny_train = train_df['target... and test data sets\\nidx_split = train_df.shape[0]\", 'def get_time_features(df):\\n    time_df = pd.Data...].fillna(time_df[col].mean())\\n\\n    return time_df', 'full_time = get_time_features(full_df[times])\\nft...[full_time, hours_dum], axis=1)\\nprint(ft_columns)', \"full_sites_tf = full_sites.copy()\\n\\nfor col in fu... x: ' '.join([i for i in x if len(i)>0]), axis=1)\", 'df_tf_col', 'df_tf_col[0]', 'df_tf_col.iloc[0]', 'df_tf_col.iloc[2]', 'df_tf_col.iloc[3]', 'df_tf_col.iloc[6]', 'X_train = pd.concat([df_tf_col[:idx_split], full...[idx_split:], full_time.loc[idx_split:]], axis=1)', 'full_time.shape', 'df_tf_col.shape', 'X_train = pd.concat([df_tf_col.loc[:idx_split], ...[idx_split:], full_time.loc[idx_split:]], axis=1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'NumberSelector': <class '__main__.NumberSelector'>, ...}\n        local_ns = None\n   1238             except:\n   1239                 self.shell.showtraceback()\n   1240                 return\n   1241             end = clock2()\n\n...........................................................................\n/home/ningenkun/alicization/<timed exec> in <module>()\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, groups=None, scoring='roc_auc', cv=TimeSeriesSplit(max_train_size=None, n_splits=10), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    338                                 scoring={'score': scorer}, cv=cv,\n    339                                 return_train_score=False,\n    340                                 n_jobs=n_jobs, verbose=verbose,\n    341                                 fit_params=fit_params,\n--> 342                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    343     return cv_results['test_score']\n    344 \n    345 \n    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, groups=None, scoring={'score': make_scorer(roc_auc_score, needs_threshold=True)}, cv=TimeSeriesSplit(max_train_size=None, n_splits=10), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method TimeSeriesSplit.split of TimeSeriesSplit(max_train_size=None, n_splits=10)>\n        X =                                                 ...    0             1  \n\n[253561 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Oct 24 14:13:48 2018\nPID: 7490                Python 3.7.0: /home/ningenkun/anaconda3/bin/python\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...    0             1  \n\n[253561 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 23048, 23049, 23050]), array([23051, 23052, 23053, ..., 46099, 46100, 46101]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...    0             1  \n\n[253561 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 23048, 23049, 23050]), test=array([23051, 23052, 23053, ..., 46099, 46100, 46101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y_train = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('feats', Feat...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'feats': {}}\n        name = 'feats'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f517d4db400>), *args=(FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method FeatureUnion.fit_transform of Feat...std=True))]))],\n       transformer_weights=None)>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[..._std=True))]))],\n       transformer_weights=None), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    734         \"\"\"\n    735         self._validate_transformers()\n    736         result = Parallel(n_jobs=self.n_jobs)(\n    737             delayed(_fit_transform_one)(trans, weight, X, y,\n    738                                         **fit_params)\n--> 739             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...std=True))]))],\n       transformer_weights=None)>\n    740 \n    741         if not result:\n    742             # All transformers are None\n    743             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object FeatureUnion.fit_transform.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), None,                                                 ...     0             0  \n\n[23051 rows x 37 columns], session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), weight=None, X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method Pipeline.fit_transform of Pipeline...ler(copy=True, with_mean=True, with_std=True))])>\n        X =                                                 ...     0             0  \n\n[23051 rows x 37 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py in fit_transform(self=Pipeline(memory=None,\n     steps=[('select', Num...aler(copy=True, with_mean=True, with_std=True))]), X=                                                ...     0             0  \n\n[23051 rows x 37 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    278             Transformed samples\n    279         \"\"\"\n    280         last_step = self._final_estimator\n    281         Xt, fit_params = self._fit(X, y, **fit_params)\n    282         if hasattr(last_step, 'fit_transform'):\n--> 283             return last_step.fit_transform(Xt, y, **fit_params)\n        last_step.fit_transform = <bound method TransformerMixin.fit_transform of ...Scaler(copy=True, with_mean=True, with_std=True)>\n        Xt = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params = {}\n    284         elif last_step is None:\n    285             return Xt\n    286         else:\n    287             return last_step.fit(Xt, y, **fit_params).transform(Xt)\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/base.py in fit_transform(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method StandardScaler.fit of StandardScaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    585         y : Passthrough for ``Pipeline`` compatibility.\n    586         \"\"\"\n    587 \n    588         # Reset internal state before fitting\n    589         self._reset()\n--> 590         return self.partial_fit(X, y)\n        self.partial_fit = <bound method StandardScaler.partial_fit of Stan...Scaler(copy=True, with_mean=True, with_std=True)>\n        X = Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns]\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64\n    591 \n    592     def partial_fit(self, X, y=None):\n    593         \"\"\"Online computation of mean and std on X for later scaling.\n    594         All of X is processed as a single batch. This is intended for cases\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py in partial_fit(self=StandardScaler(copy=True, with_mean=True, with_std=True), X=Empty DataFrame\nColumns: []\nIndex: [21669, 54843...89, 31636, 217764, ...]\n\n[23051 rows x 0 columns], y=session_id\n21669     0\n54843     0\n77292     0\n1...      0\nName: target, Length: 23051, dtype: int64)\n    607             used for later scaling along the features axis.\n    608 \n    609         y : Passthrough for ``Pipeline`` compatibility.\n    610         \"\"\"\n    611         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n--> 612                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n        self = StandardScaler(copy=True, with_mean=True, with_std=True)\n    613 \n    614         # Even in the case of `with_mean=False`, we update the mean anyway\n    615         # This is needed for the incremental computation of the var\n    616         # See incr_mean_variance_axis and _incremental_mean_variance_axis\n\n...........................................................................\n/home/ningenkun/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(23051, 0), dtype=float64), accept_sparse=('csr', 'csc'), dtype=<class 'numpy.float64'>, order=None, copy=True, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=True, estimator=StandardScaler(copy=True, with_mean=True, with_std=True))\n    465         n_features = array.shape[1]\n    466         if n_features < ensure_min_features:\n    467             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    468                              \" a minimum of %d is required%s.\"\n    469                              % (n_features, shape_repr, ensure_min_features,\n--> 470                                 context))\n        context = ' by StandardScaler'\n    471 \n    472     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    473         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    474                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(23051, 0)) while a minimum of 1 is required by StandardScaler.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_split = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "ft_cols = np.array(ft_columns)\n",
    "mask_cols = np.zeros(len(ft_columns), dtype='bool')\n",
    "mask_scale = np.zeros(len(ft_columns), dtype='bool')\n",
    "cv_cols = ['cv' + str(j) for j in range(10)]\n",
    "results = pd.DataFrame(np.zeros((n_cols*2, 12)), columns=['Col', 'Scale'] + cv_cols)\n",
    "\n",
    "score = 0.8758\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(ft_cols)\n",
    "for i in range(n_cols):\n",
    "    score_ = [0, 0]\n",
    "    for use_scaler in [0, 1]:\n",
    "        mask_cols[i] = True\n",
    "        mask_scale[i] = True if use_scaler else False\n",
    "        k = i + use_scaler\n",
    "        \n",
    "        results.iloc[k, 0] = ft_cols[i]\n",
    "        results.iloc[k, 1] = use_scaler\n",
    "        t_cols = ft_cols[mask_cols & ~mask_scale]\n",
    "        ts_cols = ft_cols[mask_cols & mask_scale]\n",
    "\n",
    "        results.iloc[k, cv_cols] = cross_val_score(pl.set_params(feats__pl_time__select__key=t_cols, feats__pl_time_scale__select__key=ts_cols), \n",
    "                          X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "        \n",
    "        score_[use_scaler] = results.iloc[k, cv_cols].mean()\n",
    "        \n",
    "    if score_[0] < score and score_[1] < score:\n",
    "        mask_cols[i] = False\n",
    "        mask_scale[i] = False\n",
    "        \n",
    "    if score_[0] > score and score_[1] < score:\n",
    "        mask_scale[i] = False\n",
    "        \n",
    "    if score_[0] > score or score_[1] > score:\n",
    "        score = max(score_)\n",
    "    \n",
    "    print(f'Column: {results.iloc[k, 0]} Use: {mask_cols[i]} Scale: {mask_scale[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results, cv_results = analyze_results(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf__C</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.872588</td>\n",
       "      <td>0.074915</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.875889</td>\n",
       "      <td>0.074876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.875592</td>\n",
       "      <td>0.073643</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0.873039</td>\n",
       "      <td>0.071317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clf__C  mean_score  std_score  rank\n",
       "0       1    0.872588   0.074915     4\n",
       "1       3    0.875889   0.074876     1\n",
       "2      10    0.875592   0.073643     2\n",
       "3      30    0.873039   0.071317     3"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf C\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__count__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.866710</td>\n",
       "      <td>0.079719</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.868556</td>\n",
       "      <td>0.079310</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.869854</td>\n",
       "      <td>0.080480</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.870058</td>\n",
       "      <td>0.080325</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.870057</td>\n",
       "      <td>0.080277</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25000</td>\n",
       "      <td>0.870272</td>\n",
       "      <td>0.080233</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.870328</td>\n",
       "      <td>0.080248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__count__max_features  mean_score  std_score  rank\n",
       "0                                 5000    0.866710   0.079719     7\n",
       "1                                 8000    0.868556   0.079310     6\n",
       "2                                10000    0.869854   0.080480     5\n",
       "3                                15000    0.870058   0.080325     3\n",
       "4                                20000    0.870057   0.080277     4\n",
       "5                                25000    0.870272   0.080233     2\n",
       "6                                50000    0.870328   0.080248     1"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COUNT on sites_num find max_feat\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__count__max_df</th>\n",
       "      <th>feats__pl_text__count__ngram_range</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.868690</td>\n",
       "      <td>0.081518</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.864770</td>\n",
       "      <td>0.084686</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.869854</td>\n",
       "      <td>0.080480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.865331</td>\n",
       "      <td>0.084242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.865640</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.864722</td>\n",
       "      <td>0.083968</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__count__max_df feats__pl_text__count__ngram_range  \\\n",
       "0                            0.1                             (1, 1)   \n",
       "1                            0.1                             (1, 2)   \n",
       "2                            0.2                             (1, 1)   \n",
       "3                            0.2                             (1, 2)   \n",
       "4                            0.3                             (1, 1)   \n",
       "5                            0.3                             (1, 2)   \n",
       "\n",
       "   mean_score  std_score  rank  \n",
       "0    0.868690   0.081518     2  \n",
       "1    0.864770   0.084686     5  \n",
       "2    0.869854   0.080480     1  \n",
       "3    0.865331   0.084242     4  \n",
       "4    0.865640   0.075904     3  \n",
       "5    0.864722   0.083968     6  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COUNT on sites_num find max_df and n_gram\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__norm</th>\n",
       "      <th>feats__pl_text__tfidf__use_idf</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.851279</td>\n",
       "      <td>0.081743</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.845603</td>\n",
       "      <td>0.078184</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.872588</td>\n",
       "      <td>0.074915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.869540</td>\n",
       "      <td>0.075021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feats__pl_text__tfidf__norm  feats__pl_text__tfidf__use_idf  mean_score  \\\n",
       "0                          l1                            True    0.851279   \n",
       "1                          l1                           False    0.845603   \n",
       "2                          l2                            True    0.872588   \n",
       "3                          l2                           False    0.869540   \n",
       "\n",
       "   std_score  rank  \n",
       "0   0.081743     3  \n",
       "1   0.078184     4  \n",
       "2   0.074915     1  \n",
       "3   0.075021     2  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num find binary features\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__binary</th>\n",
       "      <th>feats__pl_text__tfidf__smooth_idf</th>\n",
       "      <th>feats__pl_text__tfidf__sublinear_tf</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.872248</td>\n",
       "      <td>0.077487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.872248</td>\n",
       "      <td>0.077487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.872588</td>\n",
       "      <td>0.074915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.869938</td>\n",
       "      <td>0.075274</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.872584</td>\n",
       "      <td>0.074907</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.869920</td>\n",
       "      <td>0.075279</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__binary  feats__pl_text__tfidf__smooth_idf  \\\n",
       "0                           True                               True   \n",
       "1                           True                               True   \n",
       "2                           True                              False   \n",
       "3                           True                              False   \n",
       "4                          False                               True   \n",
       "5                          False                               True   \n",
       "6                          False                              False   \n",
       "7                          False                              False   \n",
       "\n",
       "   feats__pl_text__tfidf__sublinear_tf  mean_score  std_score  rank  \n",
       "0                                 True    0.872248   0.077487     3  \n",
       "1                                False    0.872248   0.077487     3  \n",
       "2                                 True    0.872236   0.077471     5  \n",
       "3                                False    0.872236   0.077471     5  \n",
       "4                                 True    0.872588   0.074915     1  \n",
       "5                                False    0.869938   0.075274     7  \n",
       "6                                 True    0.872584   0.074907     2  \n",
       "7                                False    0.869920   0.075279     8  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num find binary features\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.868928</td>\n",
       "      <td>0.075332</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.869938</td>\n",
       "      <td>0.075274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.869377</td>\n",
       "      <td>0.074591</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.869607</td>\n",
       "      <td>0.074615</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.869721</td>\n",
       "      <td>0.074630</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25000</td>\n",
       "      <td>0.869725</td>\n",
       "      <td>0.074622</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.869728</td>\n",
       "      <td>0.074671</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_features  mean_score  std_score  rank\n",
       "0                                 5000    0.868928   0.075332     7\n",
       "1                                 8000    0.869938   0.075274     1\n",
       "2                                10000    0.869377   0.074591     6\n",
       "3                                15000    0.869607   0.074615     5\n",
       "4                                20000    0.869721   0.074630     4\n",
       "5                                25000    0.869725   0.074622     3\n",
       "6                                50000    0.869728   0.074671     2"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num find max_feat\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_df</th>\n",
       "      <th>feats__pl_text__tfidf__ngram_range</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.869420</td>\n",
       "      <td>0.076220</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.867631</td>\n",
       "      <td>0.079379</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.864607</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.869728</td>\n",
       "      <td>0.074671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.867434</td>\n",
       "      <td>0.078435</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.863854</td>\n",
       "      <td>0.080793</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.863373</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.863557</td>\n",
       "      <td>0.081261</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.859794</td>\n",
       "      <td>0.084414</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_df feats__pl_text__tfidf__ngram_range  \\\n",
       "0                            0.1                             (1, 1)   \n",
       "1                            0.1                             (1, 2)   \n",
       "2                            0.1                             (1, 3)   \n",
       "3                            0.2                             (1, 1)   \n",
       "4                            0.2                             (1, 2)   \n",
       "5                            0.2                             (1, 3)   \n",
       "6                            0.3                             (1, 1)   \n",
       "7                            0.3                             (1, 2)   \n",
       "8                            0.3                             (1, 3)   \n",
       "\n",
       "   mean_score  std_score  rank  \n",
       "0    0.869420   0.076220     2  \n",
       "1    0.867631   0.079379     3  \n",
       "2    0.864607   0.081646     5  \n",
       "3    0.869728   0.074671     1  \n",
       "4    0.867434   0.078435     4  \n",
       "5    0.863854   0.080793     6  \n",
       "6    0.863373   0.078525     8  \n",
       "7    0.863557   0.081261     7  \n",
       "8    0.859794   0.084414     9  "
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num find max_df and n_gram\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_df</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.869420</td>\n",
       "      <td>0.076220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.869512</td>\n",
       "      <td>0.076091</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.869728</td>\n",
       "      <td>0.074671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.866681</td>\n",
       "      <td>0.077613</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.863373</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_df  mean_score  std_score  rank\n",
       "0                           0.10    0.869420   0.076220     3\n",
       "1                           0.15    0.869512   0.076091     2\n",
       "2                           0.20    0.869728   0.074671     1\n",
       "3                           0.25    0.866681   0.077613     4\n",
       "4                           0.30    0.863373   0.078525     5"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num find max_df\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.839395</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.848638</td>\n",
       "      <td>0.080481</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.849106</td>\n",
       "      <td>0.079854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.848911</td>\n",
       "      <td>0.079858</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_features  mean_score  std_score  rank\n",
       "0                               1000.0    0.839395   0.077396     6\n",
       "1                               5000.0    0.848638   0.080481     5\n",
       "2                              10000.0    0.849106   0.079854     1\n",
       "3                              25000.0    0.848911   0.079858     4\n",
       "4                              50000.0    0.848937   0.079883     2\n",
       "5                                  NaN    0.848937   0.079883     2"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_dms\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.848638</td>\n",
       "      <td>0.080481</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.849106</td>\n",
       "      <td>0.079854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.848911</td>\n",
       "      <td>0.079858</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_features  mean_score  std_score  rank\n",
       "0                               5000.0    0.848638   0.080481     6\n",
       "1                              10000.0    0.849106   0.079854     1\n",
       "2                              25000.0    0.848911   0.079858     5\n",
       "3                              50000.0    0.848937   0.079883     2\n",
       "4                             100000.0    0.848937   0.079883     2\n",
       "5                                  NaN    0.848937   0.079883     2"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_ds\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.863212</td>\n",
       "      <td>0.078470</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.863428</td>\n",
       "      <td>0.078527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.863373</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.863373</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_features  mean_score  std_score  rank\n",
       "0                              10000.0    0.863212   0.078470     4\n",
       "1                              25000.0    0.863428   0.078527     1\n",
       "2                             100000.0    0.863373   0.078525     2\n",
       "3                                  NaN    0.863373   0.078525     2"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites_num \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__tfidf__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.839395</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.848638</td>\n",
       "      <td>0.080481</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.849106</td>\n",
       "      <td>0.079854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25000</td>\n",
       "      <td>0.848911</td>\n",
       "      <td>0.079858</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.848937</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__tfidf__max_features  mean_score  std_score  rank\n",
       "0                                 1000    0.839395   0.077396     6\n",
       "1                                 5000    0.848638   0.080481     5\n",
       "2                                10000    0.849106   0.079854     1\n",
       "3                                25000    0.848911   0.079858     4\n",
       "4                                50000    0.848937   0.079883     2\n",
       "5                               100000    0.848937   0.079883     2"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF on sites \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats__pl_text__count__max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.863764</td>\n",
       "      <td>0.075713</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7500</td>\n",
       "      <td>0.864520</td>\n",
       "      <td>0.074875</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.865640</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.865493</td>\n",
       "      <td>0.075473</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.865668</td>\n",
       "      <td>0.075458</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feats__pl_text__count__max_features  mean_score  std_score  rank\n",
       "0                                 5000    0.863764   0.075713     5\n",
       "1                                 7500    0.864520   0.074875     4\n",
       "2                                10000    0.865640   0.075904     2\n",
       "3                                20000    0.865493   0.075473     3\n",
       "4                                50000    0.865668   0.075458     1"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COUNT on sites_num \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.refit\n",
    "\n",
    "pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "write_to_submission_file(pred, 'pl_almost_orig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>split_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.989991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.996261</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.992144</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.991079</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.992333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable     value  split_num\n",
       "0         0  0.989991          1\n",
       "1         0  0.996261          2\n",
       "2         0  0.992144          3\n",
       "3         0  0.991079          4\n",
       "4         0  0.992333          5"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 408.375x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "melted = cv_results.melt()\n",
    "melted['split_num'] = list(range(cv_results.shape[0])) * cv_results.shape[1]\n",
    "\n",
    "sns.lmplot(x='split_num', y='value', data=melted, fit_reg=True, hue='variable');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sites_tf = full_sites.copy()\n",
    "\n",
    "for col in full_sites_tf.columns:\n",
    "    full_sites_tf[col] = full_sites_tf[col].map(sites_dict.site)\n",
    "\n",
    "full_sites_tf = full_sites_tf.fillna('')\n",
    "# df_tf_col = full_sites_tf.apply(lambda x: '.'.join([i for i in x if len(i)>0]), axis=1)\n",
    "# df_tf_col = df_tf_col.str.split('[.-]').str.join(' ')\n",
    "\n",
    "df_tf_col = full_sites_tf.apply(lambda x: ' '.join([i for i in x if len(i)>0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_df=.7, sublinear_tf=True)\n",
    "df_tf = vect.fit_transform(df_tf_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split = TimeSeriesSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df_tf[:idx_split,:]\n",
    "# X_test = df_tf[idx_split:,:]\n",
    "\n",
    "\n",
    "X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = [0.01, 0.03]\n",
    "# cw_values = [{0: 0.6, 1: 0.4}, {0: 0.9, 1: 0.1}, {0: 0.8, 1: 0.2}, {0: 0.7, 1: 0.3} , {0: 0.3, 1: 0.7}]\n",
    "\n",
    "lrcv = LogisticRegressionCV(Cs=c_values, scoring='roc_auc', n_jobs=-1, cv=kfold_split,\n",
    "                            verbose=1, class_weight='balanced', max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:  8.3min remaining: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 56s, sys: 2min 36s, total: 6min 33s\n",
      "Wall time: 10min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lrcv.fit(X_train, y_train);\n",
    "lrcv.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC [0.01]: 0.9574+-0.0141\n",
      "ROC_AUC [0.03]: 0.9587+-0.0136\n",
      "Best params: [0.03]\n"
     ]
    }
   ],
   "source": [
    "cvr = lrcv.scores_[1]\n",
    "idx = cvr.mean(axis=0).argmax()\n",
    "for i in range(cvr.shape[1]):\n",
    "    print(f\"ROC_AUC [{lrcv.Cs_[i]:>4}]: {cvr[:, i].mean():.4f}+-{cvr[:, i].std():.4f}\")\n",
    "print(f\"Best params: {lrcv.C_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC_AUC [0.01]: 0.9574+-0.0141\n",
    "ROC_AUC [0.03]: 0.9587+-0.0136\n",
    "ROC_AUC [ 0.1]: 0.9586+-0.0127\n",
    "ROC_AUC [ 0.3]: 0.9578+-0.0123\n",
    "ROC_AUC [ 1.0]: 0.9559+-0.0129\n",
    "ROC_AUC [ 3.0]: 0.9531+-0.0142\n",
    "ROC_AUC [10.0]: 0.9488+-0.0167\n",
    "Best params: [0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_tf[:idx_split,:]\n",
    "X_test = df_tf[idx_split:,:]\n",
    "\n",
    "# X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "# X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "logit = LogisticRegression(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 791 ms, sys: 159 ms, total: 950 ms\n",
      "Wall time: 8.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC: 0.8537+-0.0796\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROC_AUC: {cv_scores.mean():.4f}+-{cv_scores.std():.4f}\")\n",
    "# cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(X_train, y_train)\n",
    "logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
    "write_to_submission_file(logit_test_pred, 'subm_not_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check columns importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cw {0: 0.2, 1: 0.8}: 0.9542+-0.0159\n",
      "cw {0: 0.3, 1: 0.7}: 0.9537+-0.0162\n",
      "cw {0: 0.4, 1: 0.6}: 0.9529+-0.0165\n",
      "CPU times: user 3min 28s, sys: 22.5 s, total: 3min 51s\n",
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores_arr = list()\n",
    "\n",
    "for cw in [{0: 0.2, 1: 0.8}, {0: 0.3, 1: 0.7}, {0: 0.4, 1: 0.6}]:\n",
    "    vect = TfidfVectorizer(max_df=0.9, sublinear_tf=True)\n",
    "    df_tf = vect.fit_transform(df_tf_col)\n",
    "    params = {'C': 0.1, 'class_weight': cw, 'random_state':17, 'n_jobs':1}\n",
    "    \n",
    "    X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "    X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])\n",
    "    \n",
    "    logit = LogisticRegression(**params)\n",
    "    cv_scores_ = cross_val_score(logit, X_train, y_train, cv=kfold_split, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_scores_arr.append(cv_scores_)\n",
    "    \n",
    "    print(f\"cw {cw}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cw balanced  : 0.9586+-0.0127\n",
    "cw {0: 0.9, 1: 0.1}: 0.9390+-0.0209\n",
    "cw {0: 0.8, 1: 0.2}: 0.9451+-0.0188\n",
    "cw {0: 0.7, 1: 0.3}: 0.9483+-0.0178\n",
    "cw {0: 0.6, 1: 0.4}: 0.9504+-0.0172\n",
    "cw {0: 0.5, 1: 0.5}: 0.9518+-0.0168\n",
    "cw {0: 0.4, 1: 0.6}: 0.9529+-0.0165\n",
    "cw {0: 0.3, 1: 0.7}: 0.9537+-0.0162\n",
    "cw {0: 0.2, 1: 0.8}: 0.9542+-0.0159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define good tf-idf params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 0.5   : 0.8736+-0.1068\n",
      "max_df 0.6   : 0.8742+-0.1057\n",
      "max_df 0.7   : 0.8742+-0.1057\n",
      "max_df 0.8   : 0.8736+-0.1061\n",
      "max_df 0.9   : 0.8738+-0.1067\n",
      "max_df 1     : 0.8008+-0.0957\n",
      "CPU times: user 59.3 s, sys: 6.51 s, total: 1min 5s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "cv_scores_arr = list()\n",
    "\n",
    "for i in [.5, .6, .7, .8, .9, 1]:\n",
    "    vect = TfidfVectorizer(max_df=i, sublinear_tf=True)\n",
    "    df_tf = vect.fit_transform(df_tf_col)\n",
    "    \n",
    "    X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split,:]])\n",
    "    X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:,:]])\n",
    "    \n",
    "    logit = LogisticRegression(**params)\n",
    "    cv_scores_ = cross_val_score(logit, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_scores_arr.append(cv_scores_)\n",
    "    \n",
    "    print(f\"max_df {i:<6}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_df 0.0001: 0.9581+-0.0129\n",
    "min_df 0.001: 0.9560+-0.0120\n",
    "min_df 0.01: 0.9403+-0.0132\n",
    "min_df 0.1: 0.9110+-0.0209\n",
    "min_df 0.3: 0.8979+-0.0200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_df 0.50: 0.9582+-0.0125\n",
    "max_df 0.60: 0.9583+-0.0126\n",
    "max_df 0.70: 0.9583+-0.0126\n",
    "max_df 0.80: 0.9583+-0.0126\n",
    "max_df 0.85: 0.9583+-0.0126\n",
    "max_df 0.90: 0.9586+-0.0127\n",
    "max_df 0.95: 0.9586+-0.0127\n",
    "max_df 0.98: 0.9586+-0.0127\n",
    "max_df 1.00: 0.8968+-0.0200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define good hour split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC: 0.9530+-0.0141\n"
     ]
    }
   ],
   "source": [
    "good_cols = ['sin_min', 'cos_max', 'n_null', 'dt', 'year', 'morning', 'day', 'evening']\n",
    "mask = pd.Series(ft_columns).isin(good_cols).values\n",
    "\n",
    "X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask]])\n",
    "X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask]])\n",
    "\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "logit = LogisticRegression(**params)\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train, y_train, cv=kfold_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster\n",
    "\n",
    "print(f\"ROC_AUC: {cv_scores.mean():.4f}+-{cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins 2         : 0.9465+-0.0194 EXCLUDE\n",
      "Bins 3         : 0.9418+-0.0187 EXCLUDE\n",
      "Bins 4         : 0.9583+-0.0126 ADD\n",
      "Bins 5         : 0.9494+-0.0208 EXCLUDE\n",
      "Bins 6         : 0.9429+-0.0222 EXCLUDE\n",
      "Bins 7         : 0.9548+-0.0194 EXCLUDE\n",
      "Bins 8         : 0.9592+-0.0168 ADD\n",
      "CPU times: user 1min 29s, sys: 34.6 s, total: 2min 4s\n",
      "Wall time: 20min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "good_cols = ['sin_min', 'cos_max', 'n_null', 'dt', 'year']\n",
    "mask = pd.Series(ft_columns).isin(good_cols).values\n",
    "\n",
    "mask_hours = pd.Series(ft_columns).isin(['hour']).values\n",
    "hours = pd.Series(full_time[:, mask_hours].flatten())\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "cv_scores_arr = []\n",
    "\n",
    "for i in range(2, 9):\n",
    "    hours_dum = pd.get_dummies(pd.cut(hours, bins=i)).values\n",
    "    \n",
    "    X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask], hours_dum[:idx_split, :]])\n",
    "    X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask], hours_dum[idx_split:, :]])\n",
    "    \n",
    "    logit = LogisticRegression(**params)\n",
    "    cv_scores_ = cross_val_score(logit, X_train, y_train, cv=kfold_split, scoring='roc_auc', n_jobs=-1)\n",
    "    cv_scores_arr.append(cv_scores_)\n",
    "    \n",
    "    d_cv = cv_scores_ - cv_scores\n",
    "    n_pos = (d_cv > 0).sum()\n",
    "    if not(d_cv.mean() > 0 and n_pos > 4):\n",
    "        print(f\"Bins {i:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} EXCLUDE\")\n",
    "    else:\n",
    "        cv_scores = cv_scores_.copy()\n",
    "        print(f\"Bins {i:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} ADD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete columns one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_columns = ['dow', 'weekend', 'day_', 'month', 'sin_min', 'cos_min', 'dt', 'dt_std', 'dt_mean', 'n_null',\n",
    "              'sin_max', 'cos_max', 'hour', 'year', 'minutes', 'myear', 'bin1', 'bin2', 'bin3', 'bin4']  # full_time.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8735747277102843"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "bin3      : 0.8723+-0.1060 OK  \n",
      "weekend   : 0.8803+-0.1304 EXCLUDE  \n",
      "bin4      : 0.8800+-0.1307 OK  \n",
      "dt_mean   : 0.8804+-0.1302 EXCLUDE  \n",
      "sin_max   : 0.8804+-0.1304 OK  \n",
      "bin2      : 0.8813+-0.1266 OK  \n",
      "dt        : 0.8802+-0.1307 OK  \n",
      "year      : 0.8803+-0.1301 OK  \n",
      "sin_min   : 0.8803+-0.1304 OK  \n",
      "day_      : 0.8803+-0.1300 OK  \n",
      "cos_min   : 0.8803+-0.1301 OK  \n",
      "minutes   : 0.8801+-0.1309 OK  \n",
      "n_null    : 0.8812+-0.1328 OK  \n",
      "dt_std    : 0.8804+-0.1303 OK  \n",
      "bin1      : 0.8804+-0.1304 OK  \n",
      "cos_max   : 0.8803+-0.1304 OK  \n",
      "month     : 0.8803+-0.1303 OK  \n",
      "dow       : 0.8799+-0.1290 OK  \n",
      "myear     : 0.8804+-0.1300 OK  \n",
      "hour      : 0.8806+-0.1304 EXCLUDE  \n",
      "******************************\n",
      "Iter 1\n",
      "month     : 0.8731+-0.1065 OK  \n",
      "bin1      : 0.8744+-0.1054 OK  \n",
      "dt        : 0.8736+-0.1061 OK  \n",
      "sin_max   : 0.8736+-0.1062 OK  \n",
      "day_      : 0.8744+-0.1061 OK  \n",
      "minutes   : 0.8736+-0.1062 OK  \n",
      "sin_min   : 0.8735+-0.1062 OK  \n",
      "bin2      : 0.8748+-0.0999 OK  \n",
      "dt_std    : 0.8736+-0.1061 OK  \n",
      "weekend   : 0.8803+-0.1304 EXCLUDE  \n",
      "year      : 0.8802+-0.1302 OK  \n",
      "dow       : 0.8798+-0.1291 OK  \n",
      "bin4      : 0.8800+-0.1307 OK  \n",
      "bin3      : 0.8803+-0.1290 OK  \n",
      "n_null    : 0.8811+-0.1330 OK  \n",
      "myear     : 0.8803+-0.1301 OK  \n",
      "dt_mean   : 0.8804+-0.1302 EXCLUDE  \n",
      "hour      : 0.8806+-0.1304 EXCLUDE  \n",
      "cos_max   : 0.8805+-0.1305 OK  \n",
      "cos_min   : 0.8805+-0.1302 OK  \n",
      "******************************\n",
      "Iter 2\n",
      "hour      : 0.8738+-0.1064 EXCLUDE  \n",
      "sin_min   : 0.8738+-0.1064 OK  \n",
      "bin3      : 0.8726+-0.1062 OK  \n",
      "dow       : 0.8674+-0.1234 OK  \n",
      "n_null    : 0.8742+-0.1094 OK  \n",
      "cos_min   : 0.8737+-0.1062 OK  \n",
      "month     : 0.8733+-0.1067 OK  \n",
      "sin_max   : 0.8738+-0.1064 OK  \n",
      "weekend   : 0.8805+-0.1305 EXCLUDE  \n",
      "bin2      : 0.8815+-0.1268 OK  \n",
      "dt_std    : 0.8805+-0.1305 OK  \n",
      "bin1      : 0.8805+-0.1307 OK  \n",
      "minutes   : 0.8806+-0.1312 OK  \n",
      "day_      : 0.8805+-0.1303 OK  \n",
      "cos_max   : 0.8804+-0.1306 OK  \n",
      "dt        : 0.8804+-0.1306 OK  \n",
      "bin4      : 0.8802+-0.1309 OK  \n",
      "year      : 0.8804+-0.1303 OK  \n",
      "myear     : 0.8805+-0.1302 OK  \n",
      "dt_mean   : 0.8806+-0.1304 EXCLUDE  \n",
      "******************************\n",
      "Iter 3\n",
      "minutes   : 0.8736+-0.1062 OK  \n",
      "day_      : 0.8744+-0.1061 OK  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-508:\n",
      "Process ForkPoolWorker-507:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "cv_scores_all = list()\n",
    "delete_dict = {col:0 for col in ft_columns}\n",
    "boundary = time_split.n_splits * 7 // 10\n",
    "\n",
    "for iter_ in range(10):\n",
    "    print(f\"Iter {iter_}\")\n",
    "    idx_order = list(range(n_cols))\n",
    "    np.random.seed(iter_)\n",
    "    np.random.shuffle(idx_order)\n",
    "    cv_scores_n_ = cv_scores.copy()\n",
    "    cv_scores_arr = list()\n",
    "    mask = np.ones(n_cols, dtype='bool')\n",
    "    \n",
    "    for n_ in range(-n_cols, 0):\n",
    "        i = idx_order[n_]\n",
    "        mask[i] = False\n",
    "        X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask]])\n",
    "        X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask]])\n",
    "        logit = LogisticRegression(**params)\n",
    "        cv_scores_ = cross_val_score(logit, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "        cv_scores_arr.append(cv_scores_)\n",
    "\n",
    "        d_cv = cv_scores_ - cv_scores_n_\n",
    "        n_neg = (d_cv > 0).sum()\n",
    "        if d_cv.mean() > 0 and n_neg >= boundary:\n",
    "            delete_dict[ft_columns[i]] += 1\n",
    "            cv_scores_n_ = cv_scores_.copy()\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} EXCLUDE  \")\n",
    "        else:\n",
    "            mask[i] = True\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} OK  \")\n",
    "    cv_scores_all.append(cv_scores_arr)\n",
    "    print('*' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {'C': 0.1, 'class_weight': 'balanced', 'random_state':17, 'n_jobs':1}\n",
    "\n",
    "n_cols = len(ft_columns)\n",
    "cv_scores_arr = []\n",
    "mask = np.zeros(n_cols, dtype='bool')\n",
    "for i in range(-n_cols, 0):\n",
    "    if 'dt_time' not in ft_columns[i]:\n",
    "        mask[i] = True\n",
    "        X_train = hstack([df_tf[:idx_split,:], full_time[:idx_split, mask]])\n",
    "        X_test = hstack([df_tf[idx_split:,:], full_time[idx_split:, mask]])\n",
    "        logit = LogisticRegression(**params)\n",
    "        cv_scores_ = cross_val_score(logit, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)\n",
    "        cv_scores_arr.append(cv_scores_)\n",
    "\n",
    "        d_cv = cv_scores_ - cv_scores\n",
    "        n_pos = (d_cv > 0).sum()\n",
    "        if not(d_cv.mean() > 0 and n_pos > d_cv.shape[0]/2):\n",
    "            mask[i] = False\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} EXCLUDE  \")\n",
    "        else:\n",
    "            cv_scores = cv_scores_.copy()\n",
    "            print(f\"{ft_columns[i]:<10}: {cv_scores_.mean():.4f}+-{cv_scores_.std():.4f} ADD  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dow       : 0.8544+-0.0874 EXCLUDE\n",
    "weekend   : 0.8399+-0.0972 EXCLUDE\n",
    "day_      : 0.8523+-0.0798 EXCLUDE\n",
    "month     : 0.8552+-0.0807 ADD\n",
    "sin_min   : 0.9028+-0.0783 ADD\n",
    "cos_min   : 0.8915+-0.0949 EXCLUDE\n",
    "dt        : 0.9019+-0.0794 EXCLUDE\n",
    "dt_std    : 0.9028+-0.0788 EXCLUDE\n",
    "dt_mean   : 0.9016+-0.0794 EXCLUDE\n",
    "n_null    : 0.9020+-0.0756 EXCLUDE\n",
    "morning   : 0.8923+-0.0966 EXCLUDE\n",
    "day       : 0.9008+-0.0817 EXCLUDE\n",
    "evening   : 0.9057+-0.0756 ADD\n",
    "sin_max   : 0.9057+-0.0756 ADD\n",
    "cos_max   : 0.8854+-0.1113 EXCLUDE\n",
    "hour      : 0.9007+-0.0837 EXCLUDE\n",
    "year      : 0.9099+-0.0767 ADD\n",
    "minutes   : 0.9054+-0.0844 EXCLUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols = ['sin_min', 'cos_max', 'n_null', 'dt', 'year', 'morning', 'day', 'evening']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer df_tf + time  max_df=.7 sublinear_tf=True\n",
    "ROC_AUC: 0.9168+-0.0542\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time  max_df=.7\n",
    "ROC_AUC: 0.9148+-0.0504\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time  max_df=.8\n",
    "ROC_AUC: 0.9125+-0.0538\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time\n",
    "ROC_AUC: 0.9115+-0.0546\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf + time (sites name full)\n",
    "ROC_AUC: 0.9115+-0.0546\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "TfidfVectorizer df_tf\n",
    "ROC_AUC: 0.8575+-0.0753\n",
    "Best params: {'C': 20, 'class_weight': {0: 0.6, 1: 0.4}}\n",
    "\n",
    "CountVectorizer df_tf\n",
    "ROC_AUC: 0.8351+-0.0763\n",
    "Best params: {'C': 10, 'class_weight': {0: 0.6, 1: 0.4}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred = logit_grid_searcher.predict_proba(X_test)[:, 1]\n",
    "write_to_submission_file(logit_test_pred, 'pred/a_sub_new_df_tfidf_drop_dub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets watch origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User sessions are chosen in the way they are not longer than half an hour or/and contain more than ten websites. I.e. a session is considered as ended either if a user has visited ten websites or if a session has lasted over thirty minutes.\n",
    "\n",
    "There are some empty values in the table, it means that some sessions contain less than ten websites. Replace empty values with 0 and change columns types to integer. Also load the websites dictionary and check how it looks like:\n",
    "\n",
    "**Пользовательские сессии выбираются так, чтобы они не превышали получаса или / и содержали более десяти веб-сайтов. То есть сеанс считается завершенным, если пользователь посетил десять веб-сайтов или если сеанс длится более тридцати минут.**  \n",
    "\n",
    "**В таблице есть несколько пустых значений, это означает, что некоторые сеансы содержат менее десяти веб-сайтов. Замените пустые значения на 0 и измените типы столбцов на integer. Также загрузите словарь веб-сайтов и проверьте, как это выглядит:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-12 16:25:10</td>\n",
       "      <td>api.bing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-12 16:25:11</td>\n",
       "      <td>api.bing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>api.bing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>www.google.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>www.google.fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp           site\n",
       "0  2013-02-12 16:25:10   api.bing.com\n",
       "1  2013-02-12 16:25:11   api.bing.com\n",
       "2  2013-02-12 16:32:10   api.bing.com\n",
       "3  2013-02-12 16:32:11  www.google.fr\n",
       "4  2013-02-12 16:32:24  www.google.fr"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alice = pd.read_csv('data/train/Alice_log.csv')\n",
    "df_alice.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-18 10:19:27</td>\n",
       "      <td>ocsp.digicert.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-18 10:19:28</td>\n",
       "      <td>ocsp.digicert.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-18 10:19:28</td>\n",
       "      <td>clients1.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-18 10:19:29</td>\n",
       "      <td>gtglobal-ocsp.geotrust.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-18 10:19:29</td>\n",
       "      <td>clients1.google.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                        site\n",
       "0  2013-12-18 10:19:27           ocsp.digicert.com\n",
       "1  2013-12-18 10:19:28           ocsp.digicert.com\n",
       "2  2013-12-18 10:19:28         clients1.google.com\n",
       "3  2013-12-18 10:19:29  gtglobal-ocsp.geotrust.com\n",
       "4  2013-12-18 10:19:29         clients1.google.com"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user0010 = pd.read_csv('data/train/other_user_logs/user0010.csv')\n",
    "df_user0010.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>site6</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>952</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57     55 2013-01-12 08:05:57      0   \n",
       "54843          56 2013-01-12 08:37:23     55 2013-01-12 08:37:23     56   \n",
       "77292         946 2013-01-12 08:50:13    946 2013-01-12 08:50:14    951   \n",
       "114021        945 2013-01-12 08:50:17    948 2013-01-12 08:50:17    949   \n",
       "146670        947 2013-01-12 08:50:20    950 2013-01-12 08:50:20    948   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843      2013-01-12 09:07:07     55 2013-01-12 09:07:09      0   \n",
       "77292      2013-01-12 08:50:15    946 2013-01-12 08:50:15    946   \n",
       "114021     2013-01-12 08:50:18    948 2013-01-12 08:50:18    945   \n",
       "146670     2013-01-12 08:50:20    947 2013-01-12 08:50:21    950   \n",
       "\n",
       "                         time5  site6               time6  site7  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843                      NaT      0                 NaT      0   \n",
       "77292      2013-01-12 08:50:16    945 2013-01-12 08:50:16    948   \n",
       "114021     2013-01-12 08:50:18    946 2013-01-12 08:50:18    947   \n",
       "146670     2013-01-12 08:50:21    952 2013-01-12 08:50:21    946   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843                      NaT      0                 NaT      0   \n",
       "77292      2013-01-12 08:50:16    784 2013-01-12 08:50:16    949   \n",
       "114021     2013-01-12 08:50:19    945 2013-01-12 08:50:19    946   \n",
       "146670     2013-01-12 08:50:21    951 2013-01-12 08:50:22    946   \n",
       "\n",
       "                         time9  site10              time10  \n",
       "session_id                                                  \n",
       "21669                      NaT       0                 NaT  \n",
       "54843                      NaT       0                 NaT  \n",
       "77292      2013-01-12 08:50:17     946 2013-01-12 08:50:17  \n",
       "114021     2013-01-12 08:50:19     946 2013-01-12 08:50:20  \n",
       "146670     2013-01-12 08:50:22     947 2013-01-12 08:50:22  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2297 entries, 251175 to 244233\n",
      "Data columns (total 21 columns):\n",
      "site1     2297 non-null int32\n",
      "time1     2297 non-null datetime64[ns]\n",
      "site2     2297 non-null int32\n",
      "time2     2294 non-null datetime64[ns]\n",
      "site3     2297 non-null int32\n",
      "time3     2287 non-null datetime64[ns]\n",
      "site4     2297 non-null int32\n",
      "time4     2286 non-null datetime64[ns]\n",
      "site5     2297 non-null int32\n",
      "time5     2280 non-null datetime64[ns]\n",
      "site6     2297 non-null int32\n",
      "time6     2273 non-null datetime64[ns]\n",
      "site7     2297 non-null int32\n",
      "time7     2269 non-null datetime64[ns]\n",
      "site8     2297 non-null int32\n",
      "time8     2263 non-null datetime64[ns]\n",
      "site9     2297 non-null int32\n",
      "time9     2262 non-null datetime64[ns]\n",
      "site10    2297 non-null int32\n",
      "time10    2258 non-null datetime64[ns]\n",
      "target    2297 non-null int64\n",
      "dtypes: datetime64[ns](10), int32(10), int64(1)\n",
      "memory usage: 305.1 KB\n"
     ]
    }
   ],
   "source": [
    "train_df[train_df['target']==1].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "      <th>timestamp2</th>\n",
       "      <th>site2</th>\n",
       "      <th>timestamp3</th>\n",
       "      <th>site3</th>\n",
       "      <th>timestamp4</th>\n",
       "      <th>site4</th>\n",
       "      <th>timestamp5</th>\n",
       "      <th>site5</th>\n",
       "      <th>timestamp6</th>\n",
       "      <th>site6</th>\n",
       "      <th>timestamp7</th>\n",
       "      <th>site7</th>\n",
       "      <th>timestamp8</th>\n",
       "      <th>site8</th>\n",
       "      <th>timestamp9</th>\n",
       "      <th>site9</th>\n",
       "      <th>timestamp10</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-12 16:25:10</td>\n",
       "      <td>270</td>\n",
       "      <td>2013-02-12 16:25:11</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-12 16:25:11</td>\n",
       "      <td>270</td>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12 16:32:10</td>\n",
       "      <td>270</td>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2013-02-12 16:32:28</td>\n",
       "      <td>7832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-12 16:32:11</td>\n",
       "      <td>21</td>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2013-02-12 16:32:28</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:29</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-12 16:32:24</td>\n",
       "      <td>21</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013-02-12 16:32:26</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2013-02-12 16:32:28</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>2013-02-12 16:32:29</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2013-02-12 16:32:34</td>\n",
       "      <td>7832.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  site          timestamp2   site2          timestamp3  \\\n",
       "0 2013-02-12 16:25:10   270 2013-02-12 16:25:11   270.0 2013-02-12 16:32:10   \n",
       "1 2013-02-12 16:25:11   270 2013-02-12 16:32:10   270.0 2013-02-12 16:32:11   \n",
       "2 2013-02-12 16:32:10   270 2013-02-12 16:32:11    21.0 2013-02-12 16:32:24   \n",
       "3 2013-02-12 16:32:11    21 2013-02-12 16:32:24    21.0 2013-02-12 16:32:25   \n",
       "4 2013-02-12 16:32:24    21 2013-02-12 16:32:25  7832.0 2013-02-12 16:32:25   \n",
       "\n",
       "    site3          timestamp4   site4          timestamp5   site5  \\\n",
       "0   270.0 2013-02-12 16:32:11    21.0 2013-02-12 16:32:24    21.0   \n",
       "1    21.0 2013-02-12 16:32:24    21.0 2013-02-12 16:32:25  7832.0   \n",
       "2    21.0 2013-02-12 16:32:25  7832.0 2013-02-12 16:32:25    21.0   \n",
       "3  7832.0 2013-02-12 16:32:25    21.0 2013-02-12 16:32:26  7832.0   \n",
       "4    21.0 2013-02-12 16:32:26  7832.0 2013-02-12 16:32:27    30.0   \n",
       "\n",
       "           timestamp6   site6          timestamp7   site7          timestamp8  \\\n",
       "0 2013-02-12 16:32:25  7832.0 2013-02-12 16:32:25    21.0 2013-02-12 16:32:26   \n",
       "1 2013-02-12 16:32:25    21.0 2013-02-12 16:32:26  7832.0 2013-02-12 16:32:27   \n",
       "2 2013-02-12 16:32:26  7832.0 2013-02-12 16:32:27    30.0 2013-02-12 16:32:27   \n",
       "3 2013-02-12 16:32:27    30.0 2013-02-12 16:32:27  7832.0 2013-02-12 16:32:27   \n",
       "4 2013-02-12 16:32:27  7832.0 2013-02-12 16:32:27    29.0 2013-02-12 16:32:28   \n",
       "\n",
       "    site8          timestamp9   site9         timestamp10  site10  \n",
       "0  7832.0 2013-02-12 16:32:27    30.0 2013-02-12 16:32:27  7832.0  \n",
       "1    30.0 2013-02-12 16:32:27  7832.0 2013-02-12 16:32:27    29.0  \n",
       "2  7832.0 2013-02-12 16:32:27    29.0 2013-02-12 16:32:28  7832.0  \n",
       "3    29.0 2013-02-12 16:32:28  7832.0 2013-02-12 16:32:29    37.0  \n",
       "4  7832.0 2013-02-12 16:32:29    37.0 2013-02-12 16:32:34  7832.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT = 30\n",
    "\n",
    "df_alice = pd.read_csv('data/train/Alice_log.csv')\n",
    "df_alice['timestamp'] = df_alice['timestamp'].apply(pd.to_datetime)\n",
    "for i in range(-1, -10, -1):\n",
    "    df_alice['timestamp' + str(-i+1)] = df_alice['timestamp'].shift(i)\n",
    "    df_alice['site' + str(-i+1)] = df_alice['site'].shift(i)\n",
    "    \n",
    "    df_alice['dt'] = (df_alice['timestamp' + str(-i+1)] - df_alice['timestamp']).dt.seconds / 60\n",
    "    df_alice.loc[df_alice['dt']>DT, ['timestamp' + str(-i+1), 'site' + str(-i+1)]] = None\n",
    "\n",
    "del df_alice['dt']\n",
    "\n",
    "to_int = dict(zip(sites_dict['site'], sites_dict.index))\n",
    "for col in df_alice.columns:\n",
    "    if 'site' in col:\n",
    "        df_alice[col] = df_alice[col].map(to_int)\n",
    "\n",
    "# df_alice['dt'] = (df_alice['timestamp'].shift(-1) - df_alice['timestamp']).dt.seconds / 60\n",
    "# df_alice['dt_10sites'] = (df_alice['timestamp'].shift(-10) - df_alice['timestamp']).dt.seconds / 60\n",
    "df_alice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
