{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import clone\n",
    "from tqdm import tqdm \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "PATH_TO_DATA = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cols = ['time%d' % i for i in range(1, 11)]\n",
    "site_cols = ['site%d' % i for i in range(1, 11)]\n",
    "\n",
    "train_df = pd.read_csv(PATH_TO_DATA + 'train_sessions.csv', index_col='session_id', parse_dates=time_cols)\n",
    "test_df = pd.read_csv(PATH_TO_DATA + 'test_sessions.csv', index_col='session_id', parse_dates=time_cols)\n",
    "\n",
    "with open(PATH_TO_DATA + 'site_dic.pkl', 'rb') as site_file:\n",
    "     sites_dict = pickle.load(site_file)\n",
    "        \n",
    "id_sites_dict = {v: k for k, v in sites_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X_data, y_data):\n",
    "    grouped = train_df[['target']].groupby(by='target')\n",
    "    \n",
    "    train_ids = []\n",
    "    valid_ids = []\n",
    "    \n",
    "    for g in tqdm(grouped.groups.keys()):\n",
    "        train_shape = int(grouped.get_group(g).shape[0] * 0.7)\n",
    "\n",
    "        ids_to_train = grouped.get_group(g).index[:train_shape]\n",
    "        ids_to_valid = grouped.get_group(g).index[train_shape:]\n",
    "\n",
    "        train_ids.extend(ids_to_train)\n",
    "        valid_ids.extend(ids_to_valid)\n",
    "        \n",
    "    train_ids = np.array(train_ids) - 1\n",
    "    valid_ids = np.array(valid_ids) - 1\n",
    "        \n",
    "    return X_data.tocsc()[train_ids], y_data[train_ids], X_data.tocsc()[valid_ids], y_data[valid_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_matrix(matrix):\n",
    "    site_ids = list(id_sites_dict)\n",
    "    X = matrix.values\n",
    "    \n",
    "    i = 0\n",
    "    data = list()\n",
    "    col = list()\n",
    "    rows = list()\n",
    "    for row in tqdm(X):\n",
    "        unique, counts = np.unique(row, return_counts=True)\n",
    "        dic = dict(zip(unique, counts))\n",
    "        for k in dic:\n",
    "            if k != 0:\n",
    "                data.append(dic[k])\n",
    "                rows.append(i)\n",
    "                col.append(k-1)\n",
    "            \n",
    "        i += 1\n",
    "    X_sparse = csr_matrix((data, (rows, col)), shape=(X.shape[0], len(site_ids)))\n",
    "    return X_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, X_train, y_train, X_valid, y_valid):\n",
    "    model.fit(X_train, y_train)\n",
    "    valid_score = model.predict_proba(X_valid)\n",
    "    print(roc_auc_score(y_valid, valid_score[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file, target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels, index = np.arange(1, predicted_labels.shape[0] + 1), columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(model, X_train, y_train, X_test, file_name):\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred_proba = model.predict_proba(X_test)\n",
    "    write_to_submission_file(test_pred_proba[:, 1:], file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exptact_time_features(data):\n",
    "\n",
    "    day_offset = 24\n",
    "    month_offset = day_offset + 7\n",
    "    morning_offset = month_offset + 12\n",
    "    evening_offset = morning_offset + 1\n",
    "    row_size = evening_offset + 2\n",
    "    values = []\n",
    "\n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "        \n",
    "        time = row[time_cols[0]]\n",
    "\n",
    "        r = np.zeros(row_size)\n",
    "        r[time.hour] += 1\n",
    "        r[day_offset + time.dayofweek] += 1\n",
    "        r[month_offset + time.month] += 1\n",
    "        r[morning_offset] = time.hour < 11\n",
    "        r[evening_offset] = time.hour > 19\n",
    "        values.append(r[1:])\n",
    "        \n",
    "    return csr_matrix(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(data):\n",
    "    return csr_matrix([[sum(1 for s in np.unique(row.values) if s != 0)] for _, row in tqdm(data.iterrows())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_train = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in train_df[site_cols].iterrows()]\n",
    "str_test = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in test_df[site_cols].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 2)).fit(np.array(str_train))\n",
    "X_train_idf = tfidf.transform(np.array(str_train))\n",
    "X_test_idf = tfidf.transform(np.array(str_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:18, 13547.16it/s]\n",
      "253561it [00:26, 9605.02it/s]\n",
      "82797it [00:05, 14269.17it/s]\n",
      "82797it [00:08, 9822.51it/s] \n"
     ]
    }
   ],
   "source": [
    "X_tmp_train = hstack((X_train_idf, \n",
    "                      exptact_time_features(train_df[time_cols]),\n",
    "                      unique(train_df[site_cols].fillna(0).astype('int'))))\n",
    "\n",
    "X_tmp_test = hstack((X_test_idf, \n",
    "                     exptact_time_features(test_df[time_cols]),\n",
    "                     unique(test_df[site_cols].fillna(0).astype('int'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 33.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((177491, 129384), (177491,), (76070, 129384), (76070,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid = split_data(X_tmp_train, train_df['target'].values.astype('int64'))\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit_c_values = np.logspace(-4, 2, 10)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=17)\n",
    "\n",
    "logit_grid_searcher = LogisticRegressionCV(Cs=logit_c_values, cv=skf, n_jobs=-1)\n",
    "logit_grid_searcher.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.000000    0.995205\n",
       "21.544347     0.995183\n",
       "4.641589      0.994653\n",
       "1.000000      0.993600\n",
       "0.215443      0.992687\n",
       "0.046416      0.991481\n",
       "0.010000      0.990946\n",
       "0.002154      0.990946\n",
       "0.000464      0.990946\n",
       "0.000100      0.990946\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_mean_cv_scores = next (iter (logit_grid_searcher.scores_.values())).mean(axis=0)\n",
    "pd.Series(logit_mean_cv_scores, index=logit_grid_searcher.Cs_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9900939394988099\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 253561/253561 [00:11<00:00, 23033.61it/s]\n",
      "253561it [00:18, 14029.15it/s]\n",
      "253561it [00:21, 11798.66it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_sparse = get_dense_matrix(train_df[site_cols].fillna(0).astype('int'))\n",
    "X_train_time_features = exptact_time_features(train_df[time_cols])\n",
    "X_Train_unique = unique(train_df[site_cols].fillna(0).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp_train = hstack((X_train_sparse, X_train_time_features, X_Train_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 29.61it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid = split_data(X_tmp_train, train_df['target'].values.astype('int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    175884\n",
       "1      1607\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75380\n",
       "1      690\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_valid).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_tmp_train, y, train_size =0.7, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    175884\n",
       "1      1608\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75380\n",
       "1      689\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_valid).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, X, y, train_size=0.7, random_states=[1, 13, 42]):\n",
    "    result = []\n",
    "    \n",
    "    for rs in random_states:\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=train_size, stratify=y, random_state=rs)\n",
    "        m = clone(model, safe=True)\n",
    "        m.fit(X_train, y_train)\n",
    "        valid_score = m.predict_proba(X_valid)\n",
    "        result.append(roc_auc_score(y_valid, valid_score[:, 1:]))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid value for train_size: <76069x48417 sparse matrix of type '<class 'numpy.float64'>'\n\twith 757097 stored elements in Compressed Sparse Row format>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-ce46e8881ca0>\u001b[0m in \u001b[0;36mscore\u001b[1;34m(model, X, y, train_size, random_states)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrandom_states\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2205\u001b[0m         cv = CVClass(test_size=test_size,\n\u001b[0;32m   2206\u001b[0m                      \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2207\u001b[1;33m                      random_state=random_state)\n\u001b[0m\u001b[0;32m   2208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2209\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, test_size, train_size, random_state)\u001b[0m\n\u001b[0;32m   1675\u001b[0m                  random_state=None):\n\u001b[0;32m   1676\u001b[0m         super(StratifiedShuffleSplit, self).__init__(\n\u001b[1;32m-> 1677\u001b[1;33m             n_splits, test_size, train_size, random_state)\n\u001b[0m\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, test_size, train_size, random_state)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     def __init__(self, n_splits=10, test_size=\"default\", train_size=None,\n\u001b[0;32m   1277\u001b[0m                  random_state=None):\n\u001b[1;32m-> 1278\u001b[1;33m         \u001b[0m_validate_shuffle_split_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split_init\u001b[1;34m(test_size, train_size)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'i'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m             \u001b[1;31m# int values are checked during split based on the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid value for train_size: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid value for train_size: <76069x48417 sparse matrix of type '<class 'numpy.float64'>'\n\twith 757097 stored elements in Compressed Sparse Row format>"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9869365413592901, 0.9869002280077986, 0.9894256521673834]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_tmp_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_df[time_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>time4</th>\n",
       "      <th>time5</th>\n",
       "      <th>time6</th>\n",
       "      <th>time7</th>\n",
       "      <th>time8</th>\n",
       "      <th>time9</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-20 10:02:45</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>2014-02-22 11:20:15</td>\n",
       "      <td>2014-02-22 11:20:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-16 16:40:17</td>\n",
       "      <td>2013-12-16 16:40:18</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:20</td>\n",
       "      <td>2013-12-16 16:40:21</td>\n",
       "      <td>2013-12-16 16:40:22</td>\n",
       "      <td>2013-12-16 16:40:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time1               time2               time3  \\\n",
       "session_id                                                               \n",
       "1          2014-02-20 10:02:45                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:50 2014-02-22 11:19:50 2014-02-22 11:19:51   \n",
       "3          2013-12-16 16:40:17 2013-12-16 16:40:18 2013-12-16 16:40:19   \n",
       "\n",
       "                         time4               time5               time6  \\\n",
       "session_id                                                               \n",
       "1                          NaT                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:51 2014-02-22 11:19:51 2014-02-22 11:19:51   \n",
       "3          2013-12-16 16:40:19 2013-12-16 16:40:19 2013-12-16 16:40:19   \n",
       "\n",
       "                         time7               time8               time9  \\\n",
       "session_id                                                               \n",
       "1                          NaT                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:52 2014-02-22 11:19:52 2014-02-22 11:20:15   \n",
       "3          2013-12-16 16:40:20 2013-12-16 16:40:21 2013-12-16 16:40:22   \n",
       "\n",
       "                        time10  \n",
       "session_id                      \n",
       "1                          NaT  \n",
       "2          2014-02-22 11:20:16  \n",
       "3          2013-12-16 16:40:24  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_month(data):\n",
    "    time = time_cols[0]\n",
    "    values = [row[time].year * 100 + row[time].month for _, row in tqdm(data.iterrows())]\n",
    "    series = pd.Series(values)\n",
    "    return csr_matrix(pd.get_dummies(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:21, 11980.31it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_year_month = extract_year_month(train_df[time_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, X_train_time_features, X_Train_unique, X_train_year_month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9870906901885792, 0.9870493707546978, 0.9895351505925853]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_part_of_day(data):\n",
    "    time = time_cols[0]\n",
    "    values = [row[time].hour // 6 for _, row in tqdm(data.iterrows())]\n",
    "    series = pd.Series(values)\n",
    "    return csr_matrix(pd.get_dummies(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:16, 15815.78it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_part_of_day = extract_part_of_day(train_df[time_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, X_train_time_features, X_Train_unique, X_train_part_of_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.986982616571442, 0.9869237373408691, 0.9892917972259372]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weekend(data):\n",
    "    time = time_cols[0]\n",
    "    values = [[row[time].dayofweek > 4] for _, row in tqdm(data.iterrows())]\n",
    "    return csr_matrix(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:16, 15684.93it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_weekend = extract_weekend(train_df[time_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, X_train_time_features, X_Train_unique, X_train_weekend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9869277422067813, 0.9869012099701138, 0.9894044725880407]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_df[time_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>time4</th>\n",
       "      <th>time5</th>\n",
       "      <th>time6</th>\n",
       "      <th>time7</th>\n",
       "      <th>time8</th>\n",
       "      <th>time9</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-20 10:02:45</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>2014-02-22 11:20:15</td>\n",
       "      <td>2014-02-22 11:20:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-16 16:40:17</td>\n",
       "      <td>2013-12-16 16:40:18</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>2013-12-16 16:40:20</td>\n",
       "      <td>2013-12-16 16:40:21</td>\n",
       "      <td>2013-12-16 16:40:22</td>\n",
       "      <td>2013-12-16 16:40:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time1               time2               time3  \\\n",
       "session_id                                                               \n",
       "1          2014-02-20 10:02:45                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:50 2014-02-22 11:19:50 2014-02-22 11:19:51   \n",
       "3          2013-12-16 16:40:17 2013-12-16 16:40:18 2013-12-16 16:40:19   \n",
       "\n",
       "                         time4               time5               time6  \\\n",
       "session_id                                                               \n",
       "1                          NaT                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:51 2014-02-22 11:19:51 2014-02-22 11:19:51   \n",
       "3          2013-12-16 16:40:19 2013-12-16 16:40:19 2013-12-16 16:40:19   \n",
       "\n",
       "                         time7               time8               time9  \\\n",
       "session_id                                                               \n",
       "1                          NaT                 NaT                 NaT   \n",
       "2          2014-02-22 11:19:52 2014-02-22 11:19:52 2014-02-22 11:20:15   \n",
       "3          2013-12-16 16:40:20 2013-12-16 16:40:21 2013-12-16 16:40:22   \n",
       "\n",
       "                        time10  \n",
       "session_id                      \n",
       "1                          NaT  \n",
       "2          2014-02-22 11:20:16  \n",
       "3          2013-12-16 16:40:24  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_duration(data):\n",
    "    values = []\n",
    "    time = time_cols[0]\n",
    "\n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "\n",
    "        first = row[time]\n",
    "        last = first\n",
    "\n",
    "        for t, check in zip(time_cols, row.values == np.datetime64('NaT')):\n",
    "            if check:\n",
    "                break\n",
    "            else:\n",
    "                last = row[t]\n",
    "\n",
    "        values.append([np.log1p(last.minute - first.minute)])\n",
    "\n",
    "    return csr_matrix(np.nan_to_num(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [01:11, 3566.61it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_duration = extract_duration(train_df[time_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, X_train_time_features, X_Train_unique, X_train_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9870381359505644, 0.9868416472167529, 0.9895346114760203]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_week(data):\n",
    "    time = time_cols[0]\n",
    "    values = []\n",
    "    \n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "        \n",
    "        r = np.zeros(53)\n",
    "        r[row[time].week] = 1\n",
    "        values.append(r)\n",
    "        \n",
    "    return csr_matrix(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:17, 14362.88it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_weeks = extract_week(train_df[time_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, X_train_time_features, X_Train_unique, X_train_weeks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9894175365376625, 0.9901336951318929, 0.9910148522762849]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((X_train_sparse, \n",
    "            X_train_time_features, \n",
    "            X_Train_unique, \n",
    "            X_train_year_month, \n",
    "            X_train_part_of_day, \n",
    "            X_train_weekend,\n",
    "            X_train_duration,\n",
    "            X_train_weeks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9895003968283003, 0.990180992983398, 0.9909503123217787]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_sites_df = pd.concat([train_df[site_cols].fillna(0).astype('int'), test_df[site_cols].fillna(0).astype('int')])\n",
    "train_test_times_df = pd.concat([train_df[time_cols], test_df[time_cols]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 336358/336358 [00:13<00:00, 25523.40it/s]\n",
      "336358it [00:23, 14116.79it/s]\n",
      "336358it [00:36, 9297.70it/s]\n",
      "336358it [00:26, 12652.57it/s]\n",
      "336358it [00:20, 16380.67it/s]\n",
      "336358it [00:22, 15117.17it/s]\n",
      "336358it [01:24, 3958.92it/s]\n",
      "336358it [00:21, 15349.42it/s]\n"
     ]
    }
   ],
   "source": [
    "X_tmp_sparse = get_dense_matrix(train_test_sites_df)\n",
    "X_tmp_time_features = exptact_time_features(train_test_times_df)\n",
    "X_tmp_unique = unique(train_test_sites_df)\n",
    "\n",
    "X_tmp_year_month = extract_year_month(train_test_times_df)\n",
    "X_tmp_part_of_day = extract_part_of_day(train_test_times_df)\n",
    "X_tmp_weekend = extract_weekend(train_test_times_df)\n",
    "X_tmp_duration = extract_duration(train_test_times_df)\n",
    "X_tmp_weeks = extract_week(train_test_times_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_test(data, train_size):\n",
    "    return data.tocsc()[:train_size], data.tocsc()[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_tmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-7f5b78a3b420>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_tmp' is not defined"
     ]
    }
   ],
   "source": [
    "X_tmp.shape, X_train.shape, X_test.shape, train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = hstack((X_tmp_sparse, \n",
    "                X_tmp_time_features, \n",
    "                X_tmp_unique, \n",
    "                X_tmp_year_month, \n",
    "#                 X_tmp_part_of_day, \n",
    "#                 X_tmp_weekend,\n",
    "#                 X_tmp_duration,\n",
    "#                 X_tmp_weeks\n",
    "               ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_test = split_train_and_test(X_tmp, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253561it [00:17, 14354.43it/s]\n",
      "82797it [00:05, 14436.92it/s]\n"
     ]
    }
   ],
   "source": [
    "str_train = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in tqdm(train_df[site_cols].iterrows())]\n",
    "str_test = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in tqdm(test_df[site_cols].iterrows())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 5)).fit(np.array(str_train))\n",
    "X_train_idf = tfidf.transform(np.array(str_train))\n",
    "X_test_idf = tfidf.transform(np.array(str_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = hstack((vstack((X_train_idf, X_test_idf)), \n",
    "                X_tmp_time_features, \n",
    "                X_tmp_unique, \n",
    "                X_tmp_year_month, \n",
    "                X_tmp_part_of_day, \n",
    "                X_tmp_weekend,\n",
    "                X_tmp_duration,\n",
    "                X_tmp_weeks\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_test = split_train_and_test(X_tmp, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9902382933726015, 0.9920294503976177, 0.989674647003802]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.990263362292878, 0.9920144128962844, 0.9894890368721073]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=15, n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 1698311)\n",
      "(82797, 1698311)\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_submission(LogisticRegression(C=15, n_jobs=-1), X_train, y, X_test, 'i_test.csv') # 0.96002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse = vstack((X_train_idf, X_test_idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100)\n",
    "X_svd = svd.fit_transform(X_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = hstack((X_sparse, X_svd,\n",
    "                X_tmp_time_features, \n",
    "                X_tmp_unique, \n",
    "                X_tmp_year_month, \n",
    "                X_tmp_part_of_day, \n",
    "                X_tmp_weekend,\n",
    "                X_tmp_duration,\n",
    "                X_tmp_weeks\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_test = split_train_and_test(X_tmp, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9902779376942987, 0.9921437046010904, 0.9899757628595668]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9902991942902936, 0.9921449753758509, 0.9898079050661939]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=15, n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9879016274003685, 0.9884361807288162, 0.9825051090921624]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=21.544347, solver='lbfgs', n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9874112623760948, 0.9890079523544183, 0.9820001879206313]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=15, solver='lbfgs', n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9869483152799883, 0.98891019896867, 0.9822151606509602]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=37.92690190732246, solver='lbfgs', n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_params' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_params = {'C' : np.logspace(-2, 2, 20)}\n",
    "gridsearcer = GridSearchCV(LogisticRegression(solver='lbfgs', n_jobs=-1), grid_params, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "gridsearcer.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 3), max_features=100000).fit(np.array(str_train))\n",
    "X_train_idf = tfidf.transform(np.array(str_train))\n",
    "X_test_idf = tfidf.transform(np.array(str_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = hstack((vstack((X_train_idf, X_test_idf)), \n",
    "                X_tmp_time_features, \n",
    "                X_tmp_unique, \n",
    "                X_tmp_year_month, \n",
    "                X_tmp_part_of_day, \n",
    "                X_tmp_weekend,\n",
    "                X_tmp_duration,\n",
    "                X_tmp_weeks\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_test = split_train_and_test(X_tmp, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9902807488021023, 0.9919933103335938, 0.9894300036082302]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=15, n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 1698311)\n",
      "(82797, 1698311)\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_submission(LogisticRegression(C=15, n_jobs=-1), X_train, y, X_test, 'i_test_tfidf_3_max_100K.csv') # 0.95952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_alice_top_30(df_sites):\n",
    "    alice_top_30 = pd.Series(df_sites[:y.shape[0]][y==1].values.flatten()).value_counts()[:30]\n",
    "    alice_top_30 = alice_top_30.drop(0) \n",
    "    return df_sites.apply(lambda row: row.isin(alice_top_30).astype(int), axis=1).max(axis=1).values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_long(df):\n",
    "    return ((df.max(axis=1) - df.time1).dt.seconds > 60).astype(int).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(df):\n",
    "    return (df.time1.dt.year % 2013).astype(int).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_train = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in tqdm(train_df[site_cols].iterrows())]\n",
    "str_test = [' '.join([id_sites_dict[idx] for idx in row.values if idx in id_sites_dict]) for _, row in tqdm(test_df[site_cols].iterrows())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "853it [00:00, 8454.34it/s]\n",
      "1780it [00:00, 8661.75it/s]\n",
      "2731it [00:00, 8877.55it/s]\n",
      "3673it [00:00, 9010.36it/s]\n",
      "4624it [00:00, 9131.05it/s]\n",
      "5547it [00:00, 9136.13it/s]\n",
      "6485it [00:00, 9183.70it/s]\n",
      "7418it [00:00, 9202.65it/s]\n",
      "8373it [00:00, 9279.86it/s]\n",
      "9330it [00:01, 9340.48it/s]\n",
      "10266it [00:01, 9321.31it/s]\n",
      "11182it [00:01, 9219.26it/s]\n",
      "12093it [00:01, 9161.39it/s]\n",
      "13028it [00:01, 9192.79it/s]\n",
      "13972it [00:01, 9241.22it/s]\n",
      "14912it [00:01, 9263.69it/s]\n",
      "15863it [00:01, 9311.67it/s]\n",
      "16793it [00:01, 9200.59it/s]\n",
      "17731it [00:01, 9229.22it/s]\n",
      "18683it [00:02, 9290.14it/s]\n",
      "19622it [00:02, 9295.07it/s]\n",
      "20558it [00:02, 9289.62it/s]\n",
      "21498it [00:02, 9297.67it/s]\n",
      "22433it [00:02, 9288.42it/s]\n",
      "23372it [00:02, 9293.87it/s]\n",
      "24313it [00:02, 9303.60it/s]\n",
      "25244it [00:02, 9198.15it/s]\n",
      "26176it [00:02, 9209.89it/s]\n",
      "27111it [00:02, 9226.90it/s]\n",
      "28048it [00:03, 9244.79it/s]\n",
      "28973it [00:03, 9221.62it/s]\n",
      "29908it [00:03, 9235.13it/s]\n",
      "30832it [00:03, 9211.83it/s]\n",
      "31759it [00:03, 9204.62it/s]\n",
      "32704it [00:03, 9252.43it/s]\n",
      "33646it [00:03, 9277.47it/s]\n",
      "34574it [00:03, 9225.80it/s]\n",
      "35497it [00:03, 9174.91it/s]\n",
      "36439it [00:03, 9222.73it/s]\n",
      "37389it [00:04, 9279.80it/s]\n",
      "38329it [00:04, 9290.78it/s]\n",
      "39283it [00:04, 9339.52it/s]\n",
      "40218it [00:04, 9317.63it/s]\n",
      "41150it [00:04, 9265.66it/s]\n",
      "42077it [00:04, 9214.61it/s]\n",
      "42999it [00:04, 9029.68it/s]\n",
      "43903it [00:04, 8928.56it/s]\n",
      "44827it [00:04, 8996.18it/s]\n",
      "45766it [00:04, 9087.10it/s]\n",
      "46701it [00:05, 9140.31it/s]\n",
      "47646it [00:05, 9206.88it/s]\n",
      "48601it [00:05, 9282.90it/s]\n",
      "49530it [00:05, 9260.17it/s]\n",
      "50457it [00:05, 9183.44it/s]\n",
      "51376it [00:05, 9079.41it/s]\n",
      "52285it [00:05, 9031.28it/s]\n",
      "53195it [00:05, 9027.64it/s]\n",
      "54124it [00:05, 9080.86it/s]\n",
      "55075it [00:05, 9181.57it/s]\n",
      "56018it [00:06, 9230.37it/s]\n",
      "56963it [00:06, 9270.69it/s]\n",
      "57901it [00:06, 9278.47it/s]\n",
      "58838it [00:06, 9280.95it/s]\n",
      "59767it [00:06, 9258.79it/s]\n",
      "60696it [00:06, 9243.38it/s]\n",
      "61636it [00:06, 9265.17it/s]\n",
      "62563it [00:06, 9186.87it/s]\n",
      "63496it [00:06, 9204.91it/s]\n",
      "64426it [00:06, 9208.63it/s]\n",
      "65374it [00:07, 9264.02it/s]\n",
      "66324it [00:07, 9308.95it/s]\n",
      "67271it [00:07, 9331.95it/s]\n",
      "68205it [00:07, 9309.34it/s]\n",
      "69139it [00:07, 9293.59it/s]\n",
      "70076it [00:07, 9291.56it/s]\n",
      "71016it [00:07, 9299.04it/s]\n",
      "71946it [00:07, 9137.84it/s]\n",
      "72875it [00:07, 9158.65it/s]\n",
      "73805it [00:08, 9175.53it/s]\n",
      "74741it [00:08, 9206.35it/s]\n",
      "75687it [00:08, 9256.61it/s]\n",
      "76622it [00:08, 9259.67it/s]\n",
      "77549it [00:08, 9210.48it/s]\n",
      "78501it [00:08, 9276.82it/s]\n",
      "79439it [00:08, 9282.78it/s]\n",
      "80383it [00:08, 9304.67it/s]\n",
      "81314it [00:08, 9253.70it/s]\n",
      "82244it [00:08, 9242.77it/s]\n",
      "83197it [00:09, 9302.65it/s]\n",
      "84138it [00:09, 9309.77it/s]\n",
      "85070it [00:09, 9287.89it/s]\n",
      "85999it [00:09, 9236.01it/s]\n",
      "86932it [00:09, 9239.37it/s]\n",
      "87860it [00:09, 9226.79it/s]\n",
      "88803it [00:09, 9262.26it/s]\n",
      "89730it [00:09, 9239.82it/s]\n",
      "90656it [00:09, 9221.12it/s]\n",
      "91591it [00:09, 9234.79it/s]\n",
      "92524it [00:10, 9238.50it/s]\n",
      "93458it [00:10, 9244.05it/s]\n",
      "94399it [00:10, 9268.59it/s]\n",
      "95326it [00:10, 9244.20it/s]\n",
      "96259it [00:10, 9245.10it/s]\n",
      "97191it [00:10, 9242.72it/s]\n",
      "98119it [00:10, 9229.15it/s]\n",
      "99042it [00:10, 9204.63it/s]\n",
      "99975it [00:10, 9217.35it/s]\n",
      "100909it [00:10, 9229.25it/s]\n",
      "101843it [00:11, 9237.55it/s]\n",
      "102774it [00:11, 9234.50it/s]\n",
      "103698it [00:11, 9156.69it/s]\n",
      "104614it [00:11, 9078.88it/s]\n",
      "105534it [00:11, 9090.66it/s]\n",
      "106482it [00:11, 9180.10it/s]\n",
      "107413it [00:11, 9194.20it/s]\n",
      "108333it [00:11, 9116.86it/s]\n",
      "109258it [00:11, 9132.07it/s]\n",
      "110185it [00:11, 9148.66it/s]\n",
      "111132it [00:12, 9218.58it/s]\n",
      "112062it [00:12, 9218.24it/s]\n",
      "112984it [00:12, 9139.45it/s]\n",
      "113899it [00:12, 9010.46it/s]\n",
      "114827it [00:12, 9065.80it/s]\n",
      "115778it [00:12, 9170.79it/s]\n",
      "116710it [00:12, 9190.62it/s]\n",
      "117630it [00:12, 9114.36it/s]\n",
      "118571it [00:12, 9176.96it/s]\n",
      "119499it [00:12, 9183.16it/s]\n",
      "120449it [00:13, 9251.69it/s]\n",
      "121392it [00:13, 9279.84it/s]\n",
      "122329it [00:13, 9281.96it/s]\n",
      "123258it [00:13, 9231.92it/s]\n",
      "124182it [00:13, 9209.59it/s]\n",
      "125130it [00:13, 9264.67it/s]\n",
      "126057it [00:13, 9241.46it/s]\n",
      "126982it [00:13, 9164.50it/s]\n",
      "127925it [00:13, 9218.27it/s]\n",
      "128874it [00:13, 9273.75it/s]\n",
      "129816it [00:14, 9292.21it/s]\n",
      "130746it [00:14, 9242.25it/s]\n",
      "131671it [00:14, 9110.93it/s]\n",
      "132583it [00:14, 8903.10it/s]\n",
      "133475it [00:14, 8857.86it/s]\n",
      "134371it [00:14, 8864.63it/s]\n",
      "135259it [00:14, 8766.97it/s]\n",
      "136137it [00:14, 8493.76it/s]\n",
      "136989it [00:14, 8185.91it/s]\n",
      "137812it [00:15, 7895.11it/s]\n",
      "138607it [00:15, 7263.82it/s]\n",
      "139486it [00:15, 7645.07it/s]\n",
      "140324it [00:15, 7831.91it/s]\n",
      "141139it [00:15, 7904.04it/s]\n",
      "141938it [00:15, 7658.64it/s]\n",
      "142823it [00:15, 7961.66it/s]\n",
      "143683it [00:15, 8122.28it/s]\n",
      "144600it [00:15, 8389.89it/s]\n",
      "145446it [00:15, 8030.44it/s]\n",
      "146263it [00:16, 8050.41it/s]\n",
      "147129it [00:16, 8203.17it/s]\n",
      "147954it [00:16, 8027.90it/s]\n",
      "148886it [00:16, 8356.09it/s]\n",
      "149848it [00:16, 8677.87it/s]\n",
      "150804it [00:16, 8902.57it/s]\n",
      "151704it [00:16, 8907.82it/s]\n",
      "152600it [00:16, 8769.10it/s]\n",
      "153489it [00:16, 8781.66it/s]\n",
      "154373it [00:17, 8775.60it/s]\n",
      "155253it [00:17, 8681.69it/s]\n",
      "156123it [00:17, 8587.06it/s]\n",
      "157054it [00:17, 8769.58it/s]\n",
      "157985it [00:17, 8902.08it/s]\n",
      "158927it [00:17, 9027.98it/s]\n",
      "159877it [00:17, 9140.92it/s]\n",
      "160793it [00:17, 9095.02it/s]\n",
      "161748it [00:17, 9203.03it/s]\n",
      "162670it [00:17, 9156.12it/s]\n",
      "163587it [00:18, 9108.55it/s]\n",
      "164499it [00:18, 9060.51it/s]\n",
      "165429it [00:18, 9107.02it/s]\n",
      "166391it [00:18, 9231.17it/s]\n",
      "167315it [00:18, 9209.12it/s]\n",
      "168237it [00:18, 8947.22it/s]\n",
      "169134it [00:18, 8572.02it/s]\n",
      "169996it [00:18, 7734.47it/s]\n",
      "170869it [00:18, 7988.73it/s]\n",
      "171751it [00:19, 8200.62it/s]\n",
      "172670it [00:19, 8453.40it/s]\n",
      "173526it [00:19, 8242.75it/s]\n",
      "174364it [00:19, 8261.50it/s]\n",
      "175259it [00:19, 8435.20it/s]\n",
      "176162it [00:19, 8583.27it/s]\n",
      "177105it [00:19, 8798.77it/s]\n",
      "178049it [00:19, 8958.88it/s]\n",
      "178971it [00:19, 9011.92it/s]\n",
      "179919it [00:19, 9136.75it/s]\n",
      "180859it [00:20, 9189.86it/s]\n",
      "181805it [00:20, 9244.77it/s]\n",
      "182738it [00:20, 9265.65it/s]\n",
      "183678it [00:20, 9282.41it/s]\n",
      "184607it [00:20, 9284.67it/s]\n",
      "185536it [00:20, 9152.02it/s]\n",
      "186466it [00:20, 9171.44it/s]\n",
      "187390it [00:20, 9167.38it/s]\n",
      "188330it [00:20, 9211.60it/s]\n",
      "189275it [00:20, 9257.45it/s]\n",
      "190221it [00:21, 9292.67it/s]\n",
      "191159it [00:21, 9293.89it/s]\n",
      "192105it [00:21, 9318.36it/s]\n",
      "193037it [00:21, 9293.91it/s]\n",
      "193967it [00:21, 9243.18it/s]\n",
      "194913it [00:21, 9282.65it/s]\n",
      "195842it [00:21, 9259.96it/s]\n",
      "196769it [00:21, 9238.14it/s]\n",
      "197716it [00:21, 9281.97it/s]\n",
      "198664it [00:21, 9315.84it/s]\n",
      "199603it [00:22, 9313.09it/s]\n",
      "200556it [00:22, 9352.39it/s]\n",
      "201492it [00:22, 9329.62it/s]\n",
      "202426it [00:22, 9307.60it/s]\n",
      "203364it [00:22, 9304.44it/s]\n",
      "204295it [00:22, 9171.56it/s]\n",
      "205226it [00:22, 9188.24it/s]\n",
      "206146it [00:22, 9139.86it/s]\n",
      "207090it [00:22, 9203.65it/s]\n",
      "208033it [00:22, 9245.96it/s]\n",
      "208965it [00:23, 9243.39it/s]\n",
      "209909it [00:23, 9276.90it/s]\n",
      "210859it [00:23, 9318.10it/s]\n",
      "211812it [00:23, 9355.94it/s]\n",
      "212748it [00:23, 9276.65it/s]\n",
      "213676it [00:23, 9252.81it/s]\n",
      "214611it [00:23, 9257.02it/s]\n",
      "215537it [00:23, 9233.11it/s]\n",
      "216461it [00:23, 9210.44it/s]\n",
      "217388it [00:23, 9203.57it/s]\n",
      "218321it [00:24, 9216.59it/s]\n",
      "219265it [00:24, 9258.02it/s]\n",
      "220198it [00:24, 9254.78it/s]\n",
      "221141it [00:24, 9282.03it/s]\n",
      "222070it [00:24, 9231.97it/s]\n",
      "222994it [00:24, 9154.93it/s]\n",
      "223928it [00:24, 9185.35it/s]\n",
      "224847it [00:24, 9134.83it/s]\n",
      "225803it [00:24, 9234.33it/s]\n",
      "226752it [00:24, 9285.07it/s]\n",
      "227696it [00:25, 9306.28it/s]\n",
      "228645it [00:25, 9335.87it/s]\n",
      "229587it [00:25, 9336.05it/s]\n",
      "230525it [00:25, 9324.18it/s]\n",
      "231466it [00:25, 9324.90it/s]\n",
      "232399it [00:25, 9301.42it/s]\n",
      "233330it [00:25, 9279.06it/s]\n",
      "234258it [00:25, 9199.49it/s]\n",
      "235189it [00:25, 9207.79it/s]\n",
      "236130it [00:25, 9243.07it/s]\n",
      "237077it [00:26, 9285.48it/s]\n",
      "238033it [00:26, 9341.54it/s]\n",
      "238978it [00:26, 9348.90it/s]\n",
      "239927it [00:26, 9365.88it/s]\n",
      "240864it [00:26, 9286.54it/s]\n",
      "241800it [00:26, 9283.64it/s]\n",
      "242754it [00:26, 9334.45it/s]\n",
      "243688it [00:26, 9255.81it/s]\n",
      "244627it [00:26, 9270.99it/s]\n",
      "245572it [00:27, 9299.28it/s]\n",
      "246506it [00:27, 9286.59it/s]\n",
      "247460it [00:27, 9336.56it/s]\n",
      "248397it [00:27, 9321.59it/s]\n",
      "249337it [00:27, 9320.06it/s]\n",
      "250276it [00:27, 9316.04it/s]\n",
      "251228it [00:27, 9351.54it/s]\n",
      "252174it [00:27, 9358.86it/s]\n",
      "253110it [00:27, 9278.63it/s]\n",
      "253561it [00:27, 9097.96it/s]\n",
      "0it [00:00, ?it/s]\n",
      "925it [00:00, 9167.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1868it [00:00, 9220.73it/s]\n",
      "2822it [00:00, 9289.83it/s]\n",
      "3766it [00:00, 9309.61it/s]\n",
      "4715it [00:00, 9338.22it/s]\n",
      "5652it [00:00, 9322.46it/s]\n",
      "6585it [00:00, 9300.04it/s]\n",
      "7541it [00:00, 9351.89it/s]\n",
      "8456it [00:00, 9265.12it/s]\n",
      "9408it [00:01, 9315.56it/s]\n",
      "10337it [00:01, 9282.88it/s]\n",
      "11278it [00:01, 9295.90it/s]\n",
      "12222it [00:01, 9313.92it/s]\n",
      "13171it [00:01, 9341.22it/s]\n",
      "14121it [00:01, 9363.46it/s]\n",
      "15064it [00:01, 9358.27it/s]\n",
      "16007it [00:01, 9354.66it/s]\n",
      "16941it [00:01, 8848.57it/s]\n",
      "17880it [00:01, 8981.21it/s]\n",
      "18841it [00:02, 9137.63it/s]\n",
      "19796it [00:02, 9233.48it/s]\n",
      "20746it [00:02, 9287.35it/s]\n",
      "21696it [00:02, 9325.48it/s]\n",
      "22639it [00:02, 9331.69it/s]\n",
      "23595it [00:02, 9374.28it/s]\n",
      "24537it [00:02, 9362.86it/s]\n",
      "25495it [00:02, 9402.08it/s]\n",
      "26436it [00:02, 9351.35it/s]\n",
      "27372it [00:02, 9301.09it/s]\n",
      "28317it [00:03, 9320.51it/s]\n",
      "29266it [00:03, 9345.87it/s]\n",
      "30222it [00:03, 9384.30it/s]\n",
      "31172it [00:03, 9393.67it/s]\n",
      "32112it [00:03, 9370.41it/s]\n",
      "33050it [00:03, 9320.34it/s]\n",
      "33994it [00:03, 9331.05it/s]\n",
      "34940it [00:03, 9344.50it/s]\n",
      "35875it [00:03, 9321.05it/s]\n",
      "36808it [00:03, 9298.79it/s]\n",
      "37751it [00:04, 9312.97it/s]\n",
      "38691it [00:04, 9314.02it/s]\n",
      "39640it [00:04, 9341.38it/s]\n",
      "40575it [00:04, 9291.16it/s]\n",
      "41525it [00:04, 9328.14it/s]\n",
      "42458it [00:04, 9303.69it/s]\n",
      "43407it [00:04, 9334.07it/s]\n",
      "44341it [00:04, 9310.83it/s]\n",
      "45273it [00:04, 9233.50it/s]\n",
      "46215it [00:04, 9264.11it/s]\n",
      "47167it [00:05, 9314.83it/s]\n",
      "48118it [00:05, 9347.78it/s]\n",
      "49057it [00:05, 9335.42it/s]\n",
      "49994it [00:05, 9320.77it/s]\n",
      "50931it [00:05, 9310.52it/s]\n",
      "51863it [00:05, 9288.41it/s]\n",
      "52817it [00:05, 9337.86it/s]\n",
      "53757it [00:05, 9331.45it/s]\n",
      "54691it [00:05, 9253.75it/s]\n",
      "55637it [00:05, 9290.11it/s]\n",
      "56584it [00:06, 9318.60it/s]\n",
      "57532it [00:06, 9341.65it/s]\n",
      "58467it [00:06, 9291.34it/s]\n",
      "59409it [00:06, 9304.73it/s]\n",
      "60360it [00:06, 9340.74it/s]\n",
      "61303it [00:06, 9342.38it/s]\n",
      "62245it [00:06, 9340.57it/s]\n",
      "63180it [00:06, 9318.38it/s]\n",
      "64112it [00:06, 9238.65it/s]\n",
      "65062it [00:06, 9291.03it/s]\n",
      "65996it [00:07, 9280.84it/s]\n",
      "66925it [00:07, 9258.74it/s]\n",
      "67854it [00:07, 9243.31it/s]\n",
      "68795it [00:07, 9268.06it/s]\n",
      "69736it [00:07, 9285.51it/s]\n",
      "70683it [00:07, 9315.40it/s]\n",
      "71627it [00:07, 9327.58it/s]\n",
      "72576it [00:07, 9350.86it/s]\n",
      "73512it [00:07, 9273.18it/s]\n",
      "74440it [00:08, 9250.37it/s]\n",
      "75394it [00:08, 9310.91it/s]\n",
      "76331it [00:08, 9303.62it/s]\n",
      "77275it [00:08, 9319.38it/s]\n",
      "78229it [00:08, 9359.69it/s]\n",
      "79180it [00:08, 9379.37it/s]\n",
      "80120it [00:08, 9360.42it/s]\n",
      "81071it [00:08, 9379.88it/s]\n",
      "82023it [00:08, 9396.49it/s]\n",
      "82797it [00:08, 9307.39it/s]"
     ]
    }
   ],
   "source": [
    "num_train = [' '.join([str(idx) for idx in row.values if ~np.isnan(idx)]) for _, row in tqdm(train_df[site_cols].iterrows())]\n",
    "num_test = [' '.join([str(idx) for idx in row.values if ~np.isnan(idx)]) for _, row in tqdm(test_df[site_cols].iterrows())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_train_ws = [' '.join(row.split('.')) for row in str_train]\n",
    "str_test_ws = [' '.join(row.split('.')) for row in str_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 5), max_features=100000).fit(np.array(str_train))\n",
    "X_train_idf = tfidf.transform(np.array(str_train))\n",
    "X_test_idf = tfidf.transform(np.array(str_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp_alice_top_30 = extract_alice_top_30(train_test_sites_df)\n",
    "X_tmp_long = extract_long(train_test_times_df)\n",
    "X_tmp_year = extract_year(train_test_times_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id\n",
       "1        3\n",
       "2        5\n",
       "3        0\n",
       "4        4\n",
       "5        4\n",
       "6        1\n",
       "7        3\n",
       "8        4\n",
       "9        0\n",
       "10       3\n",
       "11       0\n",
       "12       2\n",
       "13       0\n",
       "14       4\n",
       "15       5\n",
       "16       1\n",
       "17       0\n",
       "18       1\n",
       "19       4\n",
       "20       2\n",
       "21       6\n",
       "22       1\n",
       "23       2\n",
       "24       3\n",
       "25       3\n",
       "26       1\n",
       "27       1\n",
       "28       1\n",
       "29       4\n",
       "30       1\n",
       "        ..\n",
       "82768    4\n",
       "82769    3\n",
       "82770    2\n",
       "82771    6\n",
       "82772    6\n",
       "82773    0\n",
       "82774    3\n",
       "82775    3\n",
       "82776    5\n",
       "82777    3\n",
       "82778    6\n",
       "82779    0\n",
       "82780    5\n",
       "82781    4\n",
       "82782    5\n",
       "82783    6\n",
       "82784    4\n",
       "82785    0\n",
       "82786    4\n",
       "82787    6\n",
       "82788    4\n",
       "82789    0\n",
       "82790    3\n",
       "82791    5\n",
       "82792    1\n",
       "82793    3\n",
       "82794    0\n",
       "82795    4\n",
       "82796    5\n",
       "82797    6\n",
       "Name: time1, Length: 336358, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_times_df['time1'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "wscaler = StandardScaler()\n",
    "X_tmp_weeks_scaled = csr_matrix(wscaler.fit_transform(train_test_times_df['time1'].dt.weekday.values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<336358x1 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 336358 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_matrix(StandardScaler().fit_transform(X_tmp_duration.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = hstack((vstack((X_train_idf, X_test_idf)), \n",
    "                X_tmp_time_features, \n",
    "#                 X_tmp_unique, \n",
    "                X_tmp_year_month, \n",
    "                X_tmp_part_of_day, \n",
    "                X_tmp_weekend,\n",
    "                X_tmp_duration,\n",
    "#                 csr_matrix(StandardScaler().fit_transform(X_tmp_duration.todense())),\n",
    "                X_tmp_weeks,\n",
    "#                 X_tmp_weeks_scaled\n",
    "#                 X_tmp_alice_top_30,\n",
    "#                 X_tmp_long,\n",
    "#                 X_tmp_year\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_test = split_train_and_test(X_tmp, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 100127)\n",
      "(82797, 100127)\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_submission(LogisticRegression(C=15, n_jobs=-1), X_train, y, X_test, 'subm_top2.csv') # , solver='lbfgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99549224, 0.99565788, 0.99563412])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(C=15, n_jobs=-1), X_train, y, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99430911, 0.99424995, 0.9943563 ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(n_jobs=-1), X_train, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98996515 0.98956524 0.98973357]\n",
      "[0.98097117 0.98324009 0.98291327]\n"
     ]
    }
   ],
   "source": [
    "X_tmp = hstack((vstack((X_train_idf, X_test_idf)), \n",
    "                X_tmp_time_features, \n",
    "                #X_tmp_unique, \n",
    "                #X_tmp_year_month, \n",
    "                #X_tmp_part_of_day, \n",
    "                #X_tmp_weekend,\n",
    "                #X_tmp_duration,\n",
    "                #X_tmp_weeks\n",
    "               ))\n",
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_test = split_train_and_test(X_tmp, train_df.shape[0])\n",
    "print(cross_val_score(LogisticRegression(C=15, n_jobs=-1), X_train, y, cv=3, scoring='roc_auc'))\n",
    "print(cross_val_score(LogisticRegression(n_jobs=-1), X_train, y, cv=3, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96451302 0.96575294 0.96158993]\n",
      "[0.94855154 0.95410396 0.94985419]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(LogisticRegression(C=15, n_jobs=-1), X_train_idf, y, cv=3, scoring='roc_auc'))\n",
    "print(cross_val_score(LogisticRegression(n_jobs=-1), X_train_idf, y, cv=3, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['718 0 0 0 0 0 0 0 0 0',\n",
       "       '890 941 3847 941 942 3846 3847 3846 1516 1518'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_str = train_df[site_cols].fillna(0).astype(int).astype(str).apply(lambda row: ' '.join(row), axis=1)\n",
    "train_df_str[:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range = (1, 3), max_features=100000)\n",
    "X_train_sparse = tfidf_vec.fit_transform(train_df_str.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96121915 0.96207822 0.95527485]\n",
      "[0.9504246  0.95423162 0.9487498 ]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(LogisticRegression(C=15, n_jobs=-1), X_train_sparse, y, cv=3, scoring='roc_auc'))\n",
    "print(cross_val_score(LogisticRegression(n_jobs=-1), X_train_sparse, y, cv=3, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96121915 0.96207822 0.95527485]\n",
      "[0.9504246  0.95423162 0.9487498 ]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(LogisticRegression(C=15, random_state=17, n_jobs=-1), X_train_sparse, y, cv=3, scoring='roc_auc'))\n",
    "print(cross_val_score(LogisticRegression(random_state=17, n_jobs=-1), X_train_sparse, y, cv=3, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_sorted = train_df.sort_values('time1').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s = train_df_sorted.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_sorted_str = train_df_sorted[site_cols].fillna(0).astype(int).astype(str).apply(lambda row: ' '.join(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec_sorted = TfidfVectorizer(ngram_range = (1, 3), max_features=100000)\n",
    "X_train_sorted_sparse = tfidf_vec_sorted.fit_transform(train_df_sorted_str.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84151882 0.83717209 0.87342938]\n",
      "[0.85269461 0.81783706 0.89248218]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(LogisticRegression(C=15, random_state=17, n_jobs=-1), X_train_sorted_sparse, y_s, cv=3, scoring='roc_auc'))\n",
    "print(cross_val_score(LogisticRegression(random_state=17, n_jobs=-1), X_train_sorted_sparse, y_s, cv=3, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_alice_top_30(df_sites):\n",
    "    alice_top_30 = pd.Series(df_sites[:y.shape[0]][y==1].values.flatten()).value_counts()[:30]\n",
    "    alice_top_30 = alice_top_30.drop(0) \n",
    "    return df_sites.apply(lambda row: row.isin(alice_top_30).astype(int), axis=1).max(axis=1).values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp_alice_top_30 = extract_alice_top_30(train_test_sites_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_long(df):\n",
    "    return ((df.max(axis=1) - df.time1).dt.seconds > 60).astype(int).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp_long = extract_long(train_test_times_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(df):\n",
    "    return (df.time1.dt.year % 2013).astype(int).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp_year = extract_year(train_test_times_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp_alice_top_30 = extract_alice_top_30(train_test_sites_df)\n",
    "X_tmp_long = extract_long(train_test_times_df)\n",
    "X_tmp_year = extract_year(train_test_times_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 5)).fit(np.array(str_train))\n",
    "X_train_idf = tfidf.transform(np.array(str_train))\n",
    "X_test_idf = tfidf.transform(np.array(str_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = hstack((vstack((X_train_idf, X_test_idf)), \n",
    "                X_tmp_time_features, \n",
    "                X_tmp_unique, \n",
    "                X_tmp_year_month, \n",
    "                X_tmp_part_of_day, \n",
    "                X_tmp_weekend,\n",
    "                X_tmp_duration,\n",
    "                X_tmp_weeks,\n",
    "                X_tmp_alice_top_30,\n",
    "                X_tmp_long,\n",
    "                X_tmp_year\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_test = split_train_and_test(X_tmp, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.990220175205182, 0.9920215561907717, 0.9895030539027996]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=15, n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 1698314)\n",
      "(82797, 1698314)\n"
     ]
    }
   ],
   "source": [
    "make_submission(LogisticRegression(C=15, n_jobs=-1), X_train, y, X_test, 'lr_tfidf_5_more.csv') # 0.95999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = hstack((vstack((X_train_idf, X_test_idf)), \n",
    "                #X_tmp_time_features, \n",
    "                X_tmp_unique, \n",
    "                X_tmp_year_month, \n",
    "                X_tmp_part_of_day, \n",
    "                X_tmp_weekend,\n",
    "                X_tmp_duration,\n",
    "                X_tmp_weeks,\n",
    "                X_tmp_alice_top_30,\n",
    "                X_tmp_long,\n",
    "                X_tmp_year\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values.astype('int64')\n",
    "X_train, X_test = split_train_and_test(X_tmp, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9813161934057573, 0.9852840239352352, 0.9826542903473875]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "score(LogisticRegression(C=15, n_jobs=-1), X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
